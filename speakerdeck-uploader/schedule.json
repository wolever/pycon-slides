[
    {
        "abstract": "###overview\r\nThis tutorial aims to teach participants how to use standard Python tools and Plotly to create stunning data visualizations which can be shared and leveraged as a platform for collaboration. \r\n\r\n###takeaways\r\nAfter completion of the tutorial, students will be able to use their data to create matplotlib and Plotly figures from a Python script. They will be able to convert matplotlib figures into interactive graphs and subsequently share them on the web. Beginner Python programmers will get a feel for using the language and all will learn how to make beautiful data visualizations in the browser.\r\n\r\n###requirements\r\nTo participate in the entire tutorial, students will need to install Python and the following packages: numpy, matplotlib, ipython[notebook], and plotly. Students will also need to create an account here [https://plot.ly](https://plot.ly). They may want to follow the getting started instructions here [https://plot.ly/python/getting-started](https://plot.ly/python/getting-started). If students run into any difficulties getting their environments setup for this tutorial they may contact the presenters directly at: <andrew@plot.ly>, <etienne@plot.ly>, and <marianne@plot.ly>.\r\n\r\n###format\r\nThe format of the tutorial is that of an interactive classroom.  Deriving motivation from real-world data visualization needs in science and journalism, we begin by showing how to get from data to basic, informative visualizations quickly and easily.  Students will then be introduced to different ways of improving and customizing their graphs.  We will also show how to edit existing graphs and instructors will engage students to help them explore on their own.  We will put forward an exploratory approach and address reproducibility, which is made possible by a seamless workflow in the Python world (use of Python scripts, the IPython Notebook, Plotly\u2019s Python package).\r\n",
        "authors": [
            "Andrew Seier",
            "\u00c9tienne T\u00e9treault-Pinard",
            "Marianne Corvellec"
        ],
        "conf_key": 26,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/317/",
        "contact": [
            "andrew@plot.ly",
            "etienne@plot.ly",
            "marianne.corvellec@gmail.com"
        ],
        "description": "From Python basics to NYT-quality graphics, we walk through workflows to make beautiful, shareable data visualizations. We\u2019ll also explore 3D plotting in the browser, cross-language collaboration, and matplotlib figure conversion. By using Python\u2019s scientific stack and an IPython notebook--attendees may follow along. For data analysts, data journalists, and anyone who likes plots.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Making Beautiful Graphs in Python and Sharing Them",
        "released": true,
        "room": "Room 512EA",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "Machine learning forms the core of many intelligent services we use today, including language translation, web search, movie recommendation, and spam detection. Python's ecosystem provides a high quality array of tools for developing insights on these use cases and applying machine learning in production.\r\n\r\nIn this tutorial, we will provide a hands-on introduction to the concepts of machine learning and the process of applying these concepts in a competition setting. We'll start out with an overview of machine learning applications and how computers can learn from data. Then, we'll look at algorithms and methodologies that have been demonstrated to work well in a wide variety of applications, and what makes these algorithms tick.\r\n\r\nFor the bulk of the tutorial, we'll focus on a live Kaggle competition. We'll load the data into iPython notebook for interactive exploration and visualization, and use this to gain a basic understanding of what's in the data. From there, we'll extract features and train a model using scikit-learn. This will bring us to our first Kaggle submission.\r\n\r\nNext, we'll switch out of iPython notebook and start structuring the code for repeatability, using git for version control and Make for an explicit dependency graph. We'll learn how to structure the problem for offline evaluation and then use scikit-learn's clean model API's to train many models simultaneously and perform feature selection and hyperparameter optimization.\r\n\r\nAt this point, we'll provide suggestions for how to further improve on the problem and then finish with an hour-long lab, with tutorial participants working individually or in groups to improve their methodologies and getting advice as needed.\r\n\r\nBy the end of this tutorial, participants will have a basic understanding of how to identify problems where machine learning can add value, along with how to use machine learning and the Python ecosystem to address these problems. They will be able to apply these techniques to their work, hobbies, Kaggle competitions, and research.",
        "authors": [
            "Ben Hamner"
        ],
        "conf_key": 27,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/321/",
        "contact": [
            "pycon@benhamner.com"
        ],
        "description": "This tutorial will offer an introduction machine learning and how to apply it to a Kaggle competition. We will cover methodologies that have worked well across a diverse set of problems, and then work on a current Kaggle competition together using iPython notebook and scikit-learn. We will cover concepts including feature extraction, feature selection, model evaluation, and data visualization.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Winning Machine Learning Competitions With Scikit-Learn",
        "released": true,
        "room": "Room 512FB",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "Are you interested in learning how to orchestrate and configure servers? This tutorial will cover **Ansible**, a popular orchestration and configuration management tool written in Python.\r\n\r\nWe'll cover:\r\n\r\n  * Writing Ansible playbooks for tasks such as installing and configuration software, and piecing together an application deployment.\r\n  * Writing reusable, exportable Ansible _roles_.\r\n  * Writing inventory and lookup plugins to extend Ansible's core functionality.\r\n\r\nFinally, we'll conclude by deploying an actual application.",
        "authors": [
            "Luke Sneeringer"
        ],
        "conf_key": 28,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/313/",
        "contact": [
            "luke@sneeringer.com"
        ],
        "description": "Interested in Ansible, or in server orchestration and configuration generally? This tutorial will teach the basics -- and a few of the not-so-basics -- of orchestrating machines with Ansible.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Ansible 101",
        "released": true,
        "room": "Room 513A",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "This tutorial is a systematic introduction to descriptors and metaclasses.\r\nIt covers all relevant information with a focus on practical applications\r\nfor common tasks.\r\n\r\nIn hand-on sessions you will learn how to write your own descriptors that\r\nadapt attribute access to your needs. You will experience how metaclasses\r\ncan help you to get more insight into a code base.\r\n\r\nUse cases provide working code that can serve as a basis for your own\r\nsolutions. You will gain a deeper understanding of more advanced concepts\r\nthat can help to write better programs.\r\n\r\nI've been delivering these topics over the last years as a part of an advanced\r\ntraining in open and in-house courses as well as trainings at EuroPython,\r\nPyCon PL, PyCon DE and PyCon IE. The material has been continuously refined\r\nowing to the participant feedback.",
        "authors": [
            "Mike M\u00fcller"
        ],
        "conf_key": 29,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/302/",
        "contact": [
            "mmueller@python-academy.de"
        ],
        "description": "Descriptors and metaclasses are advanced Python features. While it is\r\npossible to write Python programs without active knowledge of them,\r\nknowing more about them facilitates a deeper understanding of\r\nthe language. With examples, you will learn how they work and how to\r\nwrite your own descriptors and metaclasses. Furthermore, you will understand\r\nwhen to use and when better not to use them.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Descriptors and Metaclasses - Understanding and Using Python's More Advanced Features",
        "released": true,
        "room": "Room 513BC",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "In three hours the instructor will demonstrate and explain 500 Python expressions, grouped by topic, evaluated at the interactive Python prompt.  After each demonstration students will experiment with another 500 expressions provided by the instructor to solidify their understanding of the topic.  Each pairing of demonstration and experimentation lasts less than 15 minutes.\r\n\r\nSpecial attention is given to variables (names, namespaces, and objects) because many programmers new to Python assume they understand how they work based on experience in other languages, but later get tripped up by those incorrect assumptions.  Lists and dictionaries, two of Python's workhorse data structures, also receive a lot of attention.\r\n\r\nExamples of complete Python programs are given only brief treatment near the end, because we assume students already know how and why to write programs.\r\n",
        "authors": [
            "Stuart Williams"
        ],
        "conf_key": 30,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/298/",
        "contact": [
            "stugoo@gmail.com"
        ],
        "description": "A very fast introduction to Python for software developers with experience in other languages.  Instead of a traditional top-down presentation of Python's features, syntax, and semantics, students are immersed in the language bottom-up with hundreds of small examples using the interactive interpreter to quickly gain familiarity with most of the core language features.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Python by Immersion",
        "released": true,
        "room": "Room 513D",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "The aim is to cover the basics of setting up a simple Django site, but using full, rigorous TDD at every step along the way.\r\n\r\nThe tutorial is based on the first few chapters of my book, which is available (for free!) online for you to follow up with after the session, so that you can embed what you've learned.  [www.obeythetestinggoat.com](http://www.obeythetestinggoat.com)\r\n\r\nWe'll learn:\r\n\r\n* how to set up functional tests with Selenium\r\n* how to set up Django\r\n* how to run Django unit tests\r\n* how TDD actually works in practice:  the unit test / code cycle where we re-run the tests after each tiny, incremental change to the code\r\n* all the basics of Django like views, models and templates. \r\n\r\nWe'll talk about what to test, what not to test, what the point of all this testing is anyway, you'll get a real hands-on feeling for how it works, and I promise to make it all at least moderately entertaining!\r\n\r\nAnd it's all in Python 3 :)\r\n\r\n",
        "authors": [
            "Harry Percival"
        ],
        "conf_key": 44,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/300/",
        "contact": [
            "hjwp2@cantab.net"
        ],
        "description": "A beginner's introduction to testing and web development with Django. We'll build a simple web app, from scratch, but with full TDD, including functional testing with Selenium and unit testing Django's views, templates, and models. Some familiarity with Python is desirable, but no prior knowledge of Django or testing is assumed.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "TDD with Django, from scratch: a beginner's intro to testing and web development",
        "released": true,
        "room": "Room 510B",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "Machine learning is the branch of computer science concerned with the development of algorithms which can be trained by previously-seen data in order to make predictions about future data. It has become an important aspect of work in a variety of applications: from optimization of web searches, to financial forecasts, to studies of the nature of the Universe.\r\n\r\nThis tutorial will explore machine learning with a hands-on introduction to the scikit-learn package.  Beginning from the broad categories of *supervised* and *unsupervised* learning problems, we will dive into the fundamental areas of *classification*, *regression*, *clustering*, and *dimensionality reduction*.  In each section, we will introduce aspects of the Scikit-learn API and explore practical examples of some of the most popular and useful methods from the machine learning literature.\r\n\r\nThe strengths of scikit-learn lie in its uniform and well-document interface, and its efficient implementations of a large number of the most important machine learning algorithms. Those present at this tutorial will gain a basic practical background in machine learning and the use of scikit-learn, and will be well poised to begin applying these tools in many areas, whether for work, for research, for Kaggle-style competitions, or for their own pet projects.",
        "authors": [
            "Jake VanderPlas"
        ],
        "conf_key": 45,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/323/",
        "contact": [
            "jakevdp@gmail.com"
        ],
        "description": "This tutorial will offer an introduction to the core concepts of machine learning and the Scikit-Learn package. We will introduce the scikit-learn API, and use it to explore the basic categories of machine learning problems and related topics such as feature selection and model validation, and practice applying these tools to real-world data sets.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Machine Learning with Scikit-Learn (I)",
        "released": true,
        "room": "Room 510D",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "The novice or occasional user of the Pandas dataframe too often finds themselves lost in a forest of possible next moves. They try calling `groupby()` but the result an opaque object instead of a reorganized dataframe. They attempt a `pivot()` but cannot understand why the result is different from what they expected. The examples for `stack()` and `unstack()` look very nearly like the operations they want to perform, but they can never remember which is which without the documentation.\r\n\r\nThis tutorial will help students rebuild their mental model of the Pandas dataframe from the ground up, starting with the structure of the dataframe and its indexes and then progressing through a complete tour of all of the operations that dataframe methods offer. Symmetries and contrasts will regularly be drawn between the methods and operations to help make it as easy as possible to remember them all, and to help relate the vertical and horizontal indexes along the edges of the dataframe.\r\n\r\nThe tutorial will show Pandas use in both plain Python files and also in the IPython Notebook. Students will be encouraged to use Anaconda or another distribution that gives them both Python and all the standard science and numeric tools up-front without requiring further installation steps.\r\n\r\nAt each stage in the tutorial, students will be given a short lecture and demonstration, allowed to ask questions, then be presented with a series of short dojo-like exercises that build their knowledge of each maneuver by progressing from simple to fairly complex data manipulations. As each feature is learned, students will then be challenged to use it in combination with features learned earlier in the tutorial \u2014 a mechanism that should improve retention of the complete set of possible method calls.\r\n\r\nThe exercises will be hand-written and tailored to share three features. First, the examples will try to re-use dataframes whenever possible, so that students quickly become familiar with the data layout in each one of them and can more easily focus on the next maneuver they are learning. Second, the example dataframes will each be rather short \u2014 about one or two screens-full of data \u2014 so that the user has a more complete picture of \u201cwhere their data is going\u201d with each operation than would be possible with a larger data set. Finally, each example will be semantically rich and display common-sense relationships among the values present: there will be none of the vast arrays of randomly-generated random numbers that seem so common in scientific Python tutorials, but that give the learner\u2019s mind nothing familiar to grasp as they stare at the output and wonder what relation the output numbers have to the inputs.",
        "authors": [
            "Brandon Rhodes"
        ],
        "conf_key": 51,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/315/",
        "contact": [
            "brandon@rhodesmill.org"
        ],
        "description": "The typical Pandas user learns one dataframe method at a time, slowly scraping features together through trial and error until they can solve the task in front of them. In this tutorial you will re-learn how to think about dataframes from the ground up, and discover how to select intelligently from their abilities to solve your data processing problems through direct and deliberately-chosen steps.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Pandas From The Ground Up",
        "released": true,
        "room": "Room 513BC",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "After attending this tutorial, attendees will gain general knowledge, being able to:\r\n\r\n* Explain the difference between cross-site scripting and cross-site request forgery, and understand at least one way abuse each.\r\n\r\n* Describe the use of cookies in web applications and how they relate to security.\r\n\r\n* Identify authorization bugs in web applications, and name programming patterns that avoid authorization bugs.\r\n\r\n* Understand how to think like a attacker, by practicing being one.\r\n\r\nThey will be able to perform and explain specific attacks as well, such as:\r\n\r\n* Taking advantage of subdomains to steal cookies, and how to use a stolen cookie to impersonate another user.\r\n\r\n* Abusing file uploads to defeat security protections within a web app.\r\n\r\n* Abusing a Django SECRET_KEY to steal a fellow user's account.\r\n\r\n* Leveraging the \"pickle\" module to run chosen code in the context of someone else's web app.\r\n\r\nAttendees will leave the tutorial with an appreciation of the importance of security and practical experience that enables further study.",
        "authors": [
            "Asheesh Laroia",
            "Jacky Chang",
            "Nicole Zuckerman"
        ],
        "conf_key": 24,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/306/",
        "contact": [
            "asheesh@asheesh.org",
            "kyoki01@gmail.com",
            "nicole.zuckerman@gmail.com"
        ],
        "description": "Web application security can be an intimidating discipline, yet it can be of supreme importance for the people who use the things we build.\r\n\r\nIn this tutorial, you'll learn about essential topics in web security, and you will gain hands-on practice identifying and leveraging vulnerabilities in a Python-based web app. For each issue, we will cover how your code can stay on the side of safety.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Getting comfortable with web security: A hands-on session",
        "released": true,
        "room": "Room 512CG",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "Spark is a distributed computing (big data) framework, considered by many as the successor to Hadoop. You can write Spark programs in Java, Scala or Python. Spark uses a functional approach, similar to Hadoop\u2019s Map-Reduce. \r\n\r\nIn this tutorial we will cover the basics of writing spark programs in python (initially from the pyspark shell, later with independent applications). We will also discuss some of the theory behind spark, and some performance considerations when using spark in a cluster.",
        "authors": [
            "Orlando Karam"
        ],
        "conf_key": 22,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/329/",
        "contact": [
            "orlando.karam@gmail.com"
        ],
        "description": " In this tutorial we will cover the basics of writing spark programs in python (initially from the pyspark shell, later with independent applications). We will also discuss some of the theory behind spark, and some performance considerations when using spark in a cluster.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Introduction to Spark with python",
        "released": true,
        "room": "Room 510B",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "Bayesian statistical methods are becoming more common and more important, but there are not many resources to help beginners get started. \u00a0People who know Python can use their programming skills to get a head start.\r\n\r\nI will present simple programs that demonstrate the concepts of Bayesian statistics, and apply them to a range of example problems. \u00a0Participants will work hands-on with example code and practice on example problems.\r\n\r\nAttendees should have at least basic level Python and basic statistics. \u00a0If you learned about Bayes\u2019s theorem and probability distributions at some time, that\u2019s enough, even if you don\u2019t remember it!\r\n\r\nAttendees should bring a laptop with Python and matplotlib. \u00a0You can work in any environment; you just need to be able to download a Python program and run it. \u00a0I will provide code to help attendees get set up ahead of time.\r\n",
        "authors": [
            "Allen Downey"
        ],
        "conf_key": 25,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/325/",
        "contact": [
            "allendowney@gmail.com"
        ],
        "description": "An introduction to Bayesian statistics using Python. \u00a0Bayesian statistics are usually presented mathematically, but many of the ideas are easier to understand computationally. \u00a0People who know Python can get started quickly and use Bayesian analysis to solve real problems. \u00a0This tutorial is based on material and case studies from Think Bayes (O\u2019Reilly Media).\r\n",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Bayesian statistics made simple",
        "released": true,
        "room": "Room 512DH",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "Beginning programmers: welcome to PyCon! Jumpstart your Python and programming careers with this 3-hour interactive tutorial.\r\n\r\nBy the end, you'll have hands-on exposure to many core programming concepts, be able to write useful Python programs, and have a roadmap for continuing to learn and practice programming in Python.\r\n\r\nThis tutorial assumes no prior programming experience.\r\n\r\nWe'll cover:\r\n\r\n- Python as a calculator\r\n- Basic data types\r\n- Interactive programs: input and output\r\n- Making choices: booleans and flow control\r\n- Lists and iteration\r\n- Functions\r\n\r\nWe'll also practice writing Python scripts, see demos of cool Python applications, and take a quick tour of popular Python libraries.\r\n\r\nBy the end of this tutorial, you'll have the background and context to learn a lot more as you go through the rest of PyCon. You'll also be in great shape to continue learning Python through longer-form resources and start working on your own Python projects.",
        "authors": [
            "Dana Bauer"
        ],
        "conf_key": 50,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/296/",
        "contact": [
            "dana.bauer@gmail.com"
        ],
        "description": "Beginning programmers: welcome to PyCon! Jumpstart your Python and programming careers with this 3-hour interactive tutorial. By the end, you'll have hands-on exposure to many core programming concepts, be able to write useful Python programs, and have a roadmap for continuing to learn and practice programming in Python. This class assumes no prior programming experience.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "A hands-on introduction to Python for beginning programmers",
        "released": true,
        "room": "Room 513A",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "[Docker](https://docker.com/) is an open source, lightweight, virtualized environment for portable applications. With all the buzz it has attracted, it can be hard to figure out exactly what Docker is and what it can do for you. This tutorial will teach you the fundamentals of Docker, why it\u2019s making waves, and how it might be a useful addition to your platform.\r\n\r\nIn this session you will:\r\n\r\n- Learn the basics of working with Docker containers and images\r\n- Create your own Docker images\r\n- Learn how to \u201cdockerize\u201d a sample Flask application\r\n- Publish to the [Docker Hub](https://hub.docker.com/) (the GitHub of Docker)\r\n- Use Fig to manage multiple Docker containers at once\r\n- Learn about deploying to one of the new Docker-specific cloud hosting services\r\n\r\nStudents will spend most of this session getting their hands dirty in a series of exercises, which are introduced with some brief presentations. The exercises will be mostly self-paced, though students are encouraged to seek help from the instructor or their neighbors if they need it. The session is loosely based off O\u2019Reilly\u2019s \u201cIntroduction to Docker\u201d video tutorial.\r\n\r\nA Vagrantfile and Ansible playbook will be available to help students work locally. Fully provisioned cloud servers will be provided for students who don\u2019t want to set up local development environments.",
        "authors": [
            "Andrew T. Baker"
        ],
        "conf_key": 46,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/312/",
        "contact": [
            "andrew.tork.baker@gmail.com"
        ],
        "description": "Docker was one of last year\u2019s most talked about open source projects - but what is it? And what does it mean for deploying applications? This tutorial will explain what Docker is and where it fits in with other deployment and configuration management tools. Students will then learn the basics of working with Docker containers, how to \u201cdockerize\u201d their Python apps, and some emerging best practices.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Docker 101: Introduction to Docker",
        "released": true,
        "room": "Room 512CG",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "This is a class directed at Python beginners that are interested in learning Web development. In this workshop we are going to build a Web application using Flask, the Python Web micro-framework.\r\n\r\nThe only pre-requisite is that you have a basic knowledge of Python. I will be happy to explain anything you don't understand, but I will assume that you are at least familiar with the language syntax and structure.\r\n\r\nWe will start with the setup of a development environment for Flask in your laptop, and then will work on an application that we will build from scratch in small incremental steps. The main topics that I will cover in this class are Basic Applications, Templates, Web Forms and User Sessions. At the end I will also give you an overview of what you should focus on next.\r\n\r\nNote that this year my intention is to cover the basic building blocks in very good detail, so this is a class that is ideal for beginners, or those that found my PyCon 2014 tutorial too intimidating. I will welcome questions at all times and also expect all the attendees will have the example application running on their laptops by the end of the class.\r\n\r\nMy hope is that this class will give you a really good taste of what Web development is. By the end of it you will have enough knowledge to build simple Web applications on your own, and if you are interested, you will know what you need to do to continue on your learning path.",
        "authors": [
            "Miguel Grinberg"
        ],
        "conf_key": 47,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/308/",
        "contact": [
            "miguelgrinberg50@gmail.com"
        ],
        "description": "Flask is a web framework for Python based on Werkzeug, Jinja 2 and good intentions. It is considered a micro-framework, but don't get the \"micro\" part fool you; Flask can do everything others can do, many times in a simpler, leaner way. In this tutorial session we will build a web application together. Bring your laptop and your questions!",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Flask Workshop",
        "released": true,
        "room": "Room 512DH",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "Working with Hadoop using Python instead of Java is entirely possible with a conglomeration of active open source projects that provide Python APIs to Hadoop components. This tutorial will survey the most important projects and show that not only is Hadoop with Python possible, but that it also has some advantages over Hadoop with Java.\r\n\r\nThe reasons for using Hadoop with Python instead of Java are not all that different than the classic Java vs. Python arguments. One of the most important differences is not having to compile your code by instead using a scripting language. This makes more interactive development of analytics possible, makes maintaining and fixing applications in production environments simpler in many cases, makes for more succinct and easier to read code, and so much more. Also, by integrating Python with Hadoop, you get access to the world-class data analysis libraries such as numpy, scipy, nltk, and scikit-learn that are best-in-breed both inside of Python and outside.\r\n\r\nStudents will be surprised at how quickly they can get up and running with Hadoop when using Python. In this tutorial, we will talk about the following libraries and approaches and will guide students through a series of exercises:\r\n\r\n - Interacting with files in the Hadoop Distributed File System with the **snakebite** Python module to store potentially petabytes of data\r\n - Writing MapReduce jobs with the **mrjob** Python module to analyze large amounts of data over potentially thousands of nodes\r\n - Writing MapReduce jobs with Apache Pig (a higher-level data flow language) in conjunction with Python user-defined functions\r\n\r\nIn addition to these topics, we'll briefly cover the state of Python support for other Hadoop ecosystem projects, such as HBase, Hive, Spark, Storm, Flume, Accumulo, and a few others.",
        "authors": [
            "Donald Miner"
        ],
        "conf_key": 48,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/327/",
        "contact": [
            "donaldpminer@gmail.com"
        ],
        "description": "In this tutorial, students will learn how to use Python with Apache Hadoop to store, process, and analyze incredibly large data sets. Hadoop has become the standard in distributed data processing, but has mostly required Java in the past. Today, there are a numerous open source projects that support Hadoop in Python and this tutorial will show students how to use them.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Hadoop with Python",
        "released": true,
        "room": "Room 512EA",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "In this tutorial, I will show you how you can use data to construct networks for data analysis.  The goal is to demystify graph analytics and mining, and make it accessible to the general programmer. Starting with understanding a toy data set as an anchor, we will go through:\r\n\r\n   * graph basics (nodes + edges, list and matrix representations), \r\n   * modelling problems as graphs,\r\n   * preprocessing data using Pandas,\r\n   * importing data using NetworkX,\r\n   * how to compute basic statistics of the network\r\n   * generating visualizations using matplotlib,\r\n   * finding hubs, paths and clusters in the data,\r\n   * (if time permits) random graphs for statistical inference\r\n\r\n\r\nIPython notebooks and data files will be distributed beforehand on Github to facilitate code distribution.\r\n\r\nAs good pedagogical practice, we will have lots of guided hands-on time, and about 30 min to 1 hour of unstructured \u201cfree hacking time\u201d to explore a bike sharing data set (with suggested questions) in small groups of your choice of size. You will also share your IPython notebooks via Github. After the hacking time, we will showcase a select number of analyses.",
        "authors": [
            "Eric Ma"
        ],
        "conf_key": 49,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/319/",
        "contact": [
            "ericmajinglong@gmail.com"
        ],
        "description": "Have you ever wondered about how those data scientists at Facebook and LinkedIn make friend recommendations? Or how epidemiologists track down patient zero in an outbreak? If so, then this tutorial is for you. Here, we will explore a bike sharing data set as a way to understand the kinds of problems that can be solved using graph analytics.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Practical Graph/Network Analysis Made Simple",
        "released": true,
        "room": "Room 512FB",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "This tutorial will cover how easy it can be to build your own REST API using Django and Django REST Framework.  It is meant to be a course for people that have at least an introductory knowledge of Python, but are not familiar or comfortable with the Django world.  The tutorial would start with a quick walkthrough of installing the relevant Django REST Framework version.  From there, we will actually start coding a REST API for a simple Restaurant Menu application.  This will include covering the necessary building blocks that are required.  In building our Restaurant Menu application, we will control API access levels through Django Users and Groups.  We will also go over the benefits of the Admin interface and the Browsable API interface.  Once our base API is ready, we will start looking at advanced use cases.  Based on time and attendee interest, we may be able to cover additional topics along the way or at the end.  Those additional topics could be advanced API functionalities or coverage of general questions. ",
        "authors": [
            "Kenny Yarboro"
        ],
        "conf_key": 23,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/310/",
        "contact": [
            "kenny.yarboro@gmail.com"
        ],
        "description": "Using a combination of Django and Django REST Framework, we will build a Restaurant Menu that can be managed via a REST API. Starting from the install of the Django REST Framework, we will build our way to a functional API that meets the needs of developers and end-users. You will walk away with an understanding of the basic concepts of REST APIs and a working sample project.",
        "duration": 200,
        "end": "2015-04-09T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Building a REST API Using Django & Django REST Framework",
        "released": true,
        "room": "Room 510D",
        "start": "2015-04-09T09:00:00",
        "tags": ""
    },
    {
        "abstract": "We'll discuss each kind of the most prevalent security flaws at the theoretical level, then using a specially-crafted, deliberately vulnerable app, individuals or pairs will carry out exploits against these flaws, and we'll discuss strategies for mitigating each type of attack in several popular Python frameworks.\r\n\r\nWe'll be using the [OWASP Top 10][0] as our topic roadmap, addressing issues such as:\r\n\r\n * Injection Attacks\r\n * Broken Authentication & Session Management\r\n * Cross-Site Scripting (XSS)\r\n * Insecure Direct Object References\r\n * Security Misconfiguration\r\n * Sensitive Data Exposure\r\n * Missing Function-Level Access Control\r\n * Cross-Site Request Forgery (CSRF)\r\n * Using Components with Known Vulnerabilities\r\n * Unvalidated Redirects and Forwards\r\n\r\nYou'll want to set your brain to \"devious\" mode; you'll also need a laptop with Python 2.7 or 3.3 (or a buddy you can pair with). Having pip and virtualenv will be useful too, as will having Git installed to pull down the code we'll be working with.\r\n\r\nAttendees **do not need prior security experience**; this tutorial is aimed at **intermediate web developers** who are interested in gaining hands-on experience with **simple forms of the most common attacks**. Attendees should have some experience with **Python, Javascript, and SQL**, and may benefit from at least a passing familiarity with Django (eg, previously attending a Django tutorial or working through the [online tutorial][1]).\r\n\r\n  [0]: https://www.owasp.org/index.php/Top_10_2013-Top_10\r\n  [1]: https://docs.djangoproject.com/en/1.7/intro/tutorial01/",
        "authors": [
            "Mike Pirnat",
            "David Stanek"
        ],
        "conf_key": 52,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/304/",
        "contact": [
            "mpirnat@gmail.com",
            "dstanek@dstanek.com"
        ],
        "description": "The Internet is a dangerous place, filled with evildoers out to attack your code for fun or profit, so it's not enough to just ship your awesome new web app--you have to take the security of your application, your users, and your data seriously. You'll get into the mindset of the bad guys as we discuss, exploit, and mitigate the most common web app security flaws in a controlled environment.",
        "duration": 200,
        "end": "2015-04-08T12:20:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Shiny, Let's Be Bad Guys: Exploiting and Mitigating the Top 10 Web App Vulnerabilities",
        "released": true,
        "room": "Room 513D",
        "start": "2015-04-08T09:00:00",
        "tags": ""
    },
    {
        "abstract": "You might think of the Linux kernel as something that only kernel developers need to know about. Not so! It turns out that understanding some basics about kernels and systems programming makes you a better developer, and you can use this knowledge when debugging your normal everyday Python programs.\r\n\r\nWe\u2019ll talk about how to use strace, ltrace, /proc, and friends to debug your servers and your misbehaving programs. A few specific tricks we\u2019ll cover:\r\n\r\n* how to recover files with /proc (and other tricks)\r\n* using strace to understand programs without reading their source code\r\n* easily hunting down which log file a program is writing to and what commands it\u2019s executing\r\n\r\nYou\u2019ll come away with a new toolset for debugging your programs that works in any programming language. This talk will be focused on Linux tools, with some references to their OS X counterparts.",
        "authors": [
            "Julia Evans"
        ],
        "conf_key": 134,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/363/",
        "contact": [
            "julia@jvns.ca"
        ],
        "description": "You might think of the Linux kernel as something that only kernel developers need to know about. Not so! It turns out that understanding some basics about kernels and systems programming makes you a better developer, and you can use this knowledge when debugging your normal everyday Python programs.",
        "duration": 30,
        "end": "2015-04-11T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Systems programming as a swiss army knife",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T10:50:00",
        "tags": ""
    },
    {
        "abstract": "You may have learned Python's advanced syntax for functions (like `*args` and `**kwargs`), but the best time to use it may still not be obvious. The goal of this talk is to provide clear advice on how and when to use the Python language features that affect functions (and methods).\r\n\r\nThis talk will present a number of concrete suggestions for how to use functions effectively. With each suggestion I'll use code examples to demonstrate why this is the best choice and why other approaches aren't a good idea.",
        "authors": [
            "Brett Slatkin"
        ],
        "conf_key": 126,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/397/",
        "contact": [
            "brett@haxor.com"
        ],
        "description": "Functions improve readability, encourage reuse, and facilitate refactoring. Python has many unique features that make functions significantly more powerful. This talk will show you the best ways to use functions in Python: when *args is helpful and when it'll crash your programs; how to use generators for arguments and return values; the value of keyword vs. keyword-only arguments; and more!",
        "duration": 30,
        "end": "2015-04-10T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "How to Be More Effective with Functions",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T10:50:00",
        "tags": ""
    },
    {
        "abstract": "**What is an Environment?**   \r\nEnvironments are the things that make up your surroundings, both tangible and intangible. The effects that an environment can have on the people in them is profound. Examples of your environment include physical spaces like office layouts. They also include things like stage layouts, where one person is elevated over others giving them power and credibility to speak. The environment is key in shaping that power and credibility. Work environments also include the ability to navigate the job itself. How does one accomplish work, move up in the social structure, etc. The power hierarchy, communication structure, processes, and physical space are all part of the environment for an engineering team. It\u2019s important to understand the environmental factors that affect people\u2019s behavior and ability to be successful at their jobs. Sexism and racism doesn't always manifest as individuals discriminating against individuals. Sometimes it\u2019s a collective group of people (all of us) creating an environment that is better for some than others. \r\n\r\n**8 Common Problems in Engineering Environments**\r\n\r\n* Onboarding/Training \r\n *  Currently rely on existing social structures  \r\n\r\n> The first contact a person has with their new team\u2019s environment is the training and on boarding they receive. In tech, training/onboarding is not prioritized and many companies have no on boarding. However, when it comes to people, in the absence of process what ends up happening is that the process relies on the existing social structure. In most tech companies, the existing social structure is the core team that is already there; namely male and often mostly white. This means that the first experience people have with their new environment is inadvertently biased towards people like the existing team in companies that don\u2019t have thoughtful integration and training for new engineers.\r\n\r\n* Benefits \r\n *  Parental leave\r\n *  Sick days\r\n *  Vacation\r\n *  Bathroom supplies  \r\n\r\n> Benefits is not a difficult problem to solve although it requires some thought. Make your benefits count and go for the simple wins. Understanding that not all of your employees have the same amount of responsibility outside the company is important; some people have a disproportionate share of the home responsibility. Using young, single people as the baseline for work expectation will alienate people with children, especially those who do most of the childcare.\r\n\r\n* Safety \r\n *  Work hours\r\n *  Transportation\r\n *  Safety at conferences   \r\n\r\n> Safety is pretty basic and pretty important. It bleeds into a lot of aspects of work life. A common one is safety getting to and from work; if you expect employees to work late and travel home in the dark, it\u2019s important to remember that safety is going to be a bigger concern for some employees vs. Others. Have transportation plans ready for people working late or people at conferences and events. Otherwise, setup a culture that encourages people to go home while it\u2019s still light out.   \r\n> There\u2019s the other major issue of safety from other coworkers. We saw with the Tindr lawsuit that safety from coworkers is not a guarantee for many people. This is another area to have a plan and to have process about what to do if one coworker is harassing another. A plan that doesn\u2019t have anything to do with placing blame but that allows any employee to get distance or space from another employee professionally.\r\n\r\n* Promotions \r\n *  men promoted based on potential, women (and likely minorities) promoted based on accomplishments\r\n *  http://www.mckinsey.com/client_service/organization/latest_thinking/unlocking_the_full_potential\r\n *  http://www.forbes.com/sites/susanadams/2013/03/04/10-things-sheryl-sandberg-gets-exactly-right-in-lean-in/\r\n *  http://www.mckinsey.com/careers/women/~/media/Reports/Women/2012%20WSJ%20Women%20in%20the%20Economy%20white%20paper%20FINAL.ashx   \r\n\r\n> By not recognizing subconscious differences in how we promote different groups of people, we create small gaps that grow over time. If women and other minorities have to accomplish a task to be promoted but men simply have to convince others that they could potentially do the task, then you create a small gap that grows over time.\r\n\r\n* Power structures\r\n *  Flirting culture\r\n\r\n* Communication (argument vs. Discussion based culture, using emotions as weapons, gendered-loaded insults, lack of communication channels)\r\n *  Argument vs. Discussion culture\r\n *  Lack of communication channels   \r\n\r\n> There are two major environmental factors that hurt communication for a lot of people. The first is the argument vs. Discussion based culture. Allowing engineers to argue and creating an argument culture puts an emphasis on the idea of \u2018winning\u2019 a conversation. If there is an idea of winning multiple things come out of that environment. Size and aggression will be used as tactics to win. Undermining another person\u2019s point will be used to win. And finally, if something can be won then someone will cheat (that\u2019s why we have refs in sports) and it can encourage unethical behavior like lying or inventing information to win. A discussion based culture is a culture where the emphasis is on finding a shared truth. Because the goal is to collectively come to the best conclusion possible, all viewpoints should be included and acknowledged and points are not given for stomping on other ideas. It\u2019s a seemingly small but critical shift in the way decisions are made and communicated.\r\n> The second environmental factor that hurts people is having a lack of communication channels. There should be a lot of ways for someone to easily give feedback about the company, processes, organization, or their coworkers that is private and low overhead. Forcing employees to schedule meetings with busy bosses and founders and putting the responsibility on the person with less power to bring forward criticism or bad news will diminish the amount of feedback given.\r\n\r\n* Process   \r\n\r\n> There\u2019s no such thing as a structure or process not existing for people. In the absence of structure and process, people create it or fall back on unspoken existing structures and processes. A common fallacy of tech companies is in thinking that process is bad (usually because they experienced bad process) and that removing process will fix the problem. Instead, it makes it difficult for people to effectively get things done. Worse, it can inadvertently give certain people will more domain knowledge and power that can never be shared with others. Having no process can also allow people with more power to change the process at any time to fit their needs, but does not allow those with lesser power to do the same. The goal is not no process, the goal is good process.\r\n\r\n* Empathy - \r\n *  Weighing people\u2019s emotional problems and experiences more because you understand them.  \r\n\r\n> If people only solve problems that they themselves have experienced, then you get an environment and culture that is tailored to the original core team. Men will never experience gender issues and white people will never experience racial issues, so if white men are the status quo then these problems will not be solved for others in a company without empathy. Empathy involves listening, believing others stories, and understanding them through other people\u2019s experience. It\u2019s common to hear people say we do things this way because in the past I had an experience where we did things another way and it didn\u2019t work, so I learned from it. Empathy is the tool that\u2019s necessary in order to learn from other people\u2019s experiences as well as your own.\r\n",
        "authors": [
            "Kate Heddleston"
        ],
        "conf_key": 99,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/402/",
        "contact": [
            "kate.heddleston@gmail.com"
        ],
        "description": "This talk focuses on how engineering team environments can impact employee behavior, and how environmental factors can prohibit diversity at tech companies. I will talk about some of the key problems that exist in current engineering environments and how they can be fixed.",
        "duration": 30,
        "end": "2015-04-11T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "How our engineering environments are killing diversity (and how we can fix it).",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T10:50:00",
        "tags": ""
    },
    {
        "abstract": "Which tests are worth writing and which aren't? Chasing complete coverage is a waste of effort, and leads you to write bad tests. I'll describe two kinds of bad tests and show examples, and I'll share my principles for designing good tests. By choosing where to focus your efforts, and importantly where not to test, you can achieve a high degree of confidence in the correctness of your code without sacrificing speed, or risking unreliable tests.\r\n\r\nNext we will examine in detail the question of test assertions. The best tests assert about every possible output from a function or class under test, right? Of course it's important to thoroughly test your code. I will demonstrate how to structure tests so that failures point you immediately in the direction of the issues in your codebase, and how to use good object-oriented principles to make your tests serve as both readable and executable documentation of your code's behavior.\r\n\r\nFinally, we will examine the thorniest of testing scenarios, the infamous integration test. Many Python programmers favor the Mock library, which, if used carefully, is indeed a powerful tool. It should be considered an advanced weapon in your testing toolkit, to be used only sparingly and with great care, for mocking carries with it great risks: you might end up testing nothing! I'll show how to avoid the risks of overly-magic testing, and where parts of the Mock library are safe.",
        "authors": [
            "Dan Crosta"
        ],
        "conf_key": 100,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/409/",
        "contact": [
            "dcrosta@late.am"
        ],
        "description": "In a highly dynamic language like Python, testing is even more critical than in compiled or more static languages. Like any other code we produce, tests can be either good or bad. This talk explores three fallacies of testing, and the mistakes and bad habits these fallacies encourage; and shows how to write good tests which help assure proper behavior without impeding development progress.",
        "duration": 30,
        "end": "2015-04-11T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Good Test, Bad Test",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T10:50:00",
        "tags": ""
    },
    {
        "abstract": "Interest and activity in childhood computing education continues to grow on all fronts, from government-sponsored initiatives to our own Python community.  Finding age-appropriate materials and environments that are educational and motivating has always been a challenge, especially for younger coders. Meanwhile, Minecraft has become a massive cultural phenomenon, capturing the hearts and minds of our youth. Many millions of hours have been spent in Minecraft, shaping and crafting worlds and capturing the imaginations of its players. It stands out as a fun, motivating platform that encourages exploration and play. \r\n\r\nThis talk will discuss the importance of play in education, the basic principles of motivation, and how it relates to teaching programming. How does Minecraft and its virtual environment solve these problems? \r\n\r\nWe will discuss the various tools and methods that can be used to allow Python-based interactions with the Minecraft world. The available Python APIs for Minecraft will be covered along with example curriculum and projects. The tools and environments discussed will cover appropriate requirements for both PC version of Minecraft and Minecraft PI; we will cover how to set up appropriate learning environments for your own use.\r\n\r\nHear about experiences and successes in other communities.\r\n\r\nOutcome: Parents and educators will walk away with an understanding of Minecraft, its capabilities, and its significance in education. They will also learn how to teach Python programming through play within the Minecraft world. Attendees will receive references to materials that can be used to teach Python and steps required to setup learning environments. ",
        "authors": [
            "Kurt Grandis"
        ],
        "conf_key": 161,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/414/",
        "contact": [
            "kgrandis@gmail.com"
        ],
        "description": "Interest and activity in childhood computing education continues to grow. Meanwhile, Minecraft has become a massive cultural phenomenon as a fun, motivating platform that encourages exploration and play. This talk demonstrates how Python can be used to teach programming while exploring the world of Minecraft. We will cover how to set up learning environments, curricula, and case studies.",
        "duration": 30,
        "end": "2015-04-10T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Exploring Minecraft and Python: Learning to Code Through Play",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-10T10:50:00",
        "tags": ""
    },
    {
        "abstract": "Machine learning is a huge part of modern computing - from Facebook auto-tagging, spam rejection, and Google searches to robotic cars, predictive healthcare, and phones that can warn you about traffic jams before leaving work, machine learning is everywhere. These tools enhance our lives, and understanding what machine learning can (and can't) do is crucial to modern software development.\r\n\r\nThanks to the amazing Python ecosystem, it is not necessary to have deep knowledge of the mathematical techniques and statistics behind machine learning in order to use these algorithms in your daily work or hobby projects. Libraries like pandas, scikit-learn, gensim, and Theano help developers build projects that were previously impossible, and these applications empower our users and can make fundamental improvements to daily life.\r\n\r\nThis talk will show you the why, what, and how of machine learning in Python.",
        "authors": [
            "Kyle Kastner"
        ],
        "conf_key": 119,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/367/",
        "contact": [
            "kastnerkyle@gmail.com"
        ],
        "description": "Machine learning is a crucial part of modern software development. Libraries like pandas, scikit-learn, gensim, and Theano help developers build projects that were previously impossible, and these applications empower our users and can make fundamental improvements in daily life. This talk will show you the why, what, and how of machine learning in Python.",
        "duration": 30,
        "end": "2015-04-10T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Machine Learning 101",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T10:50:00",
        "tags": ""
    },
    {
        "abstract": "Virtually all software systems have security issues. They affect teams of every experience level and systems at every scale, and their effects can be anywhere from minute to disastrous. After all: we know that in most fields, striving for zero defects is simply unrealistic; if you accept that some of those defects affect security, striving for zero security issues is unrealistic as well.\r\n\r\nLike all other bugs, saying that they are unavoidable doesn't absolve us from responsibility. We still ought to limit them, both in number and in impact.\r\n\r\nWhile we have many tools for limiting generic defects, we don't have much in terms of a rigorous approach to handling security problems. This is partially because the tools we have don't necessarily apply.  Additionally, as an industry, we have historically not given information security the attention it deserves. This is the case from many different angles, including engineering, business, and education.\r\n\r\nAs more and more serious breaches of security become publicly visible, information security is increasingly on everyone's mind.\r\n\r\nPut together, this means that while we ought to be taking these problems seriously, we systematically don't -- and, even when we do, we're ill-equipped to do so. This talk deals with that problem.",
        "authors": [
            "lvh"
        ],
        "conf_key": 95,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/342/",
        "contact": [
            "_@lvh.io"
        ],
        "description": "How do you build secure software? Why do we see bad security track records in projects that otherwise seem to tick all the right engineering boxes? Why is communicating about security issues so painful? More importantly: how can we do all of these things better?",
        "duration": 30,
        "end": "2015-04-10T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Building secure systems",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T10:50:00",
        "tags": ""
    },
    {
        "abstract": "## Identity\r\nFirst, we'll look at some common CPython gotchas involving object identity. We'll try to guess the value of various `is` statements, and then see what the actual value is.\r\n\r\nThen, we'll discuss why some of these statements evaluate to `True` and others `False`, and how object identity differs from equality. We'll discuss some implementation details of CPython, and how they lead to `is` evaluating differently for integers between -5 and 256 and integers outside that range.\r\n\r\nFinally, we'll cover some quick practical tips about how to avoid bugs resulting from using the `is` statement.\r\n\r\n## Mutability\r\nAgain, we'll look at some common Python gotchas, this time caused by mutability.\r\n\r\nThen, we'll investigate which common Python objects are mutable and which aren't, which operations mutate Python objects, and what happens when you mutate an object. In the case of mutable default arguments, we'll even see how we can mutate the default argument from outside the function body using some internals that Python exposes to us.\r\n\r\nWe'll end this section by discussing some practical tips on how to avoid bugs due to mutability, how to make real copies, and a common alternative to using mutable default arguments.\r\n\r\n## Scope\r\n\r\nFirst we'll see some examples of Python name resolution, and we'll try to guess what object the name is bound to, if any, with some surprising results.\r\n\r\nAfter seeing some examples, we'll investigate how the Python interpreter does name resolution, and we'll explore the meaning of the cryptic `UnboundLocalError`.",
        "authors": [
            "Amy Hanlon"
        ],
        "conf_key": 159,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/384/",
        "contact": [
            "amyehanlon@gmail.com"
        ],
        "description": "Many of us have experienced a \"wat\" in Python - some behavior that totally mystifies us. We'll look at three areas where wats arise - identity, mutability, and scope. For each of these three topics, we'll look at some common surprising behaviors, investigate the cause of the behaviors, and cover some practical tips on how to avoid related bugs.",
        "duration": 30,
        "end": "2015-04-11T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Investigating Python Wats",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T10:50:00",
        "tags": ""
    },
    {
        "abstract": "Twenty-odd years ago, industry windbags proclaimed that the golden age of reusable software components was around the corner, thanks to the miracle cure of object-oriented programming languages. This kind of magical thinking led, in a long roundabout way, to atrocities like AbstractSingletonProxyBeanFactory (don't ask: it's a Java thing).\r\n\r\nBut reusable code is not an impossible objective, just a difficult one. After a couple of decades of trying, often successfully, to write good reusable code, I've learned a few useful tricks. If you've ever wondered whether you should write a class or a function, or when side effects are appropriate, or how much testing is enough, this is the talk for you.",
        "authors": [
            "Greg Ward"
        ],
        "conf_key": 116,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/338/",
        "contact": [
            "greg@gerg.ca"
        ],
        "description": "Learning to write high-quality, reusable code takes years of dedicated work. Or you can take a shortcut: attend this talk and learn some of the tricks I've figured out over a couple of decades of programming.",
        "duration": 30,
        "end": "2015-04-11T11:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "How to Write Reusable Code",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T10:50:00",
        "tags": ""
    },
    {
        "abstract": "We will first explain the basics of ansible common usage ( ie, using yaml playbook for configuration management and orchestation ). Then, we will explore the plugins and modules systems, showing what can be extended from inventory, connexion and modules, and how people can add their own python code in the mix. Then we will conclude by looking at Ansible own API, to write specific code that reuse it to run on several systems.",
        "authors": [
            "Michael Scherer"
        ],
        "conf_key": 139,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/368/",
        "contact": [
            "mscherer+pycon2014@redhat.com"
        ],
        "description": "Ansible is a configuration management tool whose primary mode of operation involve using YAML to describe deployments and operations. However, it can do much more and be extended using python, which is what we will explore in this talk. Among others, we will see the plugins system for various part of the tool and how to reuse Ansible in a script.",
        "duration": 30,
        "end": "2015-04-11T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Ansible beyond YAML",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T11:30:00",
        "tags": ""
    },
    {
        "abstract": "Aviation has one of the best approaches to safety and accident response in the world - and programming has some of the worst. Blame culture, lack of testing, numerous deadlines and  failing to plan the worst cases mean that software design and runtime problems are a routine thing, rather than a freakish occurrence.\r\n\r\nAs a private pilot, I was thrust into the world of aviation over three years ago, and the difference to software development was immediately obvious - and there are many things we can take away. Learn about:\r\n\r\n* Why aviation accidents happen, and how the causes relate to software\r\n* How to start eradicating blame culture and empower junior developers\r\n* How hard failure is preferable to soft failure\r\n* How to test your software without breaking the bank\r\n* Why too much noisy logging is worse than none at all\r\n* Why ops people are basically doing the same job as pilots\r\n\r\nPlus, there'll be some revealing discussion of how aviation works, and some pictures of planes. Who doesn't like those?",
        "authors": [
            "Andrew Godwin"
        ],
        "conf_key": 106,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/375/",
        "contact": [
            "andrew@aeracode.org"
        ],
        "description": "What can Python-based software teams learn from aviation? Why should software always fail hard? What's wrong with too many error logs? And why are ops people already like pilots? Learn all this, and about planes, too.",
        "duration": 30,
        "end": "2015-04-10T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "What can programmers learn from pilots?",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T11:30:00",
        "tags": ""
    },
    {
        "abstract": "The goal of static code analysis is to generate useful insights from code without actually executing it. In the talk I will explain how tools for static analysis of Python code work and which challenges we face when analyzing code in such a highly dynamic scripting language. I will give an overview of currently available tools for static analysis and show some of their use cases and limitations. I will then explain how we can make use of publicly available source code and user-provided examples of code errors to improve the quality of our analysis results and learn to detect new types of errors.\r\n",
        "authors": [
            "Andreas Dewes"
        ],
        "conf_key": 111,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/341/",
        "contact": [
            "andreas.dewes@googlemail.com"
        ],
        "description": "Static code analysis is an useful tool that can help to detect bugs early in the software development life cycle. I will explain the basics of static analysis and show the challenges we face when analyzing Python code. I will introduce a data-driven approach to code analysis that makes use of public code and example-based learning and show how it can be applied to analyzing Python code.",
        "duration": 30,
        "end": "2015-04-11T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Learning from other's mistakes: Data-driven analysis of Python code",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T11:30:00",
        "tags": ""
    },
    {
        "abstract": "When faced with a new or complicated code base, \"Finding your groove\" can feel like the sound of fingernails on a chalkboard or a toddler banging on pots and pans. It's often frustrating and headache inducing to hear jargon filled talks, like generator blah blah stdlib blah venv blah calloc blah Rietveld blah rebase blah deprecate. Can't I just bury my head in a quilt of old PyCon t-shirts and hibernate until CPython 42.0 is released? \r\n\r\nThe famous bridge keeper scene from Monty Python helps guide us:\r\n\r\n    What is your name?\r\n        Sir Doc-a-lot of Test-a-lot \r\n    What music do you like?\r\n        Jazz \r\n    What is your quest?\r\n        To find the holy CPython commit. \r\n\r\nSeriously, the path over the bridge to contributing and productivity in CPython can be crossed.  Yes, there's a way to make sense of CPython with confidence and productivity. How? Let jazz music guide you to:\r\n\r\n - commit\r\n - jump into it\r\n - find a rhythm\r\n - improvise\r\n - celebrate\r\n\r\nThis talk will help break down the complex and sometimes cloudy process of contributing to CPython (or your favorite codebase) by helping you:\r\n\r\n 1.  demystify the CPython contribution process;\r\n 2. find quality resources and help;\r\n 3. identify a suitable issue to work on;\r\n 4. master the non-linear contribution process;\r\n 5. succeed as a contributor.\r\n\r\nYou will leave this talk with concrete resources to get started, to consult as your experience grows, and to pass along to others in your travels.\r\n\r\n",
        "authors": [
            "Carol Willing"
        ],
        "conf_key": 123,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/379/",
        "contact": [
            "willingc@willingconsulting.com"
        ],
        "description": "Do you hear a jumble of jargony noise when reading Python mailing lists? Do you silently edit your dotfiles and playlists to avoid asking questions on IRC? Come see how Jazz can help you understand and contribute to Python. While both seem vast and complex, they build on simple concepts. By mixing art, knowledge, and improv, you can find your CPython contribution groove and enjoy cool cats' music.",
        "duration": 30,
        "end": "2015-04-11T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Finding Your Groove: Contributing to CPython and Beyond",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T11:30:00",
        "tags": ""
    },
    {
        "abstract": "Shakespeare is the greatest writer in the English language. But what makes him perfect for an illustration of what Python can do with text? Simple: he\u2019s already been extensively marked up in XML, so we can jump right into the good stuff. While we\u2019ll be mostly using Shakespeare in this talk, we\u2019ll make sure to see how our techniques can easily apply to other sorts of texts, like tweets or newspaper articles.\r\n\r\nAfter a brief conversation about the usefulness of metadata, the talk will concern itself with two main sections: classification and informational entropy. First, we\u2019ll explore how to find distinguishing features between kinds of texts and to use this data to classify other texts. For entropy--which is roughly a measure of randomness--we\u2019ll look at unexpected, and therefore information-rich, parts of Shakespeare\u2019s works.",
        "authors": [
            "Adam Palay"
        ],
        "conf_key": 124,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/339/",
        "contact": [
            "adampalay@gmail.com"
        ],
        "description": "This talk will give an introduction to text analysis with Python by asking some questions about Shakespeare and discussing the quantitative methods that will go in to answering them. While we\u2019ll use Shakespeare to illustrate our methodologies, we\u2019ll also discuss how they can be ported over into more 21st century texts, like tweets or New York Times articles.",
        "duration": 30,
        "end": "2015-04-10T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "\"Words, words, words\": Reading Shakespeare with Python",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-10T11:30:00",
        "tags": ""
    },
    {
        "abstract": "In this talk we'll explain what happens behind the scenes when we try to establish a secure connection to a web site. \r\n\r\nWe'll cover the common security flaws in popular TLS implementations like OpenSSL, and see how these issues can be avoided if we have a good well-designed TLS implementation in a high level language like Python. \r\n\r\nFinally, we'll discuss how the API design of OpenSSL leads to application bugs, and a lack of abstract secure defaults leads to insecure applications.",
        "authors": [
            "Ashwini Oruganti"
        ],
        "conf_key": 135,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/372/",
        "contact": [
            "ashwini.oruganti@gmail.com"
        ],
        "description": "Given recent increases in hostile attacks on internet services and large scale surveillance operations by certain unnamed government organizations, security in our software is becoming ever more important. We'll give you an idea of how modern crypto works in web services and clients, look at some of the common flaws in these crypto implementations, and discuss recent developments in TLS.",
        "duration": 30,
        "end": "2015-04-10T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Introduction to HTTPS: A Comedy of Errors",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T11:30:00",
        "tags": ""
    },
    {
        "abstract": "Why would you need to experiment if it's pure mathematics? Don't you just spend your whole day writing down complicated computations using weird symbols and popping theorems out of your head?\r\nThis talk is here to show you that pure mathematics is not always like this. We're going to explore some combinatorics questions like \"how many binary trees of size 42 are there?\" or \"What does a random binary tree of size 1000 looks like?\" and see how computer exploration plays an essential role in finding and proving new results.\r\nDoing so, we'll see what kind of code and structure we use and understand the aim of pure mathematical programming. All examples will be written in python using the mathematical software Sage. So this is also an occasion to discover about Sage through actual research based examples and demo.\r\nNo previous Sage or mathematical knowledge is needed.",
        "authors": [
            "Viviane Pons"
        ],
        "conf_key": 136,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/354/",
        "contact": [
            "viviane.pons@lri.fr"
        ],
        "description": "Pure mathematics is not always big formulas written on endless notebooks, it can also be hidden behind python code. In combinatorics, we study classical computer science objects like trees or graphs with a mathematical perspective. This talk aims to show how computer exploration and experimentation can be used to discover and prove new mathematical results.",
        "duration": 30,
        "end": "2015-04-10T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Experimental pure mathematics using Sage",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T11:30:00",
        "tags": ""
    },
    {
        "abstract": "PyPy.js is an experiment in building a fast, compliant, in-browser python interpreter. By compiling the PyPy interpreter into javascript, and retargeting its JIT compiler to emit asmjs code at runtime, it is possible to run python code in the browser at speeds competitive with a native python environment. This talk will demonstrate the combination of technologies that make such a thing possible, the results that have been achieved so far, and the challenges that still remain when trying to take python onto javascript's home turf.\r\n\r\nWe'll cover: an overview of PyPy and why it's a good fit for this type of project; an introduction to asmjs and the rise of javascript as a compile target; what it looks like when you smoosh these two technologies together; a comparison with other approaches such as brython and PythonJS; and some concrete suggestions for how the result might be useful in practice.",
        "authors": [
            "Ryan Kelly"
        ],
        "conf_key": 172,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/385/",
        "contact": [
            "ryan@rfk.id.au"
        ],
        "description": "PyPy.js is an experiment in building a fast and compliant in-browser python interpreter, by compiling PyPy into javascript and retargeting its JIT to emit javascript code at runtime. This talk will demonstrate the combination of technologies that make such a thing possible, the results achieved so far, and the challenges that still remain when taking python onto javascript's home turf.",
        "duration": 30,
        "end": "2015-04-10T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "PyPy.js: What? How? Why?",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-10T11:30:00",
        "tags": ""
    },
    {
        "abstract": "While everyone agrees that usability testing should be an important part of your development process, not everyone has enough money laying around to pay for a dedicated team or consultants. In this talk, Katie will review a number of inexpensive options that can help any team deliver a usable product. \r\n\r\nThe purpose of this talk is not to demeen the field of usability experts (if you have the money, you should hire some!), but to help those who are working on a shoe-string budget make better websites. Not every team can afford weeks (and sometimes months) of focused user surveys and specialized observation, but most can afford a pack of index cards and a few pieces of inexpensive software.\r\n\r\nThe audience will walk away not only with an idea of why they might want to do usability testing, but also how they can run a few small-scale studies themselves. These will help them pick the right design, organize their site in a logical manner, and tweak their application as time goes on and their needs change.",
        "authors": [
            "Katie Cunningham"
        ],
        "conf_key": 162,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/356/",
        "contact": [
            "katie.fulton@gmail.com"
        ],
        "description": "While everyone agrees that usability testing should be an important part of your development process, not everyone has enough money laying around to pay for a dedicated team or consultants. In this talk, Katie will review a number of inexpensive options that can help any team deliver a usable product.",
        "duration": 30,
        "end": "2015-04-11T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Usability Testing on the Cheap",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T11:30:00",
        "tags": ""
    },
    {
        "abstract": "This talk explains the basics of what happens when you start a Python interpreter from a command prompt. It covers the following topics:\r\n\r\n - What a process ID is.\r\n - What it means to forking a subprocess, and what environment variables are.\r\n - How $PATH affects what your shell does.\r\n - The underlying meaning of shell quoting.\r\n - The difference between three ways to exit Python: exit(), ^C, and ^D.\r\n\r\n",
        "authors": [
            "Philip James",
            "Asheesh Laroia"
        ],
        "conf_key": 160,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/340/",
        "contact": [
            "pjj@philipjohnjames.com",
            "asheesh@asheesh.org"
        ],
        "description": "This talk discusses how the Python interpreter starts, from the perspective of the operating system (OS). Together, we will see the ins & outs of processes: fork(), exec(), stdin, and stdout.\r\n\r\nIt focuses on OS concepts and requires no background knowledge, using analogies to Python data structures. (The talk does not discuss Python\u2019s own initialization, such as site.py or global variables.)",
        "duration": 30,
        "end": "2015-04-11T12:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Type python, press enter. What happens?",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T11:30:00",
        "tags": ""
    },
    {
        "abstract": "HTTP is the most successful application-layer network protocol of all time. The vast majority of network traffic today is either transmitted using HTTP or by protocols associated with it. It is ubiquitous: so much so that the 'world wide web', the network of systems that speak HTTP, is for many people totally synonymous with the Internet.\r\n\r\nIn part because of its success, HTTP is also quite old. The current revision, HTTP/1.1, was originally standardised in 1999. This was an era in computing quite unlike the current one. For perspective, Napster was originally released in 1999, and Google was only one year old. The web was totally unlike what we have now: pages were small and carried relatively little non-textual data, computers were relatively weak, and the mobile data plan was unheard of.\r\n\r\nHTTP/1.1 was designed for a world that no longer exists. We need an update.\r\n\r\n#### HTTP/2: A New Era\r\n\r\nInto this void stepped the Internet Engineering Task Force. In 2012, the HTTPBis Working Group of the IETF, tasked with ensuring that HTTP continues to grow, began discussing a new version of the protocol.\r\n\r\nNow, three years later, HTTP/2 is the end result. It's a protocol with a unique position in the history of computer networks. Its goal: to bring the web into the 21st century, without breaking anything that already worked. These two competing goals make HTTP/2 an intriguing entry in the catalogue of network protocols.\r\n\r\nThe final standard was delivered early in 2015, and with the delivery of this standard will come a flurry of activity as web developers and consumers get used to the new tool driving the web. Work will begin on subsidiary standards like WSGI and WebSockets, and developers will start finding new ways to push the web ever-faster. It's an exciting time.\r\n\r\n#### This Talk\r\n\r\nThis talk will cover HTTP/2 at a high level. We'll talk about how we got here. We'll talk about the problems of HTTP/1.1, and how HTTP/2 aims to address them. We'll talk about the ways in which HTTP/2 is imperfect, and how those imperfections came to be. And finally, we'll talk about how you can get started using HTTP/2 with your Python code, giving you a head start on this exciting new protocol.",
        "authors": [
            "Cory Benfield"
        ],
        "conf_key": 170,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/361/",
        "contact": [
            "cory@lukasa.co.uk"
        ],
        "description": "The internet has spoken, HTTP is to get its first serious update in 15 years. In this talk we'll discuss what HTTP/2 is, why it's happening, and how it's going to affect you and everyone you love. We'll briefly talk about how you can get started with HTTP/2, and some interesting projects associated with it, including Hyper, the first Python HTTP/2 library.",
        "duration": 30,
        "end": "2015-04-10T12:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Hyperactive: HTTP/2 and Python",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-10T12:10:00",
        "tags": ""
    },
    {
        "abstract": "Using examples from real-code, show what really matters to make code readable and maintainable.\r\n\r\nLearn how to leverage Python's toolset for maximum effect (named tuples, keyword arguments, doctests, decorators, content managers, properties, modules, packages, logging, and exception handlers). \r\n\r\nAvoid the hazards associated with a too shallow interpretation of PEP 8 and instead use it to nudge yourself toward consistent, nice-looking, clear code.",
        "authors": [
            "Raymond Hettinger"
        ],
        "conf_key": 127,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/416/",
        "contact": [
            "python@rcn.com"
        ],
        "description": "Distillation of knowledge gained from a decade of Python consulting, Python training, code reviews, and serving as a core developer.   Learn to avoid some of the hazards of the PEP 8 style guide and learn what really matters for creating beautiful intelligible code.\r\n\r\n",
        "duration": 45,
        "end": "2015-04-10T12:55:00",
        "kind": "talk",
        "license": "CC",
        "name": "Beyond PEP 8 -- Best practices for beautiful intelligible code",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T12:10:00",
        "tags": ""
    },
    {
        "abstract": "Every programming language works similarly to others, and differently than others.  Python is no exception.  Its mechanisms for supporting variables have an underlying simplicity, but preconceptions from other languages can obscure their true behavior.\r\n\r\nStarting from \"x = 23\", we'll cover how Python names and values work together to provide variables.  Along the way, we'll touch on immutability, containers, reference counting, sharing, copying, the diversity of assignment, dynamic typing, and a tiny bit of chess.\r\n\r\n",
        "authors": [
            "Ned Batchelder"
        ],
        "conf_key": 110,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/362/",
        "contact": [
            "ned@nedbatchelder.com"
        ],
        "description": "The behavior of names and values in Python can be confusing. Like many parts of Python, it has an underlying simplicity that can be hard to discern, especially if you are used to other programming languages. Here I'll explain how it all works, and present some facts and myths along the way.  Call-by-reference? Call-by-value? The answer will be clear!",
        "duration": 30,
        "end": "2015-04-11T12:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Facts and Myths about Python names and values",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T12:10:00",
        "tags": ""
    },
    {
        "abstract": "How does Yelp decide which relevant business or service to show you as an ad within 100 milliseconds of your visit? What are the criteria and metrics by which we measure success of our ad serving system?\r\n\r\nIn this talk, the audience will learn about how Yelp figures out the best ad to show a user during his visit to Yelp: via a 2nd price auction amongst all the matching advertisers. Powering this 2nd price auction is a Machine Learning based system that predicts Click Through Rates (CTR) for all ads and an Auto-Bidding system that determines the optimal bid price for each ad per user request.\r\n\r\nYelp's local advertising presents challenges that are unique compared to display, social or mobile advertising. I'll motivate this via some trends and data observations. One of the interesting aspects is business categories and geolocation: How far are people willing to travel to visit a restaurant? What about professional services like plumbers: are users less or more sensitive to how far those are compared to restaurants?\r\n\r\nI'll provide examples of how we use our open-sourced Map Reduce package (MRJob) to scale ML feature engineering and performance metric computation. I'll also provide details on our Machine Learning pipeline built using the popular python packages: numpy, scipy and sklearn.\r\n\r\nThis talk would give you an in-depth overview of advertising systems, and why with increasingly sophisticated ad systems, in future we will wonder why we ever hated ads!",
        "authors": [
            "Soups Ranjan"
        ],
        "conf_key": 107,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/396/",
        "contact": [
            "soups.ranjan@gmail.com"
        ],
        "description": "This talk would give you an in-depth overview of Real-Time Bidded (RTB) advertising systems, and why with increasing sophistication in ad-tech, in the future we will wonder why we ever hated ads. In particular, this talk will discuss technical challenges in ad systems and how we use Computational Advertising and Data Science to solve problems around Click Through Rate (CTR) Prediction, Auto-Bidding systems, Traffic Prediction, etc.",
        "duration": 45,
        "end": "2015-04-10T12:55:00",
        "kind": "talk",
        "license": "CC",
        "name": "Data Science in Advertising: Or a future when we love ads",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T12:10:00",
        "tags": ""
    },
    {
        "abstract": "Are you interested in open source, but having difficulty getting started?  Do you maintain a project that can\u2019t seem to find new contributors?\r\n\r\nThis talk will cover some of the most common \u201cfailure modes\u201d of open source contributing, from the technical to the interpersonal.  Drawing from my experience organizing and running dozens of newcomer workshops, and using examples from various open source python projects, I\u2019ll show you:\r\n\r\n - How to make good matches between newcomers and projects\r\n - How to create and identify good first tasks for new contributors\r\n - How to ease the pain of setting up development environments\r\n - How to make time to contribute and mentor\r\n - How to overcome impostor syndrome and how to make a welcoming community atmosphere\r\n\r\nThroughout the talk, I\u2019ll emphasize several themes.  \r\n\r\nFirst: open source contributing can be hard.  Whether you\u2019re a newcomer struggling to install a project or a maintainer who doesn\u2019t know what to say when someone asks how they can help, it\u2019s not your fault, and you\u2019re not alone.  We can work together to make it easier.\r\n\r\nSecond: open source is full of implicit knowledge that needs to be made explicit.  That may mean documenting your toolchain, telling a maintainer what skills you\u2019d like to work on, or setting expectations on how much time you have to work with someone.  In open source, there\u2019s seldom too much information.\r\n\r\nFinally: every contribution has value.  Newcomers can contribute in meaningful ways from the moment they join a project, though perhaps not always in the ways they imagined.  Let\u2019s encourage every kind of contribution and help ourselves become a bigger, more diverse, and more vibrant community!",
        "authors": [
            "Shauna Gordon-McKeon"
        ],
        "conf_key": 157,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/346/",
        "contact": [
            "shaunagm@gmail.com"
        ],
        "description": "Open source can be fun and rewarding, but it can also be intimidating.  This talk addresses some of the biggest technical and psychological barriers to contributing, from the perspective of both the newcomers who want to overcome them and the maintainers who want to remove them.",
        "duration": 45,
        "end": "2015-04-11T12:55:00",
        "kind": "talk",
        "license": "CC",
        "name": "Open Source for Newcomers and the People Who Want to Welcome Them",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T12:10:00",
        "tags": ""
    },
    {
        "abstract": "The Walt Disney Animation Studios has a long history of creating acclaimed animated films and continues to be an industry leader with regards to artistic achievements, storytelling excellence, and cutting-edge innovations.   Since the 1923 release of Snow White they\u2019ve been pushing forward technology in the art of movie making.  This push continues in the modern day with classics such as Oscar winning box office hit \u201cFrozen\u201d and Oscar nominated hits \u201cWreck-It Ralph\u201d, \u201cTangled\u201d, \u201cBolt\u201d, \u201cTreasure Planet\u201d, and \u201cDinosaur\u201d.\r\n\r\nOne of the most common questions we get when attending PyCon is \u201cWhy are you here?\u201d \u00a0People seem confused that technology, especially Python is used in the making of animated films. \u00a0\r\n\r\nTo dive into exactly where Python is used without context would be confusing so Paul will give the audience some background on the Walt Disney Animation Studios. \u00a0He will talk about what we\u2019ve done and what we are currently working on. \r\n\r\nThe main part of the talk is describing the production process whilst imparting this information he will interject where technology and specifically Python comes into play. \u00a0\u00a0He will describe the tools in each area and the tech stack used to create them.\r\n\r\nHe will wrap up the talk with describing how our Studio is organized, how we develop software, and venues we use to share our technology with others.",
        "authors": [
            "Paul Hildebrandt"
        ],
        "conf_key": 105,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/365/",
        "contact": [
            "paul.hildebrandt@disneyanimation.com"
        ],
        "description": " Paul will take you through the process of making of a Disney movie. \u00a0He will use examples from Big Hero 6 to explain and illustrate the steps in making a movie and explain where\u00a0technology, specifically Python, is involved. \u00a0",
        "duration": 45,
        "end": "2015-04-10T12:55:00",
        "kind": "talk",
        "license": "CC",
        "name": "Inside the Hat: Python @ Walt Disney Animation Studios",
        "released": false,
        "room": "Room 517D",
        "start": "2015-04-10T12:10:00",
        "tags": ""
    },
    {
        "abstract": "TLS is the most widely used protocol for securing TCP connections. We start with the history of TLS and an overview of its features. The core of the talk is devoted to describing how TLS provides two fundamental security properties: confidentiality and authentication. We discuss the use of X.509 certificates as well as the numerous ciphers and cryptographic algorithms TLS supports. Along the way, we see how TLS support in the Python standard library has improved dramatically in the last year and how to properly use it.",
        "authors": [
            "Benjamin Peterson"
        ],
        "conf_key": 179,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/347/",
        "contact": [
            "benjamin@python.org"
        ],
        "description": "TLS is the industry standard for secure networking. This talk will give an overview of the TLS protocol and demonstrate how to create secure connections with the standard library's ssl module.",
        "duration": 30,
        "end": "2015-04-10T12:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "A Dive into TLS",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T12:10:00",
        "tags": ""
    },
    {
        "abstract": "I've worked at many institutions with many programming languages over the past 8 years They all have technical debt. Putting on a band-aid and ignoring the real issues can be disastrous. We'll go through several case studies, review big red flags, and learn how to start chipping away at the problem with confidence. ",
        "authors": [
            "Nina Zakharenko"
        ],
        "conf_key": 181,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/424/",
        "contact": [
            "nzakharenko@gmail.com"
        ],
        "description": "Technical debt is the code monster hiding in everyone's closet. If you ignore it, it will terrorize you at night. To banish it and re-gain your productivity, you'll need to face it head on. ",
        "duration": 45,
        "end": "2015-04-11T12:55:00",
        "kind": "talk",
        "license": "CC",
        "name": "Technical Debt - The code monster in everyone's closet",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T12:10:00",
        "tags": ""
    },
    {
        "abstract": "Test-driven development is a process for writing software that can be safely changed by fallible human beings. Change is inevitable as bugs are found, requirements change and dependencies (operating system, libraries, language) change from under you. Unfortunately as programmers we can only keep so much information in our memory at any given time, not to mention our tendency to make mistakes of every sort. The combination is problematic:\r\n\r\n* How do we know our software does what we think it does?\r\n* How do we change our software without breaking existing functionality?\r\n\r\nIn this talk you'll learn the process of test-driven development (TDD). In TDD the automated tests that will validate the code's correctness are written before the actual code is written. Since the tests will fail before the code is written and pass when it is done we can be sure the code is correct. Since all code has tests we can notice when changes to the code break existing functionality.\r\n\r\nWriting tests before code may seem confusing or difficult but as you will see it's actually fairly simple to do. The talk will break down the process into clear detailed steps, allowing you to start using TDD on your software projects immediately.",
        "authors": [
            "Itamar Turner-Trauring"
        ],
        "conf_key": 155,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/364/",
        "contact": [
            "itamar@itamarst.org"
        ],
        "description": "Software is maintained by humans with limited memory and an unfortunate tendency to make mistakes. Test-driven development (TDD) can help you work around these design flaws by providing a permanent, automated specification for your code. Learn how to implement TDD when bug fixing and implementing new features and how this process will ensure your code is correct both now and in the future.",
        "duration": 45,
        "end": "2015-04-11T12:55:00",
        "kind": "talk",
        "license": "CC",
        "name": "A Beginner's Guide to Test-driven Development",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T12:10:00",
        "tags": ""
    },
    {
        "abstract": "[Docker](https://docker.com/) is an open source, lightweight, virtualized environment for portable applications. With all the buzz it has attracted, it can be hard to figure out exactly what Docker is and what it can do for you. This talk will cover the fundamentals of Docker, why it\u2019s making waves, and how it might be a useful addition to your platform.\r\n\r\nSpecifically, this talk will cover:\r\n\r\n- What Docker is (and what it isn\u2019t) compared to other application deployment techniques\r\n- The fundamental technical features that distinguish Docker from traditional Virtual Machines (VMs) or other containerization techniques\r\n- The basic concepts of Docker (e.g. containers vs. images, Docker Engine vs. Docker Hub)\r\n- Some practical applications of Docker and how it is used in production\r\n- A sample Docker development workflow using a Flask app\r\n- A little Docker history and some predictions about how Docker could affect computing in the future\r\n- Things to consider when evaluating Docker for use in your organization\r\n\r\nThe target audience for this talk is developers with some experience deploying and managing applications who are curious about Docker and how it could benefit their work. Attendees new to Python are welcome, but they will benefit most from this talk if they also have experience deploying software applications in some other language.",
        "authors": [
            "Andrew T. Baker"
        ],
        "conf_key": 130,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/417/",
        "contact": [
            "andrew.tork.baker@gmail.com"
        ],
        "description": "Docker was one of last year\u2019s most talked about open source projects - but what is it? And what does it mean for deploying applications? This talk will explain what Docker is and where it fits in with other deployment techniques. Attendees will learn the fundamentals of Docker, see some practical examples of how Docker is used, and consider if Docker could be a useful addition to their platform.",
        "duration": 30,
        "end": "2015-04-11T12:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Demystifying Docker",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T12:10:00",
        "tags": ""
    },
    {
        "abstract": "Until recently, the only good option for real-time stream processing in Python was to build your own home-grown solution atop worker-and-queue frameworks like [rq][rq] or [celery][celery]. Though these projects are good for distributing workload across Python processes and machines, they do not have built-in mechanisms for message reliability, fault tolerance, or multi-machine cluster management.\r\n\r\nA new open source project that was developed in the last year and has recently hit a major 1.0 milestone, [streamparse][streamparse], finally makes working with real-time data streams easy for Pythonistas. If you have ever wondered how to process tens of thousands of data tuples per second with Python using long-lived processes -- while maintaining fast throughput, high availability, and low latency -- this talk will give you an overview and deep dive.\r\n\r\n## Detailed Talk Overview\r\n\r\n### What is Storm?\r\n\r\n[Apache Storm][storm] is a battle-tested stream processing framework that is already used in production by the likes of Twitter, Spotify, and Wikipedia.\r\n\r\nStorm has been shown to handle 1,000,000 tuples per second per node in benchmarks (reported by Nathan Marz, author of [\"Big Data\"][big-data] by Manning Press). It has also been shown to scale up to 1,200 nodes across a computation cluster (reported by [Twitter][twitter-storm]). In other words, it is good stuff!\r\n\r\nBefore streamparse, using Storm with Python was a bit painful. Fortunately, streamparse makes using Storm easy and Pythonic, in the same way that [mrjob][mrjob] made using Hadoop easy and Pythonic.\r\n\r\n### streamparse components\r\n\r\nstreamparse has four major components:\r\n\r\n1. A command-line tool, `sparse`, that makes creating Python projects that will work with Storm very easy.\r\n2. A Python module, `streamparse`, that implements Storm's multi-lang protocol; we call this the IPC (inter-process communication) layer.\r\n3. Extensions for `Fabric` that allow you to manage a remote cluster of Storm machines, complete with Python dependency management.\r\n4. A thin Java interop layer written in Clojure and accessed with `lein` that makes it possible for you to manage a Storm cluster and compile Storm topologies from the command line; the Java bits are hidden from the streamparse user so they can work in pure Python.\r\n\r\nThese will be covered in the talk.\r\n\r\n### Real-world stream processing\r\n\r\nThis talk will also provide an overview of stream processing challenges, and put this in the context of streamparse's (and Storm's) internal architecture.\r\n\r\nAttendees will be able to use this knowledge to quickly build their own Python-on-Storm topologies, for example implementing a scalable \"real-time word counter topology\" in Python using only a few keystrokes.\r\n\r\nThe talk will conclude by showing how we currently use streamparse, Storm, and [Kafka][kafka] in production to process billions of page views per month of analytics data with sub-second latencies.\r\n\r\n[celery]: http://www.celeryproject.org/\r\n[rq]: http://python-rq.org/\r\n[mrjob]: https://pythonhosted.org/mrjob/\r\n[storm]: https://storm.incubator.apache.org/\r\n[big-data]: http://manning.com/marz/\r\n[streamparse]: https://github.com/Parsely/streamparse \r\n[twitter-storm]: http://dl.acm.org/citation.cfm?id=2595641\r\n[kafka]: http://kafka.apache.org/",
        "authors": [
            "Andrew Montalenti"
        ],
        "conf_key": 117,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/359/",
        "contact": [
            "andrew@parsely.com"
        ],
        "description": "Real-time streams are everywhere, but does Python have a good way of processing them? Until recently, there were no good options. A new open source project, streamparse, makes working with real-time data streams easy for Pythonistas. If you have ever wondered how to process 10,000 data tuples per second with Python -- while maintaining high availability and low latency -- this talk is for you.",
        "duration": 30,
        "end": "2015-04-12T13:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "streamparse: real-time streams with Python and Apache Storm",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-12T13:10:00",
        "tags": ""
    },
    {
        "abstract": "Knowing that your application is up and running is great.  However in order to make informed decisions about the future, you also need to know in what state your application currently is and how its state is developing over time.\r\n\r\nThis talk combines two topics that are usually discussed separately. However I do believe that they have a lot of overlap and ultimately a similar goal: giving you vital insights about your system in production.\r\n\r\nWe'll have a look at their commonalities, differences, popular tools, and how to apply everything in your own systems while avoiding some common pitfalls.",
        "authors": [
            "Hynek Schlawack"
        ],
        "conf_key": 131,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/353/",
        "contact": [
            "schlawack@variomedia.de"
        ],
        "description": "Your Python server applications are running but you\u2019re wondering what they are doing?  Your only clue about their current state is the server load?  Let\u2019s have stroll through the landscape of logging and metrics so you\u2019ll find the perfect fit for your use cases!",
        "duration": 30,
        "end": "2015-04-12T13:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Beyond grep: Practical Logging and Metrics",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-12T13:10:00",
        "tags": ""
    },
    {
        "abstract": "Low level operating system functions such as memory management, shared memory, and how the linux kernel keeps track of process information can seem intimidating to high level Python application developers. This talk will provide a gentle, high level overview of how memory works, and introduce some tools, scriptable in Python, to introspect and play with system memory.\r\n\r\nThis talk will demonstrate that such a tool can be easily used to search process memory and kernel memory for interesting patterns and data.",
        "authors": [
            "Ying Li"
        ],
        "conf_key": 173,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/415/",
        "contact": [
            "cyli@ying.li"
        ],
        "description": "Gumshoes, the rogue program `san_diego.py` is threatening to cause havok!  What is it doing to hide itself?  What kind of things is it doing?  Who might it be communicating with?  RAM is a big place - how can we even find it, much less any of this information? Stay tuned and find out!",
        "duration": 30,
        "end": "2015-04-12T13:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Where in your RAM is \"python san_diego.py\"?",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-12T13:10:00",
        "tags": ""
    },
    {
        "abstract": "Four years after the Arab Spring and two years after the Snowden revelations about NSA spying, it appears that little has changed. We'll answer the question \"what now?\" by remember the ad-hoc activist cluster Telecomix.\r\n\r\nCalled \"Tech Support for the Arab Spring\", Telecomix helped keep Egypt & Syria online, using everything from encryption to dialup modems and fax machines. We helped to catch a US company selling surveillance to dictators, defend journalists against Chicago cops and rally thousands to the streets of Europe against the ACTA copyright treaty. We spend more time hanging out on IRC than is technically healthy.\r\n\r\nThis talk will reflect on lessons learned during last three years of hands-on \"hacktivism\" and explore similarities with the free software community. It's a follow-up to a 2011 Pycon lightning talk given shortly after the Tahrir Square protests.",
        "authors": [
            "Pete Fein"
        ],
        "conf_key": 109,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/332/",
        "contact": [
            "pete@wearpants.org"
        ],
        "description": "Four years after the Arab Spring & 2 years after Snowden, little has changed. What now? This talk will remember Telecomix, an ad-hoc activist cluster that supported free communication around the world. Stories of humans and machines, reflection on 3 years of hacktivism & exploration of similarities to the free software community. It follows a 2011 Pycon lightning talk given after Tahrir Square.",
        "duration": 30,
        "end": "2015-04-12T13:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Free Software, Free People",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-12T13:10:00",
        "tags": ""
    },
    {
        "abstract": "As a web developer, I find myself being asked to make increasing numbers of data visualizations, interactive infographics, and more. d3.js is great, as are many other js toolkits that are out there. But if I can write more Python and less JavaScript... well, that makes me happy!\r\n\r\nBokeh is a new Python library for interactive visualization. Its origins are in the data science community, but it has a lot to offer web developers.\r\n\r\nIn this talk I'll discuss using Bokeh with a web framework (in this case, Django):\r\n\r\n- I will walk through building an interactive visualizations in Bokeh to display your data\r\n- How to unit test your visualization\r\n- How to display your plot on the web and within your templates, including a number of pitfalls I have encountered.\r\n\r\nI will not be covering real-time or high-volume analytics, or any statistical processing. This is an introduction to Bokeh's core, focused on the needs of an average web developer.",
        "authors": [
            "Sarah Bird"
        ],
        "conf_key": 133,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/369/",
        "contact": [
            "sbird@alum.mit.edu"
        ],
        "description": "Interactive data visualization libraries are mostly a JavaScript stronghold. The new Python library, Bokeh, provides a simple, clean way to make more shiny things. Although it comes from the data science community, it has a lot to offer web developers. For a visualization you might have built in d3.js, I'll show how to build it in Bokeh, how to test it, and how to hook it into your web app. ",
        "duration": 30,
        "end": "2015-04-12T13:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Interactive data for the web - Bokeh for web developers",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-12T13:10:00",
        "tags": ""
    },
    {
        "abstract": "PostgreSQL has a reputation as being complex and hard to manage. It is certainly a powerful, capable database able to handle situations from a developer's laptop up to petabyte-sized installations. But that does not mean that only a special priesthood can operate it; any talented developer is capable of keeping a PostgreSQL installation healthy and happy.\r\n\r\nWe'll go through the tasks that encompass 90% of what you'll have to do with PostgreSQL, from installation, through basic server tuning, routine backups and maintenance tasks, basic disaster recovery, though query analysis and tuning, and tips and tricks to get maximum performance out of PostgreSQL. A special focus will be on Python-based ORMs and their proper usage, such as Django and SQL Alchemy.\r\n\r\nWe'll cover special situations, such as hosting on AWS, embedded/appliance environments, and the things you should never, ever do.",
        "authors": [
            "Christophe Pettus"
        ],
        "conf_key": 57,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/328/",
        "contact": [
            "christophe.pettus@pgexperts.com"
        ],
        "description": "PostgreSQL has become the default database for most green-field development projects, and is the data storage architecture behind many major Python-based success stories, such as Instagram. Despite a reputation as being complex and fiddly, Postgres is easy to install, administer, maintain, and use... with just a little bit of orientation. This is that orientation.",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "PostgreSQL Proficiency for Python People",
        "released": true,
        "room": "Room 512EA",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "Ever wondered what all the hubbub was about with Salt or Ansible? Ever wonder how Ansible is different from Fabric or who would win in a grudge match between Thomas and Michael (respective creators of SaltStack and Ansible)?\r\n\r\nIn this tutorial we'll explore three popular tools for remote execution and automation: Fabric, SaltStack, and Ansible. We'll see how they compare to, contrast with, and compliment one another. ",
        "authors": [
            "G. Clifford Williams"
        ],
        "conf_key": 55,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/331/",
        "contact": [
            "gcw-pycon@notadiscussion.com"
        ],
        "description": "Epic, knock down, drag-out, death match of python automation tools. Ok, not really.\r\n\r\nThis class will take an in depth look at three automation, orchestration, and remote execution frameworks written in Python. ",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Fabric, SaltStack, and Ansible: DevOps'ing with Python",
        "released": true,
        "room": "Room 512CG",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "I will walk through the practicalities of building a simple video game from scratch, starting with presenting one approach to structuring the game code to keep it sane. I will talk about what libraries are available and then focus on the facilities present in the library used in the tutorial.\r\n\r\nI will then walk through the development of a simple game during which the attendees will code the game. Once the game is developed I will talk about potential further development that possibilities and use the remaining tutorial time to encourage and assist attendees in their efforts to do so.\r\n\r\nThe game developed will cover the key game-writing skills of controlling what appears on the screen (including tile mapping and animation), loading resources, handling user input and simulating the environment within the game. There will be demonstrations and discussion of the various tools that may be used to create game assets (tile maps, sprites and sound effects.)\r\n\r\nThe tutorial will also cover packaging the game for distribution both via PyPI and as a stand-alone executable. This includes the mobile platforms Android and iOS.",
        "authors": [
            "Richard Jones"
        ],
        "conf_key": 31,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/314/",
        "contact": [
            "richard@python.org"
        ],
        "description": "This tutorial will walk the attendees through development of a simple game using Kivy with time left over for some experimentation and exploration of different types of games.",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Introduction to game programming with Kivy",
        "released": true,
        "room": "Room 510B",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "In many ways Python is very similar to other programming languages.  However, in a few subtle ways it is quite different, and many software developers new to Python, after their initial successes, hit a plateau and have difficulty getting past it.  Others don't hit or perceive a plateau, but still find some of Python's features a little mysterious or confusing.  This tutorial will help deconstruct some common incorrect assumptions about Python.\r\n\r\nIf in your use of Python you sometimes feel like an outsider, like you're missing the inside jokes, like you have most of the puzzle pieces but they don't quite fit together yet, or like there are parts of Python you don't understand, this may be a good tutorial for you.\r\n\r\nAfter completing this tutorial you'll have a deeper understanding of many Python features.  Here are some of the topics we'll cover:\r\n\r\n- How objects are created and names are assigned to them\r\n\r\n- Ways to modify a namespace: assignment, import, function definition and call, and class definition and instantiation.  Much of the tutorial is structured around namespaces and ways to change them to help you understand most of the differences between variables in other languages and Python, including\r\n\r\n    - why Python has neither pass-by-value nor pass-by-reference function call semantics,\r\n\r\n    - and why parameters passed to a function can sometimes be changed by it and sometimes cannot.\r\n\r\n- Iterables, iterators, and the iterator protocol, including how to make class instances iterable\r\n\r\n- How to use generators to make your code easier to read and understand\r\n\r\n- Hacking classes after their definition, and creating classes without a class statement, as an exercise to better understand how they work\r\n\r\n- Bound versus unbound methods, how they're implemented, and interesting things you can do with bound methods\r\n\r\n- How and why you might want to create or use a partial function\r\n\r\n- Example use-cases of functions as first-class objects\r\n\r\n- Unpacking and packing arguments with * and ** on function call and definition\r\n",
        "authors": [
            "Stuart Williams"
        ],
        "conf_key": 54,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/297/",
        "contact": [
            "stugoo@gmail.com"
        ],
        "description": "This tutorial is for developers who've been using Python for a while and would consider themselves at an intermediate level, but are looking for a deeper understanding of the language.  It focuses on how Python differs from other languages in subtle but important ways that are often confusing, and it demystifies a number of language features that are sometimes misunderstood.",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Python Epiphanies",
        "released": true,
        "room": "Room 510D",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "IPython started in 2001 simply as a better interactive Python shell. Over the last decade it has grown into a powerful set of interlocking tools that maximize developer productivity in Python while working interactively.\r\n\r\nToday, Jupyter consists of an IPython kernel that executes user code, provides many features for introspection and namespace manipulation, and tools to control this kernel either in-process or out-of-process thanks to a well specified communications protocol implemented over ZeroMQ. This architecture allows the core features to be accessed via a variety of clients, each providing unique functionality tuned to a specific use case:\r\n\r\n- An interactive, terminal-based shell with capabilities beyond the default Python interactive interpreter (this is the classic application opened by the `ipython` command that most users are familiar with).\r\n\r\n- A [graphical, Qt-based console](http://ipython.org/ipython-doc/stable/interactive/qtconsole.html) that provides the look and feel of a terminal, but adds support for inline figures, graphical calltips, a persistent session that can survive crashes of\r\nthe kernel process, and more. A user-based review of some of these features can be found here.\r\n\r\n- A [web-based notebook](http://ipython.org/notebook.html) that can execute code and also contain rich text and figures, mathematical equations and arbitrary HTML. This notebook presents a document-like view with cells where code is executed but that can be edited in-place, reordered, mixed with explanatory text and figures, etc. The notebook provides an interactive experience that combines live code and results with literate documentation and the rich media that modern browsers can display:\r\n\r\n![Notebook screenshot](http://i.imgur.com/eo2SqS9.png)\r\n\r\n- A high-performance, low-latency system for [parallel computing](http://ipython.org/ipython-doc/stable/parallel/parallel_intro.html) that supports the control of a cluster of IPython engines communicating over ZeroMQ, with optimizations that minimize unnecessary copying of large objects (especially numpy arrays). These engines can be controlled interactively while developing and doing exploratory work, or can run in batch mode either on a local machine or in a large cluster/supercomputing environment via a batch scheduler.\r\n\r\nThese tools also increasingly work with languages other than Python, and we are renaming the language independent frontend components to *Jupyter* in order to make this clearer. The Python kernel we provide and the original terminal-based shell will continue to be called *IPython*.\r\n\r\nIn this hands-on, in-depth tutorial, we will briefly describe IPython's architecture and will then show how to use the above tools for a highly productive workflow in Python.",
        "authors": [
            "Thomas Kluyver",
            "Kyle Kelley"
        ],
        "conf_key": 53,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/316/",
        "contact": [
            "thomas@kluyver.me.uk",
            "rgbkrk@gmail.com"
        ],
        "description": "IPython and Jupyter provide tools for interactive and parallel computing that are widely used in scientific computing, but can benefit any Python developer. We will show how to use IPython in different ways, as: an interactive shell, a graphical console, a network-aware VM in GUIs, a web-based notebook with code, graphics and rich HTML, and a high-level framework for parallel computing.",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "IPython & Jupyter in depth: high productivity interactive and parallel python",
        "released": true,
        "room": "Room 510B",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "This talk is part coding, part lessons learned. We will do a hands on walk through of a couple of web scrapers. During the walk through, we will stop periodically to discuss to how the web works and how web pages are constructed. These stopping points will help break down how to get the content that we are looking for.\r\n\r\nBesides looking at how websites are put together, we will also discuss the ethics of scraping. What is legal? How can you be a friendly scraper, so that the administrator of the website you are scraping won\u2019t try to shut you down?\r\n\r\nLastly, we will cover some projects where folks used scraping techniques and the projects that came out of those. We will also share some datasets that could be scraped for inspiration, and how to get started with those examples.\r\n",
        "authors": [
            "Jackie Kazil",
            "Sisi Wei"
        ],
        "conf_key": 37,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/318/",
        "contact": [
            "jackiekazil@gmail.com",
            "sisi.wei@propublica.org"
        ],
        "description": "Sometimes data does not come in a format that we would like it in, and we need to other mechanisms to collect data. This tutorial taught, from the perspective of a data journalist and a data scientist, who will give you an overview of use cases of how some folks have used web scraping for data collection, how to get started, where to find data, and what are the ethics behind it.",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "How to start web scraping",
        "released": true,
        "room": "Room 513A",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "Twitter's social network is endlessly fascinating because of its many different connection channels: there are hashtags, followers, retweets, and replies, all connecting users in different ways. Using the network analysis package NetworkX, we'll take a look at how to make sense of these channels. We'll cover some of the basics of network theory, including types of networks and how measure influence in a network. We\u2019ll use the Twitter API to gather data for our analysis, and then apply the network theory we learn to that data. Students will leave with knowledge of how to think about networks from a network theory perspective and may even find out something interesting about their own Twitter network.\r\n\r\nStudents should have an intermediate knowledge of Python, including the ability to write functions and understand iterables. Knowing how to use IPython Notebook will also be helpful, since the materials will be in that format. Having both NetworkX and IPython notebook, as well as matplotlib, which we\u2019ll use for visualization, installed prior to the tutorial is necessary, as we\u2019ll only spend a few minutes covering installation. These packages can be pip installed, or can be installed through a distribution like Anaconda or Enthought Canopy.\r\n",
        "authors": [
            "Sarah Guido",
            "Celia La"
        ],
        "conf_key": 39,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/466/",
        "contact": [
            "sarah.guido89@gmail.com",
            "celiala456@gmail.com"
        ],
        "description": "Twitter's network is fascinating because of its connectivity: there are hashtags, followers, retweets, and replies. Using the network analysis tool NetworkX, we'll look at how to make sense of these channels. We'll cover the basics of network theory, including types of networks and how measure influence, and we'll apply those measures to our investigation of Twitter's network.",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Twitter Network Analysis with NetworkX",
        "released": true,
        "room": "Room 513D",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "This carefully constructed course will take a programmer with a basic understanding of Python to the next level. You should feel comforable with Python loops, variables, functions, and classes. **From there we build your knowledge and cover some of the more exciting aspects of Python that tend to bite new Python programmers.**\r\n\r\nWith a unique, fast-paced combination of lecture and lab, the student will not only listen to the material, but try it out themselves.\r\n\r\nIn addition, attendees will recieve a copy of the slides and a cheatsheet covering the material.\r\n\r\nBring a laptop with Python (2 or 3) installed and a desire to learn the basics.\r\n\r\n",
        "authors": [
            "matt harrison"
        ],
        "conf_key": 38,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/299/",
        "contact": [
            "matthewharrison@gmail.com"
        ],
        "description": "Are you new to Python and want to learn how to step it up to the next level? Have you wondered about functional programming, closures, decorators, context managers, generators, or list comprehensions and when you should use them and how to test them? This hands-on tutorial will cover these intermediate subjects in detail, by explaining the theory behind them then walking through examples.\r\n",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Hands-on Intermediate Python",
        "released": false,
        "room": "Room 513BC",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "A recommendation engine is a software system that analyzes large amounts of transactional data and distills personal profiles to present its users with relevant products/information/content. We see them in a wide variety of domains and applications and they help us navigate the overwhelming choice that we face everyday.\r\n\r\nThis tutorial will formally introduce the concepts and definitions of the recommendation systems literature and will quickly move on to an iterative process for building a minimal reco engine. In the process, we'll learn about the building blocks for scientific computing in Python: NumPy and (more recently) pandas.\r\n",
        "authors": [
            "Diego Maniloff",
            "Christian Fricke",
            "Zach Howard"
        ],
        "conf_key": 36,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/322/",
        "contact": [
            "diego@unata.com",
            "christian@unata.com",
            "zach@unata.com"
        ],
        "description": "In this tutorial we'll set ourselves the goal of building a minimal recommendation engine, and in the process learn about Python's excellent Pydata and related projects and tools: NumPy, pandas, and the IPython Notebook.\r\n",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Hands-on with Pydata: how to build a minimal recommendation engine.",
        "released": true,
        "room": "Room 512FB",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "This tutorial provides the big-picture view the documentation lacks. Though you will get your hands on many of ES's features, we won't waste your time slogging page by page through the reference manual\u2014you can look up specific corner cases any time. Instead, we will give you the mental framework to organize\u2014and even predict\u2014the specifics.\r\n\r\nWithout assuming you know anything about Lucene, we will pull back the curtain to explore the data structures used for indexing, the algorithms that make faceting so fast, and the tradeoffs involved in replication and sharding. From these fundamentals, you will be able to deduce how to make your own use cases efficient. You will also see how far ES can be stretched, applying some clever Python preprocessing to do things like trigram-accelerated regex matching. Finally, you will learn to avoid the mistakes we made, both in design and deployment, so you can build a stable cluster that needs no babysitting.",
        "authors": [
            "Erik Rose"
        ],
        "conf_key": 35,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/330/",
        "contact": [
            "erik@mozilla.com"
        ],
        "description": "Elasticsearch provides a powerful combination of clustered full-text search, synonyms, faceting, and geographic math, but there's a big gap between its documentation and real life. We'll work through hands-on examples, tell war stories yielding hard-won lessons, and show what happens behind the scenes, equipping you to slither smoothly into using Elasticsearch in your own projects.",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Slithering Into Elasticsearch",
        "released": false,
        "room": "Room 512EA",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "Do you know the difference between standard deviation and standard error? \u00a0Do you know what statistical test to use for any occasion? \u00a0Do you really know what a p-value is? \u00a0How about a confidence interval?\r\n\r\nMost students don\u2019t really understand these concepts, even after taking several statistics classes. \u00a0The problem is that these classes focus on mathematical methods that bury the concepts under a mountain of details.\r\n\r\nThis tutorial uses Python to implement simple statistical experiments that develop deep understanding. \u00a0Attendees will learn about resampling and related tools that use random simulation to perform statistical inference, including estimation and hypothesis testing. \u00a0We will use pandas, which provides structures for data analysis, along with NumPy and SciPy.\r\n\r\nI will present examples using real-world data to answer relevant questions. \u00a0The tutorial material is based on my book, _Think Stats_, a class I teach at Olin College, and my blog, \u201cProbably Overthinking It.\u201d\r\n",
        "authors": [
            "Allen Downey"
        ],
        "conf_key": 34,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/326/",
        "contact": [
            "allendowney@gmail.com"
        ],
        "description": "Statistical inference is a fundamental tool in science and engineering, but it is often poorly understood. \u00a0This tutorial uses computational methods, including Monte Carlo simulation and resampling, to explore estimation, hypothesis testing and statistical modeling. \u00a0Attendees will develop understanding of statistical concepts and learn to use real data to answer relevant questions.\r\n",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Statistical inference with computational methods",
        "released": true,
        "room": "Room 512DH",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "This tutorial will proceed through each of Django's major components in order, finishing with the administrative interface as an example of how all those components can be tired together.\r\n\r\nWe'll begin with a deep dive into the Django ORM; this will work from the bottom up, showing how Django turns a simple ORM method call into a database query and a set of results. Starting from the level of the database driver, we'll come back up the chain through the Query and QuerySet classes back into the everyday realm of Manager and Model, noting points of flexibility/customization along the way, and useful common patterns and advice for use in real applications.\r\n\r\nNext we'll turn to the forms library, covering the implementation from Form and Field down into Widget and the full validation process, including all of the customization hooks, before looking at ModelForm and direct model integration and easy methods for generating dynamic custom forms on the fly in application code.\r\n\r\nFrom there we'll look at the template language, inside and out, covering all the details of how templates are parsed, compiled and rendered, and a full explanation of how template tags work and of patterns for writing custom tags.\r\n\r\nNext up is Django's request/response processing pipeline, covering the handler behavior, request and response objects, the middleware system and how Django's URL resolution works and gets to the actual view to call.\r\n\r\nFollowing up on that we'll take a look at just what a Django view is, starting with function-based views and then working toward an understanding of class-based views as exemplified by Django's built-in generic views.\r\n\r\nFinally we'll put it all together with a look at the Django administrative interface, seeing how all the components work together and how the AdminSite and ModelAdmin classes actually work and can be customized.",
        "authors": [
            "James Bennett"
        ],
        "conf_key": 33,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/311/",
        "contact": [
            "james@b-list.org"
        ],
        "description": "This is a tutorial that goes beyond most tutorials; it's meant for developers who already know a bit about Django and want to really understand the inner guts of the framework. This tutorial will *not* involve writing code or apps; rather, it'll be a deep tour of the workings and APIs of Django itself, across all the bundled components and at all levels of the stack.",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Django in Depth",
        "released": true,
        "room": "Room 512CG",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": "This tutorial aims to cover a wide assortment of advanced topics related to modules, packages, and the import statement.  Topics will include, but are not limited to the following:\r\n\r\n- Basics of modules and packages.\r\n- What can be imported?\r\n- Module compilation (.pyc files, etc.)\r\n- Construction of sys.path\r\n- Namespace packages\r\n- Virtual environments\r\n- Circular module dependencies\r\n- Package relative imports\r\n- Module splitting (splitting modules into multiple files)\r\n- Import hooks\r\n- Module imports and threads\r\n- Module reloading\r\n",
        "authors": [
            "David Beazley"
        ],
        "conf_key": 32,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/303/",
        "contact": [
            "dave@dabeaz.com"
        ],
        "description": "All Python programmers use the import statement, but do you really know how it works and what it allows?  This tutorial aims to take a deep dive into every diabolical issue related to modules, packages, and imports.   When we're done, you'll finally be ready to unleash your million line micro framework on the world! ",
        "duration": 200,
        "end": "2015-04-09T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Modules and Packages: Live and Let Die!",
        "released": true,
        "room": "Room 510D",
        "start": "2015-04-09T13:20:00",
        "tags": ""
    },
    {
        "abstract": " \t\r\n- Data munging for predictive modeling with pandas and scikit-learn\r\n\r\nBuilding predictive models first requires shaping the data in the right format to meet the mathematical assumptions of machine learning algorithms. In this session we will introduce the pandas data frame datastructure for munging heterogeneous data into a representation that is suitable for most scikit-learn models. In particular we address problems such as missing value imputation and categorical variables. We will illustrate those concepts by combining pandas-based feature engineering with scikit-learn Logistic Regression, Random Forests and Gradient Boosted Trees.\r\n\r\n- Model evaluation and selection\r\n\r\nBuilding a predictive model is a fundamentally iterative process: design a model, train it, analyze errors, fix the model design and iterate. To iterate quickly in the right direction it is therefore very important to understand how models fail. This session will dive into methodological concepts and scikit-learn tools to evaluate models such as cross validation, overfitting and underfitting, regularization, plotting validation curves and learning curves. Finally we also cover how some parts of the model design can be automated via parameter search (exhaustive Grid Search or Random Search).\r\n\r\n\r\n\r\n- Working with text data\r\n\r\nMachine Learning with text data can be very useful for social networks analytics for instance to perform sentiment analysis. Extracting a \"machine learnable\" representation from raw text is an art in itself. In this session we will introduce the bag of words representation and its implementation in scikit-learn via its text vectorizers. We will discuss  preprocessing with NLTK, n-grams extractions, TF-IDF weighting and the use of SciPy sparse matrices. Finally we will use that data to train and evaluate of a Naive Bayes classifier and a Linear Support Vector Machine.",
        "authors": [
            "Olivier Grisel"
        ],
        "conf_key": 56,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/324/",
        "contact": [
            "olivier.grisel@gmail.com"
        ],
        "description": "This tutorial will offer an overview of common usage and methodological patterns when using Scikit-Learn to build predictive models. In particular we will highlight common strategies to deal with data with heterogeneously typed attributes with pandas dataframes, model evaluation and tuning. Finally if time permits we will explore the specificities of working with textual data.",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Machine Learning with Scikit-Learn (II)",
        "released": true,
        "room": "Room 512DH",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "Learning how to implement cryptography correctly is hard. Developers typically learn while doing, using online and local resources and trying and retrying until the code does what they want. Unfortunately, cryptography can't generally be learned in this manner as doing it wrong tends to be indistinguishable from doing it right without a significant amount of effort.\r\n\r\nThis tutorial is designed to help developers over this hump. We'll be covering general cryptography principals and best practices as well as the following topics:\r\n\r\n_Passwords & Authentication_ - We will cover general authentication topics to help developers choose between the various authentication schemes including generation methods like PDKDF2, scrypt or bcrypt and key based methods using asymmetric crypto. We will then cover how to implement these systems in Python with an eye towards usage in common frameworks.\r\n\r\n_Data at Rest Encryption_ - Data in applications comes in a huge variety of forms. We will review options for encrypting data and the pros and cons of each method. Once we've covered the cryptographic primitives, we'll cover how to use them securely in common cases and how and when to extend them.\r\n\r\n_Signing & Verification_ - Many applications don't want to encrypt data for various reasons (performance, debuggability, etc) but do want to be able to verify that information hasn't been tampered with or that it comes from a known, valid user. In this section, we'll cover the use cases and standards around signing & verifications and walk attendees through the implementation of these types of schemes.\r\n\r\n_Key Management_ - All encryptions schemes are only as secure as their keys. In this session, we'll review the various types of key management for applications and review which type will be appropriate in different scenarios. We'll then walk through an implementation of one or more key management schemes using open source software.\r\n",
        "authors": [
            "Jarret Raim",
            "Paul Kehrer"
        ],
        "conf_key": 58,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/305/",
        "contact": [
            "jarito@gmail.com",
            "paul.l.kehrer@gmail.com"
        ],
        "description": "The cryptographic world doesn't lend itself to the typical developer flow of learning while doing. Add that to the massive amount of bad or outdated information on the web and many developers are lost or worse, build insecure systems. This tutorial will introduce developers to modern cryptography with an eye towards practical scenarios around password management, encryption and key management.",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "What to do when you need crypto",
        "released": true,
        "room": "Room 512FB",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "**Overview**\r\n\r\nIt is a truth universally acknowledged that the admin is an important component of the Django framework, and knowing how to make efficient use of it can save you days or weeks of development. The Django tutorial is a great place to take your first steps with the admin, but it can often take a bit of searching to learn how to use some of the more advanced features. The goal of this tutorial is to bridge the gap between the Django tutorial and the reference documentation of the Django admin by using real examples.  \r\n\r\nWe will use a fully-functional (though fictional) Django project to build an admin interface to support the librarians at a local library. The interface will allow them to add and edit patrons and resources (books, CDs, DVDs, etc.) as well as manage fines for overdue items. They will be able to make comments on various models as well.\r\n\r\nThe tutorial begins with a discussion of what a library might need in terms of an administrative interface for the librarians.  We then cover the models that are available in our demonstration project (https://bitbucket.org/jacinda/admin-library).\r\n\r\nWe then proceed through a commit-by-commit progression of our repository that demonstrates the evolution of this admin interface.  \r\n\r\nWhile not required, students will get more out of the tutorial if they have a computer with them that is capable of running the code in the admin-library repository.  The repository includes the necessary files to use a virtual machine and vagrant or can be setup easily within a virtualenv running on the metal of most systems.  Students are expected to have some familiarity with Django but even novices will be able to get a lot of information from this tutorial (particularly the first half).\r\n\r\n**Ground to Be Covered**\r\nWe move quickly through some more basic \"review\" examples that more experienced Django users will be familiar with, like changing the default URL, the title text and some idiosyncrasies of using Django's AbstractUser with the admin.  We also cover adding models, modifying the display of those models, changing field / fieldset orders, adding help text and a laundry list of \"basic hygiene\" admin tasks.\r\n\r\nThe bulk of the tutorial then covers more intermediate / advanced topics within the admin, including the use of custom readonly fields to allow certain staff members the ability to edit certain fields while restricting other staff members, the potential performance impact of including different fields in list_display, and how to use custom filters, views, and templates to add additional functionality.\r\n\r\nBased on audience interest and timing, the tutorial will cover audience questions about the admin and either try to demonstrate answers in real time or provide a link later to an example.\r\n",
        "authors": [
            "Jacinda Shelly"
        ],
        "conf_key": 59,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/309/",
        "contact": [
            "jacinda.shelly@gmail.com"
        ],
        "description": "The admin interface is widely considered a \"killer feature\" of Django. At its most basic, you can just register all your models and be on your way, but there's so much more available within Django's admin. This tutorial takes you step by step through the creation and progressive improvement of an admin interface for a fictional library (all code is publicly available).",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Delving into the Django Admin",
        "released": true,
        "room": "Room 513A",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "Every wanted to get your feet wet in 3D graphics and animation? Well, you're in luck!\r\n\r\nThis hands-on workshop is a beginner's introduction using Blender and the Blender API. No 3D experience necessary.\r\n\r\nWe'll start off with a quick intro on basic computer graphics (like how 3D models are represented) and then dive into making your own models and scenes.\r\n\r\nAfter getting comfortable with the Blender UI, we'll tackle writing scripts to programmatically manipulate everything, from models to lights. You'll learn the quirks of the Blender API, write your very own Blender add-on, and maybe even contribute back to the Blender community.\r\n\r\n**Please bring a mouse with a scroll wheel.**\r\n",
        "authors": [
            "Jenny Cheng"
        ],
        "conf_key": 61,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/307/",
        "contact": [
            "caretdashcaret@gmail.com"
        ],
        "description": "Blender is an amazing open source graphics suite that lets you create animations, edit videos, and much more! It includes a Python API so you can script model creation and animation. Come get started with Blender and the Blender API. You'll learn the basics of 3D modeling and animation, get a guided tour of Blender's features, and write your very own Blender add-on!",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Intro to 3D Graphics with Blender and the Blender API",
        "released": true,
        "room": "Room 513D",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "Python is quickly becoming the go-to language for data analysis. However, there are so many tools out there that it can be difficult to figure out which ones are useful. In this workshop, I\u2019ll give you an in-depth look at some of the best tools for data wrangling, machine learning, and data visualization. You\u2019ll learn strategies for working with data, how to structure a data analysis workflow, and which tools are appropriate for handling different kinds of data. You\u2019ll leave with a good understanding of different data analysis techniques in Python.\r\n\r\nUsing Pandas, scikit-learn, and matplotlib, we\u2019ll work through a data analysis workflow from start to finish, and we\u2019ll cover the following data analysis problems:\r\n\r\n - Data preprocessing and data wrangling with Pandas\r\n - Using scikit-learn for machine learning\r\n - Visualizing our results with matplotlib\r\n\r\nStudents should have an intermediate knowledge of Python, including the ability to write functions. Knowing how to use IPython Notebook will also be helpful, since the materials will be in that format. Having all of the materials installed prior to the tutorial is necessary, as I'll only spend a few minutes covering installation, though I'll present several options for participating in the tutorial. These packages are most easily installed through a distribution like Anaconda or Enthought Canopy.  \r\n",
        "authors": [
            "Sarah Guido"
        ],
        "conf_key": 60,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/320/",
        "contact": [
            "sarah.guido89@gmail.com"
        ],
        "description": "Python is quickly becoming the go-to language for data analysis. However, it can be difficult to figure out which tools are good to use. In this workshop, we\u2019ll work through in-depth examples of tools for data wrangling, machine learning, and data visualization. I\u2019ll show you how to work through a data analysis workflow, and how to deal with different kinds of data.",
        "duration": 200,
        "end": "2015-04-08T16:40:00",
        "kind": "tutorial",
        "license": "CC",
        "name": "Hands-on Data Analysis with Python",
        "released": true,
        "room": "Room 513BC",
        "start": "2015-04-08T13:20:00",
        "tags": ""
    },
    {
        "abstract": "Let\u2019s program a robot at PyCon!  Not just some dumb robot that runs around the room and bumps into stuff. Let\u2019s program a baby version of one of those big fancy arms you see at a factory. No, really, we can do this, it is not as hard as you think! It turns out one of the most sophisticated robotics frameworks in the world runs on python and it is open source. This talk is a crash course on Robot Operating System (ROS) and how it can be used to build some wicked cool robots for fun and world domination. We\u2019ll cover the libraries that do the fancy math that help your robot to move and figure out where it is, and what it should do. We will also cover the ROS build system which can be a bit scary, and some of the great visualization and debugging tools in ROS. \r\n",
        "authors": [
            "Katherine Scott"
        ],
        "conf_key": 121,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/399/",
        "contact": [
            "katherineAScott@gmail.com"
        ],
        "description": "Lots of people want to learn more about robotics but are unsure where to start. Turns out there is a python robotics framework, and it runs some of the most sophisticated robots in the world! It is also open source, well-documented, and has a great community. In this talk we will look at Robot Operating System ROS.\r\n",
        "duration": 45,
        "end": "2015-04-10T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "Robots Robots Ra Ra Ra!!!",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T13:40:00",
        "tags": ""
    },
    {
        "abstract": "Continuous Deployment is the idea of changes to software being released at extremely frequent intervals as opposed to on a release timetable, and has become a popular method of deploying, in particular, hosted web applications.\r\n\r\nFor many developers and operations professionals, the idea of continuous deployment is not just an end goal, but a process -- it's a continuum.  \r\n\r\nAt one end you start with manual deployment, running commands on boxes.  Then you automate that.  Then you might get a release down to one click to deploy everything, but different manual steps for quality assurance, and those \"turn your keys all at once\" moments that involve several guys locked in a server room on a Saturday night, just in case anything goes wrong.   And something always does.\r\n\r\nGetting there to Continuous Deployment all the way is great, but getting there even part of the way (and implementing some of the concepts) can yield great improvements in one's day to day job of dealing with software releases.  Along the way, you'll learn about using automation at maximum efficiency to make sure things don't go wrong, and when they do, that you can recover painlessly.\r\n\r\nThis requires many things - an automated development environment that resembles production, a continuous integration system (like Jenkins), a stage environment that even more closely resembles production, integration tests running against this stage environment, and a production environment -- all connected together in sane ways.\r\n\r\nCombining them together, it's possible to have *software* decide when to ship code, not humans.\r\n\r\nIn this talk, we'll show you how, giving specific examples of how some major companies got to exactly the place you are going.\r\n\r\nOne of the tools we'll show off is Ansible, a powerful python-powered automation tool, which is one of the top 6 python projects on GitHub in terms of forks today (out of hundreds of thousands of projects).  Ansible's really popular in DevOps circles, due to it's agent-less nature and very large toolbox of included modules.   While it serves many other needs, it was also written specifically for the purpose of enabling zero-downtime rolling updates of infrastructure.\r\n\r\nWe'll show how Ansible can interact with monitoring systems and load balancers to orchestrate updates of complex multi-tier environments, that happen while you sleep, allowing you more time to spend on the coding and IT tasks you want to spend time on, rather than repeating the same manual steps each time you deploy your software.\r\n\r\nNo matter what automation tools you use or whether you adopt a C.D. workflow fully, the lessons learned on the path to continuous deployment will change the way you build, test, and release software for the better.\r\n\r\n\r\n\r\n",
        "authors": [
            "James Cammarata"
        ],
        "conf_key": 171,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/335/",
        "contact": [
            "jcammarata@ansible.com"
        ],
        "description": "Continuos Deployment is the act of deploying software constantly.  The idea is if \"release early, release often\" is good, releasing very often is better.  It's not trivial.   Automation is part of the battle, and testing is another.   Learn to use tools like Jenkins and Ansible to move from deploying software once a month to 15 times every hour, and why you'll want to.",
        "duration": 45,
        "end": "2015-04-11T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "Achieving Continuous Delivery: An Automation Story",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T13:40:00",
        "tags": ""
    },
    {
        "abstract": "Distributed systems are a fairly advanced field of computer science. As systems increase in scale, it's becoming increasingly more important. Furthermore, you could argue that our individual nodes themselves are increasingly becoming like distributed systems.\r\n\r\nUnfortunately, the field has some similarities to cryptography and information security. They're considered very difficult fields to be left primarily to experts; there's a plethora of papers available on subjects both theoretical and applied, and yet, we seem to do a poor job educating people. Most of us are left to self-educate, but the material is poorly organized for that purpose.\r\n\r\nThis talk intends to give a very brief introduction to distributed systems theory and practice, a kind of selected reading list, rules of thumb, and a healthy dose of existential fear.",
        "authors": [
            "lvh"
        ],
        "conf_key": 102,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/386/",
        "contact": [
            "_@lvh.io"
        ],
        "description": "A very brief introduction to the theory and practice of distributed systems.",
        "duration": 45,
        "end": "2015-04-10T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "Distributed Systems 101",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-10T13:40:00",
        "tags": ""
    },
    {
        "abstract": "### Introduction / A mysterious bug\r\nAn outline of the Python interpreter in Python that Ned Batchelder and I were writing, the reason we set out to write it, and a mysterious bug we encountered\r\n\r\n### Into the machine\r\n\r\n#### Introduction to bytecode\r\n - The definition of bytecode as an internal representation of Python code to the interpreter\r\n - What it means to talk about \"compiling\" Python code when Python is an \"interpreted\" language\r\n - Using `dis` to understand bytecode\r\n\r\n#### The VM is a stack machine\r\n - Discussing the virtual machine as a stack machine\r\n - Why bytecodes like `BINARY_MOD` don't have arguments\r\n - What \"dynamic\" means\r\n\r\n#### Executing Bytecode\r\n - The main loop of the CPython interpreter is a 1,500 line switch statement!\r\n - Visualizations of the stack as code executes\r\n\r\n### Resolving the bug\r\nAt this point I'll reveal the misunderstanding we had when first writing the interpreter\r\n\r\n### Conclusion\r\nI'll close by restating what we learned and drawing analogies to other systems, if time allows.\r\n",
        "authors": [
            "Allison Kaptur"
        ],
        "conf_key": 223,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/420/",
        "contact": [
            "allison.kaptur@gmail.com"
        ],
        "description": "Have you ever wondered how the CPython interpreter works? Do you know where to find a 1,500 line switch statement in CPython? I'll talk about the structure of the interpreter that we all use every day by explaining how Ned Batchelder and I chased down a mysterious bug in Byterun, a Python interpreter written in Python. We'll also see visualizations of the VM as it executes your code.\r\n",
        "duration": 45,
        "end": "2015-04-11T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "Bytes in the Machine: Inside the CPython interpreter",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T13:40:00",
        "tags": ""
    },
    {
        "abstract": "Sometimes, you want to modify a user experience based on rate, but first, you need a way to track how fast s/he is doing something. How to go about doing this?\r\n\r\n\u201cClassic\u201d rate tracking involves incrementing a count when a user performs a specific action of interest in a given period of time. We\u2019ll discuss why this method is not as effective as we would like, especially given the goal of rate limiting, or restricting access based on rate, namely: \r\n\r\n - no way to archive this data\r\n - the difficulty of implementing a sliding time window\r\n - the lack of granularity that we want for writing rate limiting rules\r\n\r\nNext, we will explain the \u201cvelocity engine,\u201d the more evolved rate tracker that we built in Python at Eventbrite. We\u2019ll cover:\r\n\r\n - our use of the redis-py library to implement a Redis data store and how Redis versions 2.6 and 2.7 affect our implementation\r\n - how we generate keyspaces and facets in Redis, as well as the partitioning of each bucket\r\n - translating from the Redis internal structure to a more readable list of rates\r\n - our expiration strategy for keyspaces and the \u201chousekeeper\u201d module that keep Redis clean despite tons of rate data\r\n - how this smarter implementation allows us to do more nuanced rate limiting by writing rules with a greater granularity\r\n\r\nYou will leave this talk with a better understanding of rate tracking and how smart rate tracking is a great foundation to set for better rate limiting.\r\n",
        "authors": [
            "Mica Swyers",
            "Jay Chan"
        ],
        "conf_key": 151,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/383/",
        "contact": [
            "mica@eventbrite.com",
            "jay@eventbrite.com"
        ],
        "description": "This talk provides an introduction to rate tracking as well as an explanation of a particularly cool way to implement it. You will learn what rate tracking is, why you would want to do it, and then how you can use build a Redis-backed \u201cvelocity engine\u201d  in Python to do just that. \r\n",
        "duration": 30,
        "end": "2015-04-12T14:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Finding Spammers & Scammers through Rate Tracking with Python & Redis ",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-12T13:50:00",
        "tags": ""
    },
    {
        "abstract": "*Setting the scene*\r\n\r\nMy boss alerted me to an article on a popular site, which claimed to show that my open-source Python client for MongoDB is three times slower than the Javascript client. Anxiety immediately set in: Was this true? Could I improve it? What should I tell my boss?\r\n\r\n*Why profile?*\r\n\r\nA typical program spends almost all its time in a small subset of its code. Optimizing those hotspots is all that matters. This is what a profiler is for: it leads us straight to the functions where we should spend our effort. So I decided to profile the code in the article to see why it was slow.\r\n\r\n*Which profiler?*\r\n\r\nI\u2019ll describe three open-source profilers for Python: cProfile is a fast single-thread profiler included in the Python standard library. GreenletProfiler is my package for profiling Gevent applications. Yappi is a third-party package that can profile multiple threads. I used Yappi for this investigation, since it\u2019s the most featureful.\r\n\r\n*How do we profile and what information do we get?*\r\n\r\nYappi has configuration options for how it measures time and which functions it profiles. I\u2019ll show you how I configured and ran Yappi, and how I visualized its output in KCacheGrind.\r\n\r\n*How do we use the profiling information?*\r\n\r\nI used KCacheGrind\u2019s different views to narrow the search for hotspots, and calculated upper bounds for what performance enhancements I could achieve. Optimization is like debugging: we form a hypothesis for what changes will yield the best speedups, than perform experiments. This forms a virtuous cycle of benchmarking and improving our code. I\u2019ll relate the shocking conclusion to my investigation of the slow code.\r\n\r\n*How does profiling work?*\r\n\r\nIf you\u2019re like me, you can\u2019t sleep if you don\u2019t understand how something works. We\u2019ll briefly explore how cProfile and Yappi hook into the Python interpreter\u2019s guts, and how Yappi employs a clever trick to efficiently profile all running threads.",
        "authors": [
            "A. Jesse Jiryu Davis"
        ],
        "conf_key": 97,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/400/",
        "contact": [
            "jesse@emptysquare.net"
        ],
        "description": "Your Python program is too slow, and you need to optimize it. Where do you start? With the right tools, you can optimize your code where it counts. We\u2019ll explore the guts of the Python profiler \u201cYappi\u201d to understand its features and limitations. We\u2019ll learn how to find the maximum performance wins with minimum effort.",
        "duration": 30,
        "end": "2015-04-12T14:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Python Performance Profiling: The Guts And The Glory",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-12T13:50:00",
        "tags": ""
    },
    {
        "abstract": "The terminal emulators we run so many of our programming tools in are more powerful than we remember to give them credit for, and the key to that power is understanding the interface. This talk will cover terminal colors and styles, writing to arbitrary portions of the screen, handling signals from the terminal, determining the terminal's dimensions, scrollback buffer behavior and relevant environmental variables.\r\n\r\nTerminal programming can get hairy; along the way we'll deal with encoding issues, consider cross platform concerns, acknowledge 4 decades' worth of standards for terminal communication, and consider that humans at interactive terminals may not be the only users of our interfaces. By gaining an understanding of these issues, we'll be able choose from the abstractions over them offered by Python libraries Urwid, curses, and Blessings.",
        "authors": [
            "Thomas Ballinger"
        ],
        "conf_key": 108,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/401/",
        "contact": [
            "thomasballinger@gmail.com"
        ],
        "description": "Have you ever wanted to add a status bar to your command line program?\r\nOr maybe color the output a bit? Or do you want to write a fullscreen terminal application like ls, top, vim, or emacs? Then you need to speak a bit of terminal! This talk describes how to talk to your terminal from scratch and goes on to show why Python libraries Blessings and Urwid are so awesome.",
        "duration": 30,
        "end": "2015-04-12T14:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Terminal whispering",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-12T13:50:00",
        "tags": ""
    },
    {
        "abstract": "Do you have an API? \r\n\r\nDo you accept input from users? Do you accept it in XML? What about YAML? Or maybe JSON? How safe are you?\r\n\r\nAre you sure?\r\n\r\nIt\u2019s not in the OWASP Top 10, but you don\u2019t have to look far to hear stories of security vulnerabilities involving deserialization of user input. Why do they keep happening?\r\n\r\nIn this talk I\u2019ll go over what the threat is, how you are making yourself vulnerable and how to mitigate the problem. I\u2019ll cover the features (not bugs, features) of formats like XML, YAML, and JSON that make them surprisingly dangerous, and how to protect your code from them. My examples are in Python but are also applicable to other languages and frameworks.\r\n\r\nBecause here\u2019s the thing: If you are using, say, a compliant, properly implemented XML parser to parse your XML, you are NOT safe. Possibly quite the opposite.",
        "authors": [
            "Tom Eastman"
        ],
        "conf_key": 147,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/390/",
        "contact": [
            "tom@eastman.net.nz"
        ],
        "description": "It\u2019s not in the OWASP Top 10, but you don\u2019t have to look far to hear stories of security vulnerabilities involving deserialization of user input. In this talk I\u2019ll go over what the threat is and how you might be making yourself vulnerable. I\u2019ll cover the features (not bugs: features) of XML, YAML, and JSON that make them surprisingly dangerous, and how to protect your code from them.",
        "duration": 30,
        "end": "2015-04-12T14:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "Serialization formats are not toys",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-12T13:50:00",
        "tags": ""
    },
    {
        "abstract": "Real-time webapps may be all the rage with NodeJS, but you can write them in Python too. Underneath a real-time webapp lies a technology called WebSockets, part of the HTML 5 spec. This talk takes a deep dive into WebSockets and how this TCP-based protocol works on the client- and server-side, using Python networking tools to see what actually goes over the wire.\r\n\r\nWe'll also talk about protocol details you're sure to run into deploying a WebSockets app in production, like connection upgrading and gracefully falling back to older technologies when clients don't support WebSockets.\r\n\r\nAll this networking and protocol talk may sound dry, but don't worry, I'll make it fun. :)",
        "authors": [
            "Christine Spang"
        ],
        "conf_key": 177,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/376/",
        "contact": [
            "christine@spang.cc"
        ],
        "description": "HTML5 WebSockets power the real-time web. Come take a deep dive into how they\r\nwork, from the big picture down to what goes over the wire, including insight\r\ninto the performance benefits of the protocol, via a real-world example of how\r\nWebSockets are implemented client- and server-side in Python.",
        "duration": 30,
        "end": "2015-04-12T14:20:00",
        "kind": "talk",
        "license": "CC",
        "name": "WebSockets from the Wire Up",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-12T13:50:00",
        "tags": ""
    },
    {
        "abstract": "As the author of many applications and libraries in Erlang and Python I often switch from one to the other during the day. The usage of Erlang definitely changed the way I am coding in Python. \r\n\r\nThis talk will cover some techniques that are used in Erlang and other functional programming languages and how they can be used to solve problems in more performant, robust and/or concise ways than the standard practices in Python. It will also discuss some possible changes to Python and how such changes could improve its usage by the community.",
        "authors": [
            "Benoit Chesneau"
        ],
        "conf_key": 113,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/388/",
        "contact": [
            "bchesneau@gmail.com"
        ],
        "description": "What can we learn from Erlang for building reliable high concurrency services? This talk will shows some techniques used in Erlang and how they can be used to solve problems in a more efficient way in Python. It will also discuss how Python could evolve accordingly.",
        "duration": 30,
        "end": "2015-04-10T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "What Python can learn from Erlang?",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T13:55:00",
        "tags": ""
    },
    {
        "abstract": "Requests has over 23 million downloads from PyPI alone and is relied on by open source projects and companies alike but there's no established best practices to testing an application that uses requests.\r\n\r\nI am a core developer of requests and the author of github3.py. I use requests on an almost daily basis and have developed some simple and sensible ways of testing libraries and applications that use requests. I am also the author of betamax, one of the libraries we'll be discussing in this talk.\r\n\r\n**Why test at all?**\r\n\r\nTesting is generally accepted as a best practice in our industry. The difficulty is in testing anything that talks to the internet. We all know how to test Django apps that talk to a database. We know how to test most other applications we write. Clearly our applications that use requests can benefit from tests as well.\r\n\r\n**What tools exist?**\r\n\r\nThere are many tools that already exist to help you test your code that uses requests. Some of the most popular include responses, httpretty, and vcr.py.\r\n\r\nBetamax's popularity is growing especially given its simplicity. There is a fundamental flaw with both responses and httpretty though: they encourage the user to write fixture data which means that any time the service changes, the user has to fix their fixtures to match the real world data. Tools like vcr.py and betamax relax that constraint by allowing a real interaction to take place, saving it to disk, and then re-using it. At any time, this interaction can be re-recorded to keep the fixture data up-to-date.\r\n\r\nWhat responses and httpretty especially excel at is making the user specify, for a given test, what request the user expects the code to make. In the simplest case, this can be done with the wildly popular mock library which has been included in the Python 3 standard library.\r\n\r\n**What patterns emerge?**\r\n\r\nIn my experience, the best approach is a combination of integration and unit tests. Using mock to test the calls made to requests help narrow down test failures or real code failures in dependency upgrades or contribution acceptance. Similarly, integration tests can alert you to a potentially harmful change made in requests during an upgrade.\r\n\r\nWriting unit tests without providing fixture data also forces the developer to\r\nwrite code that is not coupled tightly. This is a pattern we as a community\r\nrecognize as beneficial and maintainable.",
        "authors": [
            "Ian Cordasco"
        ],
        "conf_key": 222,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/344/",
        "contact": [
            "icordasc+pycon@coglib.com"
        ],
        "description": "A brief and opinionated view of testing applications and libraries that use requests by a core-developer of requests. You will receive an overview of testing with responses, vcr, httpretty, mock, and betamax.",
        "duration": 30,
        "end": "2015-04-11T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "Cutting Off the Internet: Testing Applications that Use Requests",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T13:55:00",
        "tags": ""
    },
    {
        "abstract": "**0. Background**\r\n\r\nHigh-quality free satellite data is available nowadays for simple download from agencies such as NASA, NOAA, ESA or the USGS. Imagery to resolutions of about 15-30m is detailed enough to map regional processes, be they environmental, industrial, or related to catastrophic events. But even coders who use GIS data as a matter of course are not often comfortable generating their own RGB raster maps. On the other hand, students and researchers in geospatial disciplines are often stuck in clumsy GUI-driven software and are unfamiliar with how a general purpose scripting language with excellent library support can help them. \r\n\r\nThis talk aims to bridge this gap: to give Python coders the enough knowledge of the anatomy of a satellite imagery scene, show researchers the power of Python, and point both to the best libraries to get both groups started on their mapping project.\r\n\r\n**1. For example, natural hazard mapping with Landsat.**\r\n\r\nSatellite imagery comes in many data file formats, from the straightforward to the frustrating and convoluted. We will spend the bulk of the talk on the easiest format: GeoTIFF, which is essentially a TIFF file with extra tags with information about data types, geographic extent and map projection. Luckily, GeoTIFF is not only the most friendly format for satellite imagery, it is also the one used by US Geological Survey, which distribute images from the Landsat family of earth observing satellites. \r\n\r\nLandsat images are not super-high resolution, but good enough to show roads, fields, rivers, industrial installations, forests, and  landscape structures. [Their quality is superb][1]. An example is this before/after image of a pond at the Mount Polley mine in BC, Canada, which, in early August, 2014, developed a breach and released toxic wastewater into the surrounding waters. \r\n![MtPolley][3]\r\n\r\n\r\n**2. Data details** \r\n\r\nThe scene comes as a zip file or tarball which contains a plain-text metadata file and, depending on the version of the satellite, a varying number of GeoTIFF files with the same footprint. Any three of these are used to make false-color RGB images. \r\n\r\nWe will use the GDAL library to read the images. This provides access to the data itself appears as Numpy arrays. GDAL makes it easy to relate rater indices to geographic location, while Numpy takes over the task of subsetting and data type conversion. The [wrapper classes][2] I have written remove some of the complexity. High-quality maps are generated with Matplotlib's Basemap toolkit, and all code will be available in iPython notebooks. \r\n\r\n**3. Beyond Landsat**\r\n\r\nA short section at the end of the talk will be devoted to data file formats that are less accessible than GeoTIFF, specifically HDF-EOS (used by NASA) and HDF5 (used among others by NOAA). HDF5 in particular is worth knowing as it is a good choice for storing your own raster data. \r\n\r\nIt turns out that making raster maps from satellite data is in no way harder than using shapefiles for GIS applications. Both can be combined using the Basmeap and/or the powerful shapely/fiona set of libraries\r\n\r\nAn animation][4] is online, and some code examples can be found in IPython notebooks [here][5] and [here][6]. \r\n\r\n\r\n  [1]: https://www.youtube.com/watch?v=8nboMGGdXUc\r\n  [2]: https://github.com/chryss/pygaarst\r\n  [3]: https://dl.dropboxusercontent.com/u/372734/IMG/MountPolley20140805.jpg\r\n  [4]: http://www2.gi.alaska.edu/~cwaigl/demos/seaice/pribiloff_map.mp4\r\n  [5]: http://nbviewer.ipython.org/gist/chryss/7593127\r\n  [6]: http://nbviewer.ipython.org/gist/chryss/7638837\r\n",
        "authors": [
            "Chris Waigl"
        ],
        "conf_key": 137,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/425/",
        "contact": [
            "chris.waigl@gmail.com"
        ],
        "description": "Concerned about urban sprawl, landscape change or ecosystem recovery? Wildfire, drought or flooding? A vast amount of satellite data, collected since the 1970s, is freely available for your next mapping project. I will demonstrate how Python helps to make sense of odd scientific data and metadata formats and produce beautiful visualization and map products.",
        "duration": 30,
        "end": "2015-04-10T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "Satellite mapping for everyone ",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T13:55:00",
        "tags": ""
    },
    {
        "abstract": "Porting Python 2 code to work with Python 2 & 3 without a constant 2to3 translation step is not hard anymore. With tools such as [python-modernize](https://github.com/python-modernize/python-modernize) or [futurize](http://python-future.org/automatic_conversion.html), the mundane details are taken care of for you (e.g. syntactic changes). That leaves only high-level API choices as the roadblock to porting and a couple of gotchas to look out for (e.g. what APIs should accept bytes vs. strings). And with 2to3 out of the picture it makes development much faster. Toss in linting tools such as [Pylint](http://pylint.org/) and you can make sure that once you make your changes that you don't accidentally regress. Add constant integration testing through tools like [Tox](https://testrun.org/tox/latest/) once you can use Python 3 and your Python 3 support will become negligible to maintain. There is even tools now like [caniusepython3](https://caniusepython3.com/) which help let you know when your project's dependencies have made the switch.",
        "authors": [
            "Brett Cannon"
        ],
        "conf_key": 140,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/360/",
        "contact": [
            "brett@python.org"
        ],
        "description": "You know Python 3 is an improvement over Python 2 and you want to use it. Unfortunately you have legacy Python 2 source code that needs to stay compatible. But don't fret! This talk will show you that you can make your code be Python 2/3 source-compatible using various tools to pick up the nitty-gritty work and help modernize your Python code to newer Python 2 practices.",
        "duration": 30,
        "end": "2015-04-10T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "How to make your code Python 2/3 compatible",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-10T13:55:00",
        "tags": ""
    },
    {
        "abstract": "Everyone who has to deal with data eventually has to deal with messy data. This task often takes over 50% of the effort yet is often billed as \"not the meat of the work\" and no one gets trained in it.\r\n\r\nGovernment data consumers, social scientists, other scientists, and even you, dear data consumer, might like this talk!\r\n\r\nYou'll learn how to tackle day to day data cleaning. Spotting issues with data, dealing with missing data and merging datasets are among the topics. I'll mention the deep, dark parts of pandas that help specifically with different types of cleaning, go over some lesser known but neat libraries and tools like Sunlight Labs' jellyfish, messytables, chardet, etc. I'll mention some thoughts on data collection, and finally go over a demo of cleaning a real life dataset!",
        "authors": [
            "Mali Akmanalp"
        ],
        "conf_key": 89,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/469/",
        "contact": [
            "mali@akmanalp.com"
        ],
        "description": "Have you ever viscerally hated a dataset? Do you want to just get data cleaning out of the way? Are you always left wondering how it consumes most of your time? Whether you work in the sciences, work with government data or scrape websites, data cleaning is a necessary evil. We'll share our woes and check out state of the art in day to day data cleaning tools and strategies.",
        "duration": 30,
        "end": "2015-04-11T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "Other people's messy data (and how not to hate it!)",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T13:55:00",
        "tags": ""
    },
    {
        "abstract": "In this talk, I will survey ethical and moral lessons from the general to the specific.  I'll begin with other professions, moving through to software development in general, then the free, libre, and open source software movement where Python has its roots, and finally Python's own history, in particular the CP4E initiative.\r\n\r\nI will also propose a conceptual framework for the conversation that needs to happen about what our ethical obligations are to society, and finally, my own vision for what those standards should be.\r\n",
        "authors": [
            "Glyph"
        ],
        "conf_key": 224,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/370/",
        "contact": [
            "glyph@twistedmatrix.com"
        ],
        "description": "As more of the world is controlled by software, software developers have an increasing obligation to serve that world well.  Yet, we don't yet have a sense of what makes a good ethical standard.  The fast pace, success, and youth (in both historical and demographic terms) of our industry have given us the sense that such a standard might not be required.  This talk will correct that misconception.",
        "duration": 30,
        "end": "2015-04-11T14:25:00",
        "kind": "talk",
        "license": "CC",
        "name": "The Ethical Consequences Of Our Collective Activities",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T13:55:00",
        "tags": ""
    },
    {
        "abstract": "PBS digital streams many videos online and this is not a trivial task.  Once you build an online video streaming system, you have touched many elements that you can control.  The remaining elements are things you cannot control: ISP bandwidth, user computers, Net Neutrality, and solar flares.  \r\n\r\nThus, PBS has invested in creating a basic framework for collecting video streaming data, processing it, and visualizing it.  This talk reviews the technologies involved including, but not limited to:\r\n\r\n - Map Reduce\r\n - Large database queries\r\n - Lightweight data collection servers\r\n - Video player instrumentation\r\n - Data visualization tools\r\n\r\nWe created the framework to be open and modular so that various technologies can be slotted in to be customized to various environments.\r\n",
        "authors": [
            "Mike Howsden"
        ],
        "conf_key": 101,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/348/",
        "contact": [
            "mvhowsden@pbs.org"
        ],
        "description": "It is extremely important to PBS that digital viewers have an awesome experience when viewing online videos.  In this talk, we explain how PBS built a system to collect, analyze, and measure who's getting a good experience -- and who's not. ",
        "duration": 30,
        "end": "2015-04-12T15:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Zen of Quality - How PBS measures QoS for digital viewers",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-12T14:30:00",
        "tags": ""
    },
    {
        "abstract": "\"Development should mirror production as much as possible.\" While the adage has been with us for some time, virtualization has made it much, much easier to create and destroy environments for development, testing, or production work.\r\n\r\nThis talk will focus on how to create development environments for server-side or web applications that adhere to their production counterparts while maintaining maximum ease of development.\r\n\r\nThere are many tools for this task, and the purpose of this talk is to teach the concepts, not to promote a given tool. However, examples must use something, so I'll be relying on Vagrant and Ansible.\r\n",
        "authors": [
            "Luke Sneeringer"
        ],
        "conf_key": 176,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/480/",
        "contact": [
            "luke@sneeringer.com"
        ],
        "description": "A talk on how to employ virtualization to make development easier, more portable, and have it more closely adhere to production environments.",
        "duration": 30,
        "end": "2015-04-12T15:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Improve your development environments with virtualization",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-12T14:30:00",
        "tags": ""
    },
    {
        "abstract": "Businesses can rise or fall on the margins created by application performance. Conversions, revenue, and traffic all increase dramatically as websites get faster. Giant after internet giant has produced metrics reaffirming the importance of fractional seconds of response time.\r\n\r\nPerformance is not an easy problem to solve, though. Intuitively applying optimizations and hoping for the best produces poor results. Inferring application characteristics from operating system metrics can mislead. Only application instrumentation can provide deep insight into application performance. Instrumenting apps is hard, though, and interpreting the results can be even harder.\r\n\r\nProfilers and system metrics are the first tools most engineers reach for, but neither is very good at understanding the performance implications of application behavior. Understanding the performance of production applications requires tools that measure the performance of production applications.\r\n\r\nThis sort of instrumentation comes in many forms. Developers often write their own monitoring endpoints. Etsy's statsd couples well with graphite as a tool to instrument an application by hand. Distributed tracing tools offer a different way of looking at latency, by putting it in the context of a request/response cycle. Each of these tools has a role in uncovering some aspect of application performance.\r\n",
        "authors": [
            "Geoff Gerrietts"
        ],
        "conf_key": 129,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/349/",
        "contact": [
            "geoff@gerrietts.net"
        ],
        "description": "Everyone knows poor performance when they see it, and performance concerns affect every application -- web applications more than most. But finding performance problems can be extraordinarily difficult, and requires an analytical approach coupled with good instrumentation. This talk explores approaches to instrumentation and what that instrumentation can tell you.",
        "duration": 30,
        "end": "2015-04-12T15:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Performance by the Numbers: analyzing the performance of web applications",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-12T14:30:00",
        "tags": ""
    },
    {
        "abstract": "In this talk, I describe what a hash function is, and how the unique properties of a hash function can be used to provide abstractions like the hash table.\r\n\r\nI will talk about bloom filters, a unique data structure that provides set membership information and extreme compression, at the cost of not being sure whether it is entirely correct. \r\n\r\nWe'll learn how to choose hash functions for data structures and for security, what an avalanching hash function is, and what differentiates a cryptographic hash function from a non-cryptographic hash function. \r\n\r\nWe will learn how modern web security is intimately tied to the humble hash function, how to hash passwords, and how _not_ to hash passwords. ",
        "authors": [
            "Curtis Lassam"
        ],
        "conf_key": 182,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/406/",
        "contact": [
            "curtis@lassam.net"
        ],
        "description": "Our trusty friend, the hash function, is as crucial to programming as linked lists or recursion, but it doesn't always get the press that it deserves. \r\n\r\nWe're going to talk about hash functions, some data structures involving hash functions, the stately bloom filter, and the security implications of password hashing. ",
        "duration": 30,
        "end": "2015-04-12T15:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Hash Functions and You: Partners in Freedom",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-12T14:30:00",
        "tags": ""
    },
    {
        "abstract": "Please see the outline, which combines the abstract with a detailed\r\napproach to how present this talk.",
        "authors": [
            "Jim Baker"
        ],
        "conf_key": 128,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/351/",
        "contact": [
            "jim.baker@rackspace.com"
        ],
        "description": "So how did we get to Jython 2.7 anyway? And what are our future plans?\r\nIn this talk, you will get a taste of how Jython works, some new\r\nfunctionality, and especially how Jython leverages both Python and\r\nJava to provide a very compatible solution.",
        "duration": 30,
        "end": "2015-04-12T15:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Getting to Jython 2.7 and beyond",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-12T14:30:00",
        "tags": ""
    },
    {
        "abstract": "**Introduction**\r\n\r\nWe start by motivating the running example I'll be using throughout this talk to illustrate the techniques: making a \"linguistic\" street map of Singapore. Why make this map? Why is there so much linguistic diversity among Singapore street names in the first place? I'll answer the latter question with a 2-minute history of Singapore presented via maps.\r\n\r\n**Building a baseline classifier with scikit-learn**\r\n\r\nNext we'll very rapidly go through the steps of building a baseline classifier with scikit-learn: this is basically the contents of the \"Working with Text Data\" tutorial. We'll do data wrangling with GeoPandas, establish a classification schema, build character n-gram features, select a classifier, perform the classification, and evaluate the baseline result.\r\n\r\n**Adding custom feature Pipelines**\r\n\r\nWe now look at ways of improving the classifier over the baseline. I'll show how to add custom features beyond those included in scikit-learn, how to build Pipelines for those features, and how to use FeatureUnion to glue them together.\r\n\r\n**Tuning hyperparameters with GridSearchCV()**\r\n\r\nWe then look at how to tune hyperparameters using GridSearchCV(). We'll discuss what happens under the hood when you use GridSearchCV(), and how to choose which hyperparameters to experiment with, focusing on Linear SVC as an example classifier.\r\n\r\n**Making the map**\r\n\r\nI'll outline the steps needed to go from the classification results to a whole map using OpenStreetMap data, with the heavy lifting largely provided by Mapnik, a C++ tool for developing mapping applications with Python bindings. It's actually easier than you might think!\r\n\r\n**Conclusion**\r\n\r\nWe'll recap what we've done and review which method of improving the baseline classifier worked best: more data, adding features, hyperparameter tuning, or swapping out classifiers?",
        "authors": [
            "Michelle Fullwood"
        ],
        "conf_key": 122,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/366/",
        "contact": [
            "michelle.fullwood@gmail.com"
        ],
        "description": "Have you built a classifier in scikit-learn with out-of-the-box features, been disappointed with the results, and wanted to know where to go next? This talk shows how to add your own feature Pipelines and how to tune hyperparameters using GridSearchCV. We'll apply this to the problem of classifying streetnames in Singapore by linguistic origin, and turn the results into a colour-coded street map.",
        "duration": 30,
        "end": "2015-04-10T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Grids, Streets and Pipelines: Building a linguistic street map with scikit-learn",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T14:35:00",
        "tags": ""
    },
    {
        "abstract": "Git is a powerful tool for describing and maintaining the history of a project, but most people never get beyond the basics. By giving you the ability to rewrite history (with the safety of never truly losing information), git allows you to craft a history that is more true to the *intent* of your changes, rather than one filled with countless \"oops\" and \"fixed typo\" commits. Of course, with great power comes great responsibility, and it is important to wield your time-travelling powers with restraint. In this talk, you'll learn how to clean up your history without confusing others, as well as how to recover if things go wrong.\r\n\r\nYou'll also learn more about the conceptual model behind git and how to bend it to your will. Once you understand how commits and branches really work, you can compose your git tools to do what you want. Need to insert a commit in the middle of a branch? See who introduced the bug two weeks ago that surfaced in production today? Resolve merge conflicts cleanly? Break a large commits into several smaller ones, or squash several smaller ones together into one? With git, you can do it.",
        "authors": [
            "David Baumgold"
        ],
        "conf_key": 88,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/343/",
        "contact": [
            "david@davidbaumgold.com"
        ],
        "description": "You know clone, commit, push, and pull. Now you're ready for the fun stuff. This talk will give you the advanced knowledge you need to take control of your git repository: rebase, cherry-pick, bisect, blame, squashing, and the reflog. You'll also get a better conceptual understanding of how git works, allowing you to chain these tools together to accomplish whatever task you need.",
        "duration": 30,
        "end": "2015-04-10T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Advanced Git",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-10T14:35:00",
        "tags": ""
    },
    {
        "abstract": "Every web framework out there comes with an ORM, but should you actually use it? An ORM makes it super easy to get up and running really quickly, but maintainers of growing database-backed applications almost always run into performance problems down the road.\r\n\r\nWhen this happens, what do you do? This talk's goal is to show you what actually happens under the hood when you make a query in an ORM like SQLAlchemy, and, by giving you the power to de-mask which SQL queries are being executed, build your intuition for when to use caution with an ORM. Sometimes, like in schema migrations, you may even want to just hand-craft the raw SQL yourself.\r\n\r\nThis talk is based off of real-world examples learned while building the [Nilas Sync Engine](https://github.com/inboxapp/inbox), which is available free and open source, so you'll be able to take a look at the results of these lessons and how the codebase has evolved to become more performant.",
        "authors": [
            "Christine Spang"
        ],
        "conf_key": 92,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/371/",
        "contact": [
            "christine@spang.cc"
        ],
        "description": "Database ORMs make it really convenient to pythonically query a database, but it's difficult to decide when to use them and when not to---and what the alternatives are. In this talk you'll learn strategies for deciding when and where to use an ORM, when to be cautious, and how to tell that you're doing the right thing, drawn from real-world lessons learned building the Inbox email platform.",
        "duration": 30,
        "end": "2015-04-11T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "To ORM or not to ORM",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T14:35:00",
        "tags": ""
    },
    {
        "abstract": "What with the proliferation of device/applications for remotely controlling everything from your lights to your coffee maker, and with the release of HomeKit in iOS 8, it's clear that companies big and small are getting into the home-automation game. But why just not do it yourself?\r\n\r\nIn this talk, I'll show you everything you need to know to turn your boring window-unit air conditioner into a wifi-enabled, remotely controllable smart-thermostat. With a couple components, a Raspberry Pi, and some handy Python libraries, you'll not only have the tools to make yourself a Smart AC, you'll be able to execute other cool home-automation projects you've dreamed up. (I'm thinking an alarm for the morning that starts my coffee pot.)\r\n\r\nYou do not need to have any previous experience with Raspberry Pi or hardware projects! I'll go over the simple circuits you'll make, tips for debugging hardware, and the libraries you'll need. I\u2019ll also cover how to set up a simple flask server that will allow you to communicate with your device from your web browser. I'll wrap up the talk with pointers to some excellent resources and a quick video demo of my Smart AC in action.",
        "authors": [
            "Miriam Lauter"
        ],
        "conf_key": 93,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/412/",
        "contact": [
            "lauter.miriam@gmail.com"
        ],
        "description": "Looking for a fun, useful Raspberry Pi project? Want to connect your household appliances to the internet? Come learn how to build your own 'smart' air conditioner using a Raspberry Pi, a bit of hardware, and, of course, Python. Plus, you can save energy and never have to come home to a sweltering bedroom again. ",
        "duration": 30,
        "end": "2015-04-10T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Make your own Smart Air Conditioner",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T14:35:00",
        "tags": ""
    },
    {
        "abstract": "[Wheels](https://pypi.python.org/pypi/wheel) are the new [standard](http://legacy.python.org/dev/peps/pep-0427/) of python distribution and are intended to replace eggs. Support is offered in pip >= 1.4 and setuptools >= 0.8. The wheel format is now the recommended way to ship Python packages on PyPI.\r\n\r\nWheels make it possible to very quickly install Python packages on all supported platforms. Packages with compiled extensions can be packaged as platform specific wheels (e.g. 32 bit Windows) so that users do not need a compiler or any other developer tool to `pip install` them.\r\n\r\nAs part as my involvement as release manager for the [scikit-learn](http://scikit-learn.org) project I have spent time and effort to setup an automated CI infrastructure that generates and tests wheel packages for all our supported platforms (Windows, OSX and Linux).\r\n\r\nThis setup makes it possible to support all recent Python versions (2.6+ and 3.3+), both on 32 bit and 64 bit architectures.\r\n\r\nThe goal of this talk is to share the experience and tools I used or developed along this journey.\r\n\r\nIn particular this talk will cover:\r\n\r\n- how to configure Travis CI to build and test wheel packages for Linux and OSX,\r\n\r\n- how to configure AppVeyor CI to build and test wheel packages for Windows,\r\n\r\n- how to embed third party dynamic libraries (`.dylib` or `.dll`) in a wheel   package on OSX and Windows to make it independent of non-Python dependencies,\r\n\r\n- how to setup 32 bit and 64 bit C/C++ and fortran compilers under Windows,\r\n\r\n- how to maintain a project specific wheelhouse using a public cloud container   such as Amazon S3, Rackspace Cloud Files, Microsoft Azure Blobs  or Google Storage.\r\n\r\n- how to automate PyPI releases to upload the artifacts generated by CI workers  for a specific tag of your project.\r\n\r\nHopefully by the end of this talk you will have all the necessary pointers and tools to help the [Python community build wheel packages](http://pythonwheels.com) for all the projects and all the platforms.",
        "authors": [
            "Olivier Grisel"
        ],
        "conf_key": 103,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/377/",
        "contact": [
            "olivier.grisel@gmail.com"
        ],
        "description": "Practical guide to build and test wheel packages for all platforms using free\r\nContinuous Integration services such as Travis CI (Linux and OSX) and AppVeyor\r\n(Windows).",
        "duration": 30,
        "end": "2015-04-11T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Build and test wheel packages on Linux, OSX & Windows",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T14:35:00",
        "tags": ""
    },
    {
        "abstract": "Learn how to extend your Python programs with high-performance functions written in Rust.\r\n\r\nPlus, get a brief overview of the Rust programming language, what it's good at, and why you might prefer it over C for your next project requiring low-level optimization.",
        "authors": [
            "Dan Callahan"
        ],
        "conf_key": 104,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/411/",
        "contact": [
            "dan.callahan@gmail.com"
        ],
        "description": "Rust is a new systems programming language from Mozilla that combines strong compile-time correctness guarantees with fast performance... and it plays nice with ctypes! Come learn how you can call Rust functions from Python code and finally say goodbye to hacking C!",
        "duration": 30,
        "end": "2015-04-10T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "My Python's a little Rust-y",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T14:35:00",
        "tags": ""
    },
    {
        "abstract": "Deployment is a simple idea in theory but can be difficult in practice.  Many mechanisms exist but few work very well with python being deployed across multiple operating systems in a [service oriented architecture](http://en.wikipedia.org/wiki/Service-oriented_architecture).\r\n\r\nOne issue we've faced with a [SOA](http://en.wikipedia.org/wiki/Service-oriented_architecture \"Not the Sons of Anarchy\") is that you can end up with many projects rolling their own deployment mechanism which results in many half-baked deployment pipelines.  This can create a large pain point in transitioning people from one team to another.  Bug fixes can be committed quickly but it can be a royal pain in getting the changes out and live.\r\n\r\nTo help alleviate that pain we've come up with a generic package-centric deployment strategy that focuses on Python but also supports other languages like NodeJS.  The deployment strategy leverages technologies like [Jenkins](http://jenkins-ci.org/), [Pip](https://pip.readthedocs.org/en/latest/), [Virtualenv](http://virtualenv.readthedocs.org/en/latest/), and [Fabric](http://www.fabfile.org/) to allow for quick deployments that result in code being isolated from other services and native libraries on the node.\r\n\r\nThis talk will introduce a deployment pipeline that uses Python packages as the main deployment strategy and the mess it helped clean up.  I will go into how the pieces fit together for this deployment, some of the successes had with this mechanism as well as some of the pain points in using it.\r\n",
        "authors": [
            "Dan Tracy"
        ],
        "conf_key": 166,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/389/",
        "contact": [
            "djt5019@gmail.com"
        ],
        "description": "Gone are the days where creating system packages or scp-ing tar balls were required for deployment.  With Pip, Fabric, and Jenkins we've  developed a pipeline to simplify deployments and rollbacks that dove-tails into configuration management and virtualization.  New machines can come fully deployed and ready to rock at a moments notice allowing you to scale out nodes quickly and painlessly.",
        "duration": 30,
        "end": "2015-04-11T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Ship it: Deployments with Pip",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T14:35:00",
        "tags": ""
    },
    {
        "abstract": "From day one, the Runscope architecture was built around the idea of small independent services that can be quickly written, deployed, and scaled up as we grow.  Core to this architecture are our service discovery and deploy tools.  Over time, we've standardized how we build and communicate with these services into two python libraries:  Smart-Service and Smart-Client.  \r\n\r\nThis talk examines the lessons learned from building these libraries as well as service building patterns found in other platforms.  We also present a detailed look at how Runscope has built over two dozen services, serving over 1 billion requests a month, all while deploying to our cluster over 20 times a day -- and more importantly how you can replicate this to help you build better systems.\r\n\r\nThe talk will show examples of Flask/Flask-Restful based servers and the important modifications we've made to help us operate dozens of services at scale.  We also will show code from our HTTP client that wraps Requests with service discovery, failover, and other useful features for reliably making API calls in our infrastructure.",
        "authors": [
            "Frank Stratton"
        ],
        "conf_key": 167,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/337/",
        "contact": [
            "frank@runscope.com"
        ],
        "description": "At Runscope we've standardized the idea of small independent \"smart\" services that can be quickly built, deployed, and scaled. This talk examines lessons learned from writing these services as well as patterns found in other platforms. We present a detailed look at the code that allow us to build dozens of services, serving billions of requests, while deploying to our cluster over 20 times a day.",
        "duration": 30,
        "end": "2015-04-10T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Smart services & smart clients:  How micro-services change the way you build and deploy code.",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-10T14:35:00",
        "tags": ""
    },
    {
        "abstract": "Using a Python Flask REST API web service for an AngularJS front-end application a team at Boston University will be delivering STEM (Science Technology Engineering and Mathematics) educational content for Deaf children, K-12.  (This work was funded by grant from the Commonwealth of Massachusetts) Python was chosen because of it's clarity, power, extensibility, and Pythonic personality.  This project complements our other initiative which is to resurrect and continue The Summer Academy started by Richard Ladner), an academically challenging program designed for deaf and hard-of-hearing students with skills in math or science who may be considering careers in computing, with the goal of encouraging them to consider college majors and careers in computing fields. The Summer Academy had occurred annually at the University of Washington (UW) since 2007-2012.  We are now re-visioning the Academy specifically as a Python Summer Academy for DHH to be held first in 2015 at Boston University and invite the Python community to share and take part.",
        "authors": [
            "en zyme",
            "Hakim Bouatou",
            "Jon Henner"
        ],
        "conf_key": 132,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/413/",
        "contact": [
            "enzyme@bu.edu",
            "hakimb@bu.edu",
            "jhenner@bu.edu"
        ],
        "description": "ASL, like Python, is a language which is both fun and powerful. We have used Python to build a tool, ASL-CLeaR (American Sign Language Concept Learning Resource)  for the DHH community which will teach STEM terminology using ASL exclusively. We are also building a summer program to teach Python in English/ASL to DHH students.\r\n",
        "duration": 30,
        "end": "2015-04-11T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Pythons are Deaf, So are Some Pythonistas",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T14:35:00",
        "tags": ""
    },
    {
        "abstract": "#### How to not read code\r\nThis talk will cover three strategies for exploring codebases that go beyond \"just read the code!\". I'll outline each strategy, provide tools that are useful for each one, and give a short demonstration of answering a real question using that strategy.\r\n\r\n1. Code as nature & the programmer as naturalist (with inspect/cinspect)\r\n2. Science! Hypothesis-driven exploration (with timeit)\r\n3. Code as architecture: Guided tours (with ack)",
        "authors": [
            "Allison Kaptur"
        ],
        "conf_key": 175,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/333/",
        "contact": [
            "allison.kaptur@gmail.com"
        ],
        "description": "Have you started to read the source code of CPython but not gotten as far as you wanted? Maybe you want to understand more about CPython but don't know where to begin. I'll present a number of strategies for getting more familiar with Python under the hood that go beyond \"just read it!\" This talk isn't about contributing - it's about getting into the code base and discovering interesting things.",
        "duration": 30,
        "end": "2015-04-11T15:05:00",
        "kind": "talk",
        "license": "CC",
        "name": "Exploring is never boring: understanding CPython without reading the code",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T14:35:00",
        "tags": ""
    },
    {
        "abstract": "#### Introduction\r\nPython developers often seem apprehensive about descriptors. This talk aims to remove some of the fear surrounding writing custom descriptors.\r\n#### Definition\r\nA [descriptor](https://docs.python.org/3/howto/descriptor.html) is a class that allows the programmer to define how given attributes are accessed and modified on an object. They define one or more of the methods `__get__`, `__set__`, or `__del__`. This allows the user to specify how attributes are declared and used with a greater deal of precision than a standard attribute declaration on an object.\r\n#### Common Examples\r\nSome relatively common examples of descriptors used in Python include decorators such as `@property` and `@classmethod`, which serve as a shorthand for relatively simple descriptors. Database Object Relational Mappers (ORMs) that interface with Python, such as used with Django, often take advantage of descriptors to simplify the declaration of attributes and control the data types being stored, which would otherwise be tedious given Python\u2019s duck typing. Ever get a read-only property error? This is often the side effect of a descriptor with a `__get__` method defined but no `__set__` method defined.\r\n#### Making your own custom descriptors to simplify code\r\nWith descriptors, Python developers can have greater control of code with less repetition. It is important to avoid circular loops which can occur when getting or setting attributes within the `__get__` or` __set__` variables within Python. And in case anything goes wrong, the appropriate Exceptions should be used to ease use and allow for debugging.",
        "authors": [
            "Laura Rupprecht"
        ],
        "conf_key": 120,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/393/",
        "contact": [
            "laura.rupprecht@gmail.com"
        ],
        "description": "The Python library uses descriptors frequently, but most developers overlook this feature. This talk will cover what a descriptor is, the current uses in the standard library, and how custom descriptors can be used in a developer\u2019s toolset to eliminate repeated code.",
        "duration": 30,
        "end": "2015-04-11T15:45:00",
        "kind": "talk",
        "license": "CC",
        "name": "Describing Descriptors",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T15:15:00",
        "tags": ""
    },
    {
        "abstract": "A property graph database represented by G = (V, E, \u03bb) is basically a set of vertices (V) connected by edges (E), where each element can contain properties (\u03bb) as key-value pairs. The most important thing of a graph database is that it provides index-free adjacency for fast global lookups in constant time, vs exponential time join-on-join in relational databases; while document databases (a.k.a. NoSQL) encourages denormalization and data embedding.\r\nMy favorite graph database is Titan, because it allows me to use the storage backend of my preference (Cassandra) and index backend of my preference (Elasticsearch). Titan also provides a seamless integration with Gremlin, which is the graph traversal language created for Blueprints to manipulate Property Graphs. However, Titan is written in Java, and Gremlin provides Groovy syntax. There are Java frameworks, like Rexster, that expose the graph database functionality through a REST API. Although this solution can work for simple use cases, as you need to execute more complex traversals, the Rexster API falls short because it provides just the basic CRUD operations (and read operations executes very simple traversals). For Python programmers, interfacing your program with Rexster API to communicate with Titan generates too much HTTP overhead, and it\u2019s limited to what Rexster functionality can provide. Instead, you can create your own a set of database models that expose Gremlin-like operations and inherit Blueprints Pipes architecture; and allows you to execute complex traversals and get the most of your graph database, without imposing a data model from your code.\r\nFor achieving this, we must follow especially the S part of SOLID design (Single responsibility principle). You want to create a models of vertices that ONLY return vertices belonging to the same namespace and only manipulate those vertices. The same principle applies for edges. Following this design principle, you can create factory classes for vertices and edges, that implement the most commonly used traversals (like g.v, g.V, g.V.has, g.out,g.outE, etc) and then create a set of models where each model correspond to a namespace (in the case of vertices) or a label (in the case of edges). Most of this is achieved by the correct use of Factory Pattern, Pipes and Filters and Decorators. ",
        "authors": [
            "Elizabeth Ramirez"
        ],
        "conf_key": 138,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/408/",
        "contact": [
            "eramirem@gmail.com"
        ],
        "description": "Creating and using models from a graph database can be quite different to the ones used for row/column/document-oriented databases, in the sense that the same query patterns could differ significantly in structure and performance. This session will present how to create models in Python for Titan property graphs, that allow you to manipulate graphs as if you were querying with Gremlin DSL.",
        "duration": 45,
        "end": "2015-04-11T16:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Graph Database Patterns in Python",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T15:15:00",
        "tags": ""
    },
    {
        "abstract": "\r\nBiology is entering an exciting time, where human genomes are fairly inexpensive to sequence, computer algorithms for analyzing the data are becoming more sophisticated, and databases for understanding genomic function are growing in size.  Suppose you get your genome sequenced \u2014 what\u2019s in there, how would you interpret it, what software might you use, and what kind of limits are there to the information you can pull out of your genome sequence?\r\n\r\nAll of the analysis will be done in an open github repo with the presentation built on top of an IPython Notebook, of course.  Also, many of the basic mapping and querying algorithms involved in genomic analysis are simple enough that I will provide Python pseucodode of them, as well as provide references to further discussions of the algorithms and databases.",
        "authors": [
            "Titus Brown"
        ],
        "conf_key": 180,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/410/",
        "contact": [
            "titus@idyll.org"
        ],
        "description": "We\u2019ve entered the era of the $1000 human genome, and soon it will be straightforward to get your own genome sequenced by a commercial company.  But what does the data mean? What information can you get out of your genomic sequence? And what are the barriers to deeper analysis?  What kinds of algorithms and databases are used in genomic analysis? All this, and more, will be revealed in this talk.",
        "duration": 45,
        "end": "2015-04-10T16:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "How to interpret your own genome using (mostly) Python.",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T15:15:00",
        "tags": ""
    },
    {
        "abstract": "3D printing is a powerful technology that excels at rapid prototyping and producing custom objects. It's easy to get started with 3D printing. All you need is a 3D model and the 3D printer will build it, layer by layer. You can print models on your own 3D printer, or rent one from local hackerspaces, schools, or universities. You can also outsource the printing by using one of the many online services.\r\n\r\nReady to 3D print? Let's make some models with Blender!\r\n\r\nBlender is an open source graphics suite that's great for creating and manipulating 3D models. It also features a rich Python 3 API. We'll explore how to use that API to programmatically create new models for 3D printing. You'll learn how 3D models are represented and how to create and manipulate a model through different API modules. You'll see example applications like 3D printing your own glasses.\r\n\r\n![][8]\r\n\r\nThe API is not only good for creating models, but also procedurally fixing unprintable models. You'll learn what makes models unprintable, the 3D printing constraints models must obey, and solutions provided by the API.\r\n\r\n![][9]\r\n\r\n  [8]: http://i1115.photobucket.com/albums/k552/caretdashcaret/2014-08/758b2c9b-3822-43f3-8664-fd0132c20204_zpsb8143665.jpg\r\n  [9]: http://i1115.photobucket.com/albums/k552/caretdashcaret/2014-07/Screenshot2014-07-13at74220PM_zpsbfbe4047.png\r\n",
        "authors": [
            "Jenny Cheng"
        ],
        "conf_key": 144,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/352/",
        "contact": [
            "caretdashcaret@gmail.com"
        ],
        "description": "3D printing is an awesome manufacturing process that makes physical objects from 3D models. Want to get started with 3D printing? Let's make some models to print! Learn how to create and manipulate 3D models using Python, Blender (an open source graphics suite), and the Blender API. You'll leave this talk with the basics to help you 3D print objects for the real world.",
        "duration": 30,
        "end": "2015-04-10T15:45:00",
        "kind": "talk",
        "license": "CC",
        "name": "3D Print Anything with the Blender API",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T15:15:00",
        "tags": ""
    },
    {
        "abstract": "There are currently three popular approaches to Python concurrency: threads, event loops, and coroutines. Each is shrouded by various degrees of mystery and peril.  In this talk, all three approaches will be deconstructed in a epic ground-up live coding battle. The core topics to be covered include:\r\n\r\n- Introduction to concurrency with threads.\r\n- How an event loop works\r\n- How coroutine-based concurrency works\r\n- The effect of the GIL\r\n- The problem with blocking (and workarounds)\r\n- Coordination with process pools and worker tasks.\r\n",
        "authors": [
            "David Beazley"
        ],
        "conf_key": 143,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/374/",
        "contact": [
            "dave@dabeaz.com"
        ],
        "description": "There are currently three popular approaches to Python concurrency: threads, event loops, and coroutines. Each is shrouded by various degrees of mystery and peril.  In this talk, all three approaches will be deconstructed and explained in a epic ground-up live coding battle.",
        "duration": 45,
        "end": "2015-04-10T16:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Python Concurrency From the Ground Up: LIVE!",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-10T15:15:00",
        "tags": ""
    },
    {
        "abstract": "Software engineering isn\u2019t just about writing code that correctly executes some task; it\u2019s also about writing code that is easy to use and maintain. A software module\u2019s receptiveness to use by end users or by other software isn\u2019t guaranteed and a particular danger to a module\u2019s usability is inappropriate coupling of the module to its dependencies, clients, and design assumptions.\r\n\r\nSometimes bad coupling happens when software is being written in a hurry and its design decisions are being driven by expediency. Sometimes bad coupling is a result of following bad advice. Sometimes bad coupling simply comes from mistakes.\r\n\r\nLoose coupling between software modules is good coupling. Loose coupling reserves freedom for you in the future as your software\u2019s needs and implementation change. We will share our experiences of dealing with tightly coupled systems written by others and how we have learned to create loosely coupled systems of our own.",
        "authors": [
            "Augie Fackler",
            "Nathaniel Manista"
        ],
        "conf_key": 165,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/381/",
        "contact": [
            "durin42@gmail.com",
            "nathaniel@google.com"
        ],
        "description": "Great software is made out of cooperating independent modules; unusable, incorrect, and bad software happen when modules don\u2019t (or can\u2019t) work together. What makes modules friendly or hostile? How do abusive relationships between modules happen? How can we write code that creates and maintains healthy connections to other code?",
        "duration": 30,
        "end": "2015-04-10T15:45:00",
        "kind": "talk",
        "license": "CC",
        "name": "Stop Sucking Me Into Your Drama: A Personal Appeal For Loose Coupling",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-10T15:15:00",
        "tags": ""
    },
    {
        "abstract": "In Python, we're trying to solve packaging problems in our own domain, but maybe someone else already solved most those problems.\r\n\r\nIn the talk I'll show how I develop and deploy Python projects that can be easily mixed with non-Python dependencies.\r\n\r\nhttp://nixos.org/ project will be demonstrated to replace technologies in our stack: pip, virtualenv, buildout, ansible and jenkins.\r\n\r\nFollowing technologies will be presented:\r\n\r\n- Nix: Package Manager and minimalistic DSL\r\n- NixOS: declarative Linux Distribution\r\n- NixOps: cloud deployment tool\r\n- Hydra: Continuous Integration server for Nix",
        "authors": [
            "Domen Ko\u017ear"
        ],
        "conf_key": 146,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/391/",
        "contact": [
            "domen@dev.si"
        ],
        "description": "Applying functional programming ideas to solve the problem of packaging software and configuration of systems in a stateless and deterministic way. Nix project addresses those problems in unique way based on academic research that has been applied to real world software collections in last 10 years.",
        "duration": 30,
        "end": "2015-04-11T15:45:00",
        "kind": "talk",
        "license": "CC",
        "name": "Rethinking packaging, development and deployment",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T15:15:00",
        "tags": ""
    },
    {
        "abstract": "Social app development challenges us to code for users\u2019 personal world. Users are giving push-back to ill-fitted assumptions about their own identity \u2014 name, gender, sexual orientation, important relationships, and many other attributes that are individually meaningful.\r\n\r\nHow can we balance users\u2019 realities with an app\u2019s business requirements?\r\n\r\nFacebook, Google+, and others are struggling with these questions. Resilient approaches arise from an app\u2019s own foundation. Discover how our earliest choices influence codebase, UX, and development itself. Learn how we can use that knowledge to both inspire the people who use our apps, and to generate the data that we need as developers.\r\n",
        "authors": [
            "Carina C. Zona"
        ],
        "conf_key": 149,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/426/",
        "contact": [
            "cczona@gmail.com"
        ],
        "description": "Development challenges us to code for users\u2019 personal world. Users give push-back to ill-fitted assumptions about their own name, gender, sexual orientation, important relationships, & other attributes that are individually meaningful. We'll explore how to develop software that brings real world into focus & that allows individuals to authentically reflect their personhood & physical world.",
        "duration": 45,
        "end": "2015-04-11T16:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Schemas for the Real World",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T15:15:00",
        "tags": ""
    },
    {
        "abstract": "If you aren\u2019t wowed by Python\u2019s super() builtin, chances are you don\u2019t really know what it is capable of doing or how to use it effectively.\r\n\r\nThere has been a great deal of misunderstanding about super(). This talk seeks to improve on the situation by:\r\n\r\n - providing practical use cases\r\n - giving a clear mental model of how it works\r\n - showing the tradecraft for getting it to work every time\r\n - concrete advice for building classes that use super()\r\n - favoring real examples over abstract ABCD diamond diagrams.\r\n\r\n",
        "authors": [
            "Raymond Hettinger"
        ],
        "conf_key": 174,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/419/",
        "contact": [
            "python@rcn.com"
        ],
        "description": "Python's super() is well-designed and powerful, but it can be tricky to use if you don't know all the moves.\r\n\r\nThis talk offers clear, practical advice with real-world use cases on how to use super() effectively and not get tripped-up by common mistakes.\r\n",
        "duration": 45,
        "end": "2015-04-10T16:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Super considered super!",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T15:15:00",
        "tags": ""
    },
    {
        "abstract": "It's happened to everyone: you change a line of code or CSS, your tests pass and you do a release, only to discover that something has broken horribly. Perhaps you forgot to test mobile? Perhaps your layout shifted by a pixel and wrapped in ways you didn't want. Or perhaps you shipped some test markup you didn't mean to.\r\n\r\nUnit tests rarely catch these sorts of errors because they only test the things you can imagine going wrong. They're good for testing things with well-defined inputs and outputs, i.e. functions. Web pages are messier than this. Visual diffs complement unit tests by checking every pixel on the page. If anything changed from the last \"golden image\", the test fails.\r\n\r\nVisual diffs have become increasingly common for web apps, but they can also provide a layer of safety for client- and server-side modules, from Flask plugins to JavaScript libraries.\r\n\r\nThe goal of this talk is to introduce visual diffs as a tool for testing libraries. I'll walk through the creation of a visual diff test and a set of golden images using [dpxdt][1], then show how they can be used to catch and debug problems. I'll also show how they can be included in version control to create a visual history of your code using image-aware diff tools like [git webdiff][2].\r\n\r\nFinally, I'll discuss how `git webdiff` exemplifies the possibilities of replacing traditional GUI apps with Python-based web servers which run on the user's machine.\r\n\r\n  [1]: https://github.com/bslatkin/dpxdt/\r\n  [2]: https://github.com/danvk/webdiff\r\n",
        "authors": [
            "Daniel Vanderkam"
        ],
        "conf_key": 141,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/395/",
        "contact": [
            "danvdk@gmail.com"
        ],
        "description": "Visual diffs are a great way to check for regressions on web sites which may be missed by unit tests. In this talk you'll learn how to run end-to-end tests on your client and server web libraries using a tool called dpxdt. I'll also show how you can combine it with web-based diff tools like \"git webdiff\" to quickly and confidently iterate on web tools.",
        "duration": 45,
        "end": "2015-04-11T16:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Make web development awesome with visual diffing tools",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T15:15:00",
        "tags": ""
    },
    {
        "abstract": "Full WSGI web application deployments involve a complicated collection of software tools that can be difficult for new developers to wrap their heads around. This talk is based on content laid out on the [Full Stack Python](http://www.fullstackpython.com/) which allows readers to navigate content in the order they choose. With this talk the audience similarly chooses the topics based on real-time text message and email voting.\r\n\r\nWe'll start with an overview of a typical WSGI deployment shown below.\r\n![][2]\r\n\r\nAfter explaining the components of web deployments and how they fit together, we will dive into five advanced deployment topics with 5-7 minutes of content per section. These topics include\r\n\r\n - hardening your web application against hackers \r\n - improving performance as web traffic scales up\r\n - tracking bugs and aggregating issues with logging\r\n - analyzing web traffic to better understand your users\r\n - scaling a development team to produce more features\r\n - implementing caching to minimize database access\r\n - automating deployments with configuration management tools\r\n - handling jobs asynchronously with task queues\r\n - sending email via SMTP and external web APIs\r\n\r\nAll topics above are prepared for this talk but only the ones chosen based on the audience's selections during the decision points screens will be covered. The decision points where the audience texts in will look something like the following screenshot. We will also incorporate voting by email address so those without cell phone service can also join in on choosing the path through the story.\r\n![][3]\r\n\r\n  [1]: http://www.fullstackpython.com/\r\n  [2]: http://www.fullstackpython.com/theme/img/simple-fsp-map.jpg\r\n  [3]: http://www.mattmakai.com/source/static/img/cyoa.jpg\r\n",
        "authors": [
            "Matt Makai",
            "Kate Heddleston"
        ],
        "conf_key": 169,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/336/",
        "contact": [
            "makaimc@gmail.com",
            "kate.heddleston@gmail.com"
        ],
        "description": "From servers and proxies to configuration management, the Web Server Gateway Interface (WSGI) deployment ecosystem is complicated for new developers. This choose your own adventure talk contains decision points for the audience to choose topics via text and email votes. Each choice leads down a separate path to explain different confusing WSGI subjects. Bring your phone or laptop to participate!",
        "duration": 45,
        "end": "2015-04-11T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Choose Your Own WSGI Deployment Adventure",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T16:15:00",
        "tags": ""
    },
    {
        "abstract": "The world is full of badly designed and difficult to use Web APIs. The REST architecture tries to make APIs better by defining a set of guiding principles that give APIs a predictable behavior modeled after the familiar HTTP protocol of World Wide Web fame.\r\n\r\nUnfortunately some of the REST principles are hard to grasp, so many APIs implement them incorrectly. For example, developers used to build APIs using other paradigms may find the focus on resources and the state transitions unconventional. Also, some of the REST principles go against well established practices for building traditional Web applications, so developers that transition to APIs usually apply techniques they learned before, such as those involving user sessions or cookies, without knowing or understanding why those are frowned upon in APIs.\r\n\r\nNow don't get me wrong, I have built bad APIs as much as the next person, so in this session I do not plan to point fingers at anyone. My intention is to explain the REST principles as I understand them and in plain English, so that the next time you design an API you have all the elements to decide if this approach is the right one for your project.\r\n\r\nI will sort the six principles by their level of complexity and then systematically go through them starting from the easier ones. For each one I will tell you what do you gain if you abide by it, and what do you lose if you don't. I will give special attention to the \"Uniform Interface\" principle, the most complex of the set, which I will cover as four sub-topics.\r\n\r\nTo conclude, I will do a live demonstration, where I will play the part of an API client and show you how to access an example API written in Python with the Flask microframework. Starting with the API documentation as a guide I will show you how to work with this example API using a command line HTTP client.",
        "authors": [
            "Miguel Grinberg"
        ],
        "conf_key": 90,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/355/",
        "contact": [
            "miguelgrinberg50@gmail.com"
        ],
        "description": "Writing a fully complaint REST API is hard, so hard it is too common for APIs to violate one or more of the REST architectural principles. In this talk I will describe the six REST principles, and I will tell you what happens if you don't follow them.",
        "duration": 45,
        "end": "2015-04-10T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Is Your REST API RESTful?",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-10T16:15:00",
        "tags": ""
    },
    {
        "abstract": "Follow along as we package and deploy a simple Python-based webapp on a CoreOS cluster... and then try to destroy it.\r\n\r\nDiscover how Fleet, Docker, and etcd keep the app running, even as we carelessly destroy VMs in the cluster.",
        "authors": [
            "Dan Callahan"
        ],
        "conf_key": 152,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/334/",
        "contact": [
            "dan.callahan@gmail.com"
        ],
        "description": "CoreOS is a new Linux distribution that makes it easy to deploy applications on dynamically scaled clusters of computers, and which has recently been embraced by infrastructure providers like DigitalOcean, Rackspace, and Google Compute Engine. Come learn how to package and deploy a Python application on this new, Docker-based platform.",
        "duration": 45,
        "end": "2015-04-10T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Fire your supervisord: running Python apps on CoreOS",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T16:15:00",
        "tags": ""
    },
    {
        "abstract": "Why does no one talk about the `bytearray`? With what great hopes was it added to the Python language? It might nearly be suspected of violating \u201cthere should be one obvious way to do it\u201d by supporting a whole parallel ecosystem of shadowy techniques for parsing data and accelerating I/O while dodging normal Python strings. What do these techniques really accomplish?\r\n\r\nThis talk will make practical and honest comparisons about the damage that `bytearray` techniques can do to your code as you contort it into ever more interesting shapes to try to minimize the number of times you copy data. After all, you reason, modern processors are usually starved for more data from RAM, and any technique that reduces the number of times string operations copy data into new regions of memory has got to be a win \u2014 right?\r\n\r\nNot nearly as often as you think. Through benchmarks and careful observation, we will learn when to identify those rare situations where sheer data copying is genuinely a limiting factor in your application\u2019s performance \u2014 and how, in those situations, to pull out the `bytearray` and let it roll. Its effect in PyPy and Cython will be compared to our mental model of how it improves performance in vanilla C\u00a0Python.\r\n",
        "authors": [
            "Brandon Rhodes"
        ],
        "conf_key": 125,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/418/",
        "contact": [
            "brandon@rhodesmill.org"
        ],
        "description": "Python string operations are profligate in their use of memory \u2014 the steps necessary to parse an HTTP request often make four or five copies of every incoming byte. But does it matter? This talk explores the \u201cbytearray\u201d, shows how its proper use dramatically reduces copying, but then uses metrics and visualizations to determine whether any increase in performance is worth the added complexity.",
        "duration": 45,
        "end": "2015-04-11T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Oh, Come On. Who Needs Bytearrays?",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T16:15:00",
        "tags": ""
    },
    {
        "abstract": "Software engineers are never done learning as our field is always changing. We are always beginners at some things and experts at others. Along the way from beginner to expert we ask a lot of questions, but it can be intimidating to ask for help. There are some common mistakes experts inadvertently make that make people feel self-conscious and stupid for getting help, when asking for help is actually the best thing they could do!\r\n\r\nThis talk will be split into two halves: giving and then getting technical help. It will give you concrete tools and tips for asking for help, and give you a checklist to see if you\u2019re currently making any of these common mistakes when it\u2019s your turn to answer questions. Improve your communication skills, get along better with your coworkers and colleagues, and learn faster than ever. ",
        "authors": [
            "Sasha Laundy"
        ],
        "conf_key": 112,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/394/",
        "contact": [
            "sasha.laundy@gmail.com"
        ],
        "description": "Software engineers are never done learning since our field is always changing. We are always beginners at some things and experts at others. Along the way from beginner to expert we have to ask a lot of questions, but it can be hard to get help. This talk gives concrete tools to help you ask with confidence, and highlights common expert mistakes that inadvertently make people feel foolish. ",
        "duration": 30,
        "end": "2015-04-11T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Your Brain's API: Giving and Getting Technical Help",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T16:30:00",
        "tags": ""
    },
    {
        "abstract": "Without virtual environments, your installed libraries can become a mess of spaghetti dependencies. To illustrate this point, we\u2019ll show a couple examples of what can go wrong if you don\u2019t use a virtual environment. Next, we\u2019ll briefly talk about what virtual environments are and how they work. Lastly, we\u2019ll set up sample projects using virtualenv and show you how easy it is to keep your installed libraries isolated for each project.\r\n",
        "authors": [
            "Renee Chu",
            "Matt Makai"
        ],
        "conf_key": 118,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/421/",
        "contact": [
            "renee.achu@gmail.com",
            "makaimc@gmail.com"
        ],
        "description": "Even though it\u2019s possible to program without using virtual environments, you can shoot yourself in the foot without them. This talk will start with an illustration of how not using virtual environments can mess you up as a programmer, and will walk you through a simple way to get started with good habits using virtualenv.",
        "duration": 30,
        "end": "2015-04-10T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Don't Make Us Say We Told You So: virtualenv for New Pythonistas",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T16:30:00",
        "tags": ""
    },
    {
        "abstract": "While Python is sometimes maligned as too slow for real world applications, many scientists, statisticians, and other data-oriented programmers find it to be efficient and powerful for large-scale data analytic tasks. The vast majority of this type of data analysis in Python is performed using NumPy, a package which extends Python with a powerful array-oriented computing interface. These arrays are flexible enough to handle all kinds of data: scientific imaging, sales records, statistical model parameters, logfile results, and more. The tools in NumPy form the core of other well-known Python data science packages such as Pandas, Scikit-Learn, SciPy, Matplotlib, and many more.\r\n\r\nDesigning efficient data-intensive algorithms in Python requires not just using NumPy, but using it effectively. In broad-brush, this amounts to replacing slow loops over datasets with more efficient vectorized operations. In this talk I\u2019ll cover briefly why loops in CPython tend to be slow, and why vectorizing these operations using NumPy can often provide speedups of 100-1000x in many cases. I\u2019ll go on to introduce the four practical concepts essential to fast data analytics using NumPy: *aggregation functions*, *universal functions*, *broadcasting*, and *fancy indexing*.\r\n\r\nWith a firm understanding of these four patterns, you\u2019ll be well on your way to writing fast & efficient data-intensive code in Python.",
        "authors": [
            "Jake VanderPlas"
        ],
        "conf_key": 153,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/373/",
        "contact": [
            "jakevdp@gmail.com"
        ],
        "description": "NumPy, the core array computing library for Python, provides tools for flexible and powerful data analysis, and is the basis for most scientific code written in Python. Getting the most out of NumPy, though, might require slightly changing how you think about writing code: this talk will outline the basic strategies essential to performing fast numerical computations in Python with NumPy.",
        "duration": 30,
        "end": "2015-04-10T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Losing your Loops: Fast Numerical Computing with NumPy",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T16:30:00",
        "tags": ""
    },
    {
        "abstract": "We often write code with bugs. They're usually shallow, simple things, but sometimes they're incredibly complex and take hours (or more) of our time to pinpoint their causes.\r\n\r\nThis talk explores these types of bugs, what type of code or environmental factors makes them so hard to track down. What tooling can make it easier to expose their cause, and what techniques can we use to better model these problems and increase our understanding earlier in the process.\r\n\r\nUsing real world examples of hard problems, I'll show how these techniques have debugged problems such as:\r\n\r\n* `posix_spawn` calls mysteriously failing to start a new process\r\n* Every few minutes a giant request spike to a website\r\n* A failure to make an HTTPS request to some websites",
        "authors": [
            "Alex Gaynor"
        ],
        "conf_key": 148,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/467/",
        "contact": [
            "alex.gaynor@gmail.com"
        ],
        "description": "Sometimes your programs have bugs. Often they're shallow things, simple AttributeErrors or TypeErrors. Sometimes they're large, complex, and nearly impossible to debug. This talk explores techniques for figuring these out.",
        "duration": 30,
        "end": "2015-04-11T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Techniques for Debugging Hard Problems",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T16:30:00",
        "tags": ""
    },
    {
        "abstract": "\"Neural Nets for Newbies\" is geared to provide clarity on what neural networks are, how to start using them and why they are valuable -- feature engineering. This talk is targeted to anyone who is passionate about understanding algorithms and code to define and leverage patterns in data.\r\n\r\nNeural network algorithms have a wide range of applications that handle complex and tough-to-model data sets. For example, they are extremely popular in image classification (e.g. identifying people, animals or other objects in photos) and were part of the Netflix challenge solution.\r\n\r\nIn the talk, I will cover a high-level history and breakdown the basic structure of a neural net. I will give an understanding on what to research further to implement a neural net in the real world. I'll list a variety of Python packages that you can use, and I\u2019ll show example Python code for running a simple neural net on your own based on the MNIST dataset (e.g. \"hello world\" of neural nets). Last, I\u2019ll briefly share where neural nets going in use and impact expectations.",
        "authors": [
            "Melanie Warrick"
        ],
        "conf_key": 96,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/350/",
        "contact": [
            "warrick.melanie@gmail.com"
        ],
        "description": "Neural networks have regained popularity in the last decade, but they get dismissed as being too complicated to understand and implement. This talk breaks down the neural net structure as simply as possible, so you have a framework on which to grow your knowledge in the space. I will put neural nets in the context of real-world applications and share Python packages and code where you can get started building your own. Coming out this talk you won't know everything about neural nets, but you will walk away with a solid foundation and some resources on where to go next to learn more.",
        "duration": 30,
        "end": "2015-04-10T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Neural Nets for Newbies",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-10T16:30:00",
        "tags": ""
    },
    {
        "abstract": "**The problem:** async applications must be tested as thoroughly as others, but the typical code flow is broken. \u201cDo something, then assert something\u201d no longer works in the obvious way. After your test code launches an async operation, it needs some way to know when to expect the operation to be complete. Developers inexperienced with async frameworks insert arbitrary sleeps into their tests to wait for the expected outcome, or they write awkward polling loops. The resulting code is unreliable, breaks good testing practices, and is illegible. There has to be a better way.\r\n\r\n**The fetch / wait pattern.** Tornado\u2019s \u201ctesting\u201d module introduced a pattern that allows async web applications to be easily tested. Your code does some setup and then fetches a URL from your application. Tornado then allows your test to wait cleanly, while the event loop completes processing your request. Finally, your test asserts the post-conditions.\r\n\r\n**Loop management.** The event loop must be shut down and recreated between tests to ensure all file descriptors and callbacks are cleared between tests. We\u2019ll see how to manage the loop when testing with Tornado and with asyncio.\r\n\r\n**Coroutine tests.** Tornado\u2019s \u201cgen_test\u201d decorator allows you to write tests as generators. We digress to explain asynchronous coroutines in general, then show how they vastly improve async tests\u2019 concision and reliability. Tornado helps you avoid some pitfalls with a few neat tricks, we\u2019ll see how those work. Then we see equivalent examples of testing asyncio applications with coroutines.\r\n\r\n**Don\u2019t sleep.** Sometimes a test requires time to pass, but calling time.sleep() in a test is slow, unreliable, and may block the event loop precisely when it needs to be running. The self-tests for asyncio demonstrate some clever patterns to simulate the passage of time while ensuring tests are fast and trustworthy.\r\n\r\n**Conclusion.** As async frameworks make their way into the mainstream of Python application programming, we must take the experience we\u2019ve gained with conventional testing and adapt it to a new paradigm. Don\u2019t reinvent the wheel: there are years of wisdom embedded in Tornado\u2019s and asyncio\u2019s testing tools. You can write fast, reliable, and elegant async tests if you use the right techniques.\r\n\r\n",
        "authors": [
            "A. Jesse Jiryu Davis"
        ],
        "conf_key": 150,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/404/",
        "contact": [
            "jesse@emptysquare.net"
        ],
        "description": "Async frameworks like Tornado and asyncio scramble our usual strategies for writing sequential code. This is most problematic when writing tests: how can you validate the outcome when you don\u2019t know when to expect it? This talk introduces you to methods and practices for unittesting async applications.",
        "duration": 30,
        "end": "2015-04-11T17:00:00",
        "kind": "talk",
        "license": "CC",
        "name": "Eventually Correct: Testing Async Apps",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T16:30:00",
        "tags": ""
    },
    {
        "abstract": "Do you litter your code with print and log statements to figure out why it isn't doing what you expected? If so, this talk is for you! The Python Debugger is an easy to use debugging tool once you learn the commands. For those that haven't been exposed to it yet, it may be overwhelming. This talk aims to cover all of the most commonly used commands for day to day debugging sessions. It will also briefly cover a few pdb alternatives to make debugging easier and ways to integrate pdb into popular editors.\r\n\r\nFor each command, the audience will learn what the command does, its shortcut and how it is used. The usage examples will be done by running pdb against code during the presentation. This will give the audience the chance to see live examples of how pdb can be used to debug and investigate Python code. Audience members should leave the talk with enough knowledge to start debugging and inspecting their own programs right away.\r\n\r\nWith the power of pdb in your toolbelt, you'll never be left in the dark, wondering why that code isn't doing what you expected. You'll be able to dig in and get to the bottom of the issue faster than ever.",
        "authors": [
            "Clayton Parker"
        ],
        "conf_key": 142,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/405/",
        "contact": [
            "clayton@sixfeetup.com"
        ],
        "description": "This talk will be an introduction to the most commonly used Python Debugger commands and what they do. Learn how to navigate and inspect code from the pdb prompt so you can better understand how it works. The Python Debugger is a valuable debugging tool for all levels of Python programmers. You should walk away being able to debug the next Python code you encounter!",
        "duration": 30,
        "end": "2015-04-11T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "So you think you can PDB?",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-11T17:10:00",
        "tags": ""
    },
    {
        "abstract": "This is an introduction to the (relatively) new asyncio module that arrived in the standard library of Python 3.4.\r\n\r\nThe documentation states that asyncio,\r\n\r\n> \"...provides infrastructure for writing single-threaded concurrent code using coroutines, multiplexing I/O access over sockets and other resources, running network clients and servers, and other related primitives.\" \r\n\r\nWhile we probably all understand much of the theoretical terminology in this definition, I intend to explore and illustrate what this means _in practice_ (with examples from a real-world networked application I have written using asyncio).\r\n\r\nTo this end, I will assume no previous knowledge of asyncio and present:\r\n\r\n - A description of the problem asyncio helps to solve;\r\n - An introduction to core asyncio concepts such as the event loop, co-routines, futures and network abstractions;\r\n - A description of how such concepts fit together;\r\n - The story of how I rewrote my distributed hash table library with asyncio (from Twisted);\r\n - Examples of real-world asyncio development: unit-testing, what's easy, what's hard, when shouldn't you use asyncio?\r\n - Where to find out more.\r\n\r\nBy the end of this introductory talk I hope you will have a desire to learn more about asyncio and perhaps give it a try in your own projects.\r\n\r\n",
        "authors": [
            "Nicholas Tollervey"
        ],
        "conf_key": 178,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/387/",
        "contact": [
            "ntoll@ntoll.org"
        ],
        "description": "This talk introduces the asyncio module. I'll cover what it's for, how it works and describe how I used it to write a real-world networked application (a distributed hash table).\r\nWe'll explore the event loop, co-routines, futures and networking with examples from my code.\r\nThis won't be an exhaustive exposition. Rather, attendees will grasp enough of asyncio to continue with their own studies.",
        "duration": 30,
        "end": "2015-04-11T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Lessons learned with asyncio (\"Look ma, I wrote a distributed hash table!\")",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-11T17:10:00",
        "tags": ""
    },
    {
        "abstract": "If we assume that more and more of the web will be built in the frontend with tools like AngularJS and Backbone.js, where does Python fit into that ecosystem? \r\n\r\nIf we love Python (and I do!) we want to position it well as part of that ecosystem. This means, among other things, that we want to best and most robust tools for building REST interfaces on the server side. These tools should be simple to pick up but powerful under the hood. \r\n\r\nToday's REST ecosystem in Python is underpowered for the world we're heading into. We'll cover the state of the art in REST, as well as the areas where our tools can do a better job to support us.",
        "authors": [
            "Jeff Schenck"
        ],
        "conf_key": 168,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/423/",
        "contact": [
            "jmschenck@gmail.com"
        ],
        "description": "As frontend web frameworks like AngularJS and Backbone.js take over, is Python on the server destined to be demoted to a basic REST interface? If we embrace our new JavaScript overlords, how do we ensure Python is best positioned for this new world of REST on the server? ",
        "duration": 30,
        "end": "2015-04-10T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "The REST Ascendancy",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-10T17:10:00",
        "tags": ""
    },
    {
        "abstract": "Supervisor is a popular Python application that lets you control and monitor process state on UNIX-like systems.\r\n\r\nWe'll talk about Supervisor's history and its most basic usage, including how to start and stop programs using supervisor and its most basic configuration.  We'll show its RPC API, which allows you to automate supervisor-related tasks.  We'll describe the concept of \"event listeners\" which are programs that receive messages from supervisor when some state has changed, and which can send email or other types of messages, and start, restart, or stop processes.  We'll show how real-world supervisor deployments might go, including how to use the Supervisor installation that's already on your operating system as well as using ``supervisord`` inside a Docker container.  Finally, we'll describe what's coming up in Supervisor's future.  \r\n",
        "authors": [
            "Chris McDonough"
        ],
        "conf_key": 164,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/380/",
        "contact": [
            "chrism@plope.com"
        ],
        "description": "Supervisor is a popular Python application that lets you control and monitor process state on UNIX-like systems.  This talk describes what it is, and how to use it effectively to make your application deployments better.",
        "duration": 30,
        "end": "2015-04-10T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Using Supervisor For Fun And Profit",
        "released": true,
        "room": "Room 517D",
        "start": "2015-04-10T17:10:00",
        "tags": ""
    },
    {
        "abstract": "This talk will consist of three main chunks:\r\n\r\n1. Background: The whats, whys, and hows of internationalization (i18n) and localization (l10n). We\u2019ll walk through the whole process of marking and scraping strings for translation, as well as how translated strings are served up. Our goal here is to get a good picture of what really happens to your l10n\u2019ed strings at runtime and discuss a few common pitfalls.\r\n\r\n2. i18n tools: What does Django natively provide to help us scrape and serve up strings in Python files and Django templates? (Simple, easy to use scripts (\u2022\u03c9\u2022)) How can we tackle other types of files, such as Mako or Underscore templates, or Javascript files? (Complex, easy to use scripts (\uff61\u25d5\u203f\u203f\u25d5\uff61))\r\n\r\n3. The eye of the translator, the thrill of the no-context fight: Now that we\u2019ve got the basics down, let\u2019s turn our attention to *how* our strings actually get translated. Can an open-source project obtain translations for free? (Yes!) What is the job of translator really like? (Like this: (\u256f\u00b0\u25a1\u00b0\uff09\u256f\ufe35 \u253b\u2501\u253b) What can we as developers do to both ease their burden and get more accurate translations? (I\u2019ll show you how to \u252c\u2500\u2500\u252c \u30ce( \u309c-\u309c\u30ce))\r\n",
        "authors": [
            "Sarina Canelake"
        ],
        "conf_key": 163,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/403/",
        "contact": [
            "robotsari@gmail.com"
        ],
        "description": "Have you heard about internationalization (i18n) and wondered what it meant? Perhaps your project already has i18n of its strings but you have a nagging feeling you could be doing it better. This talk will walk through the basics of i18n\u2019ing a Django project (but the principles apply to any project!), and how to make the process of localization (l10n) go more smoothly.",
        "duration": 30,
        "end": "2015-04-10T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "I18N: World Domination the Easy Way",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-10T17:10:00",
        "tags": ""
    },
    {
        "abstract": "What exactly are weak references anyway, especially when compared to\r\nnormal (hard) references? And do they really matter for the code we\r\nwrite?\r\n\r\nThat second question is easy to answer. You need to think about weak\r\nreferences if you are writing the following and want to avoid resource leaks:\r\n\r\n* Objects having reference cycles on CPython, such as a parent\r\n  referring to its children, and the child to its parent.\r\n  \r\n* Caches and lookup tables, which often come up in Python\r\n  metaprogramming. Using weak references for this scenario may be\r\n  applicable, regardless of the Python implementation. For example,\r\n  you might want to track the membership of all objects for a given\r\n  class. If you only have hard references, this isn't possible without\r\n  causing memory leaks.\r\n\r\nNow maybe someone has already done this hard coding work, but it's\r\nbest to know these scenarios to avoid resource leak bugs in the\r\nframework, module, or recipe you might be using. Especially in\r\nproduction!\r\n\r\nBut first, what exactly are weak references? Although weak references\r\nwere initially proposed in [PEP 205](http://legacy.python.org/dev/peps/pep-0205/) and implemented\r\nin Python 2.1 (released April 2001), they are still not widely known.\r\nSo it helps to try out some examples to build our intuition.\r\n\r\nFirst, let's import `WeakSet`. Many uses of weak references are with\r\nrespect to the collection provided by the `weakref` module:\r\n\r\n    from weakref import WeakSet\r\n\r\nDefine a class `MyStr` like so:\r\n\r\n\tMyStr(str):\r\n\t\tpass\r\n\r\nNext, let's construct a weak set and add an element to it. We then\r\nlist the set:\r\n\r\n\ts = WeakSet()\r\n\ts.add(MyStr('foo'))\r\n\tlist(s)\r\n\r\nAnd most likely we will see that it is empty - we get `[]`. Or at the\r\nvery least after a garbage collection with `gc.collect()`.\r\n\r\nWith a bit of thought, we realize that nothing was holding on to the\r\ninstance `MyStr(\"foo\")` - the point of a weak reference, including\r\ncollections that maintain only a weak reference to their contents like\r\n`WeakSet`, is that only strong references keep objects from being\r\ncollected. We can see this by adding a strong reference:\r\n\r\n\ta = MyStr('fum')\r\n\ts.add(a)\r\n\tlist(s)\r\n\r\nThis returns\r\n\r\n\t['fum']\r\n\r\nWe now have a variable `a` in our global namespace that's strongly\r\nreferencing this value. Of course if we delete this name, we might\r\nexpect the value to disappear, as it in fact is guaranteed to do,\r\nagain at least after a garbage collection:\r\n\r\n\tdel a\r\n\tlist(s)\r\n\r\nprobably still returns\r\n\r\n\t['fum']\r\n\r\nBut after a collection\r\n\r\n\tgc.collect()\r\n\tlist(s)\r\n\r\nthe resulting list is empty:\r\n\r\n\t[]\r\n\r\nSo now we have some understanding of the behavior, but why would this\r\nsort of thing even be useful?\r\n\r\nPerhaps the most important thing to know is that once we master the\r\nmechanics, with minimal fuss and just a few lines of code we can\r\nreadily apply to the problems they can solve. In particular this means\r\nsupporting caching/lookup tables without introducing memory/resource\r\nleaks, as well as reference cycle elimination on CPython.\r\n\r\nDjango uses weak references in the implementation of its\r\n[signal mechanism](https://docs.djangoproject.com/en/dev/topics/signals/):\r\n\r\n> Django includes a \u201csignal dispatcher\u201d which helps allow decoupled\r\n> applications get notified when actions occur elsewhere in the\r\n> framework. In a nutshell, signals allow certain senders to notify a\r\n> set of receivers that some action has taken place. They\u2019re\r\n> especially useful when many pieces of code may be interested in the\r\n> same events.\r\n\r\nSuch decoupling is a perfect usage of weak references. Although it is\r\ncertainly possible to compute this coupling between senders and\r\nreceivers on the fly, it's expensive to do, so caching is\r\npreferred. In Django's case, because the caching is implemented with a\r\n`WeakKeyDictionary`, cleanup is straightforward.\r\n\r\nBut there's at least one other usage to consider. Although CPython\r\ndoes support the collection of reference cycles, there are important\r\ncaveats:\r\n\r\n1. Such cycles can be only be collected upon the stop-the-world GC\r\n   collection. Without calling `gc.collect` directly, such collections\r\n   are run per the decision criteria in the `gc.set_threshold`\r\n   function, which has been further enhanced since 2.5 to support\r\n   generations. Suffice to say, it doesn't occur necessarily when you\r\n   would need it to, and certainly not on the basis of running out of\r\n   memory, or on a periodic basis.\r\n\r\n2. Using `__del__` with such cycles creates uncollectable garbage.\r\n\r\nAs a consequence, when creating numerous parent-child relationships,\r\nas seen in `xml.sax.expatreader` or previous/next links, as seen in\r\n`OrderedDict`, it is important to use weak references for one side of\r\nthe relationship, or else it's very easy to see problems arise. In\r\nparticular, `OrderedDict` uses `weakref.proxy` for previous links. By\r\ndoing so, using code automatically chases the extra level of\r\nindirection to the previous object; but the next link ensures that a\r\nhard reference is present, so the object doesn't disappear.\r\n",
        "authors": [
            "Jim Baker"
        ],
        "conf_key": 114,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/468/",
        "contact": [
            "jim.baker@rackspace.com"
        ],
        "description": "Working with weak references should not just be for Python wizards. Whether you have a cache, memoizing a function, tracking objects, or various other bookkeeping needs, you definitely do not want code leaking memory or resources. In this talk, we will look at illuminating examples drawn from a variety of sources on how to use weak references to prevent such bugs.",
        "duration": 30,
        "end": "2015-04-11T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": " A Winning Strategy with The Weakest Link: how to use weak references to make your code more robust",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-11T17:10:00",
        "tags": ""
    },
    {
        "abstract": "The brain is the most impressive computational device that we know about, and yet is just a collection of simple computational devices called neurons. Its power comes in the sheer number of neurons, and the even sheerer number of connections between neurons.\r\n\r\nHistorically, trying to simulate the brain meant trying to simulate an individual neuron accurately. Early simulation programs were implemented in C or C++, with custom scripting languages. I will show how Python bindings to these programs have made them significantly easier to use. I will also show more flexible tools for low-level simulation written entirely in Python, which have made brain simulation even easier -- it's possible to simulate thousands of complex neurons on a typical desktop computer!\r\n\r\nHowever, this is quite far off from the human scale of >100 billion neurons. How can we ever hope to reach this scale? Some research groups have created specific hardware to simulate neurons. These are called \"neuromorphic\" computing devices, and the creators of these chips have also turned to Python as a way to program their chips to run brain simulations.\r\n\r\nAt the University of Waterloo, we have been working on a new approach to scaling up brain simulations, and a new Python package to support that approach. Instead of focusing on biologically accurate neurons, we focus on how to connect neurons together such that they can compute interesting functions. Functions that we've implemented so far include recognizing digits in images, controlling a simulated arm, gambling, and solving a simple test of cognitive ability. I'll show how Python allows us to quickly simulate brain models that carry out these functions. I will also discuss how Python allows us to use those biologically accurate neurons, and even to take advantage of neuromorphic hardware, by only changing a few lines of code.",
        "authors": [
            "Trevor Bekolay"
        ],
        "conf_key": 158,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/398/",
        "contact": [
            "tbekolay@gmail.com"
        ],
        "description": "Simulating the human brain is often the subject of science fiction, but how close are we really? In this talk, I'll survey cutting edge research projects that use Python to simulate the brain, focusing on Nengo, which was used to build Spaun, the largest functional brain simulation to date.",
        "duration": 30,
        "end": "2015-04-10T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "How to build a brain with Python",
        "released": true,
        "room": "Room 511",
        "start": "2015-04-10T17:10:00",
        "tags": ""
    },
    {
        "abstract": "We've ported Python to run directly on hardware, without an operating system, based on the GRUB2 bootloader, as part of the BIOS Implementation Test Suite (BITS) project (http://biosbits.org).  We're using Python as a testing and exploration environment for hardware, BIOS, ACPI, and UEFI. In this talk, we'll explore the process of porting Python to a new platform, building an embedded Python as part of another project, recreating enough of libc and POSIX to run Python without an OS, extending CPython with Python itself rather than C, binding to platform-specific services using a foreign-function interface, accessing hardware, and rewriting bits of the CPython implementation and standard libraries for additional portability.\r\n\r\nThis talk includes a live demo of bare-metal Python, directly driving hardware.",
        "authors": [
            "Josh Triplett"
        ],
        "conf_key": 156,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/378/",
        "contact": [
            "josh@joshtriplett.org"
        ],
        "description": "We've ported Python to run directly on hardware, without an OS, as a testing and exploration environment for firmware, ACPI, and UEFI. This talk will explore porting Python to a new platform, embedding Python, recreating enough of libc and POSIX to run Python without an OS, and binding to platform-specific services. Includes live demo of bare-metal Python, directly driving hardware.",
        "duration": 30,
        "end": "2015-04-10T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Porting Python to run without an OS",
        "released": true,
        "room": "Room 710A",
        "start": "2015-04-10T17:10:00",
        "tags": ""
    },
    {
        "abstract": "SaltStack (Salt for short) is a system management platform written in Python.  In this session, we will start from the beginning.  We will learn how to install salt and get it set up on a system.  We will learn how to run commands from our Salt \u201cMaster\u201d to our Salt \u201cMinions\u201d.  We will also delve a little bit into the State system in Salt, which is Salt\u2019s take on configuration management.\r\n\r\nThis talk will give you the tools to get started managing your systems with Salt.  You\u2019ll be able to immediately begin using it to make your job of managing your servers easier.\r\n\r\nAssuming we still have time, we\u2019ll look a little deeper into what\u2019s going on underneath the commands we are sending, and discover just how easy it is to extend SaltStack for our specific needs, via custom execution modules and state modules.\r\n\r\nThis talk will be useful for anyone who administrates systems.  This includes the devops community, system administrators, and even people who want to use SaltStack for their personal servers.  It will also be a great introduction to one of the biggest Python projects on Github, for those looking for a great project to which they can contribute.\r\n",
        "authors": [
            "Colton Myers"
        ],
        "conf_key": 154,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/407/",
        "contact": [
            "colton.myers@gmail.com"
        ],
        "description": "Are you still using SSH to manage your servers? Deploying code manually with rsync? There\u2019s a better way. SaltStack is one of the latest and greatest tools for system management. Once you have a foundation of lightning-fast remote execution, you can build anything on top of it. Plus, it\u2019s written in Python, and easy to extend!",
        "duration": 30,
        "end": "2015-04-11T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Managing Your Infrastructure with SaltStack",
        "released": true,
        "room": "Room 517C",
        "start": "2015-04-11T17:10:00",
        "tags": ""
    },
    {
        "abstract": "As technical community managers we are faced with a unique set of challenges. Like most FOSS community members, we're often volunteers, but the work we do in moderating mailing lists, planning events, fielding project feedback and contributions, and being the public face of our communities can take an additional emotional toll. We do it because we love our communities, but we also are often guilty of neglecting our own very real needs in order to serve those communities. We end up feeling guilty, run down, inadequate, and ultimately burnt out.\r\n\r\nDoes this sound like you? Even if you don't do community management work, you might have run into some of the same frustrations. In this talk I'll share with you my own experiences in building and managing different communities. \r\n\r\nThrough my own lessons learned, I'll strive to help you think about ways to:\r\n\r\n- Recognize and handle burnout\r\n- Understand the causes of burnout and how they apply to your FOSS work\r\n- Build a vocabulary to talk and think about the challenges you face\r\n- Identify coping strategies that make sense for your unique situation\r\n- Avoid burnout next time around",
        "authors": [
            "Kathleen Danielson"
        ],
        "conf_key": 145,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/345/",
        "contact": [
            "kathleen.danielson@gmail.com"
        ],
        "description": "As technical community managers we are faced with a unique set of challenges. We do it because we love our communities, but we also are often guilty of neglecting our own very real needs in order to serve those communities. We end up feeling guilty, run down, inadequate, and ultimately burnt out.",
        "duration": 30,
        "end": "2015-04-11T17:40:00",
        "kind": "talk",
        "license": "CC",
        "name": "Avoiding Burnout, and other essentials of Open Source Self-Care",
        "released": true,
        "room": "Room 710B",
        "start": "2015-04-11T17:10:00",
        "tags": ""
    },
    {
        "abstract": "The application is still in development but will contain at least the following functionality:\r\n\r\n - \r\n\r\nSimple project status - unauthenticated \r\n-do task list with description of projects/due dates/ who is working on them\r\n\r\n - \r\n\r\n Authentication \r\n\r\n - User options (change username, password) \r\n\r\n**Roles**\r\n\r\n - Admin - can create projects/remove them/assign people\r\n            - can see all projects/tasks\r\n\r\n - Project Manager - can add tasks to project/remove them/ assign people\r\n             - can see only the tasks of project given to him/her\r\n\r\n - Project Team Member - can comment on tasks/ mark they are done\r\n-\tcan see only the tasks of project given to him/her\r\n\r\nTo see some of nVisium\u2019s previous open source projects please see the links below:\r\n\r\n - \r\n\r\nSwift.nV\r\nhttps://github.com/nVisium/Swift.nV\r\n\r\n - Grails.nV\r\nhttps://github.com/nVisium/grails.nV\r\n\r\n - RailsGoat\r\nhttps://github.com/OWASP/railsgoat\r\n\r\n - GoatDroid\r\nhttps://github.com/jackMannino/OWASP-GoatDroid-Project\r\n\r\n",
        "authors": [
            "Seth Law"
        ],
        "conf_key": 1465,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/465/",
        "contact": [
            "megan.bradley@nvisium.com"
        ],
        "description": "Django.nV is an intentionally vulnerable training tool built to help developers identify and test security vulnerabilities in the Django web framework. Django.nV application will be used to demonstrate attacks, defense, exploits, and resolution of security vulnerabilities. The vulnerabilities include, but are not limited to, the OWASP Top 10, mass assignment, and many more.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Django.nV: The Intentionally Vulnerable Django App",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "Without knowing a lot of Python making a game, which is fun to play, is a very achievable goal. Without knowing anything about programming, playing a game can be an accessible way to understand how programs work. Building, sharing and talking about games is great for starting discussions about what you are doing, why and how. This type of discussion, in turn, increases learning.\r\n\r\nThe poster will describe some different basic types of game. It will have specific examples of games that are within the reach of the novice programmer to design and build. The information people can take away will include the following.\r\n\r\n - Resources for learning Python by building games\r\n - Opportunities to learn through playing games\r\n - Libraries to support game-building\r\n\r\nI will be demonstrating **one** game using the **Raspberry Pi** with input and output interaction.\r\n\r\nThe poster will cover the many benefits I have found in building games to learn Python. A good way of involving (non-programming) friends, in what you have been doing, when locked into hours of weekend learning. A way of creating small, manageable projects that offer clear outcomes. Developing good practice by focusing on the end user of your programs. Practising concepts, such as: random, selection, interaction, data structures, and problem-solving.\r\n\r\nIt will encourage people to consider notions of success and failure, in the context of games, as winning and losing. I will be looking at what makes a game fun or playable. How these elements can be developed simply. Exploring ways of enticing the senses: visual, auditory and kinaesthetic feedback.",
        "authors": [
            "Corinne Welsh"
        ],
        "conf_key": 1464,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/464/",
        "contact": [
            "corinne@lilycat.co.uk"
        ],
        "description": "We learn best when we are relaxed, curious and enjoying ourselves. Without knowing a lot of Python making a game, which is fun to play, is a very achievable goal. Playing a game can help non-programmers to understand what a program is and how it works. I would like to invite people to consider the role of play in learning (and learning about) Python.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Perceptions of Play: learning Python through games",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "The [Pulp Project] is an open source content repository management system written in Python. Pulp makes it easy for administrators to push software from repositories to a large number of systems. It aids the user in performing many common tasks, such as promoting packages from development to testing and from testing to production with simple commands.\r\n\r\nPulp is also designed for integration. It features a documented REST API and an event notification system. By integrating with Pulp, users can use events to trigger other actions in their work flows, such as having a repository publish trigger deployment of a test system. Pulp also supports plugins so that various types of content can be supported and benefit from these work flows. Traditionally, Yum and Puppet repositories have been supported. The Pulp team has been developing further plugins for Docker and OpenStack repositories as well.\r\n\r\nRecently, [a new plugin set for Python packages][python] was created. Using these plugins, it is possible to create Python repositories and to upload Python source tarballs into them. After publishing, pip can be used to install those Python packages on remote systems. There is a lot of potential for further features, and the Pulp Project is seeking users and community contributions to expand what Pulp can do with Python packages. For example, Pulp could be used to manage virtualenvs on remote systems, or automatically synchronize packages from PyPI.\r\n\r\nThere are many possibilities, and we are very excited about the future of this plugin and the project. We are also interested in seeing third party plugins for other types being developed as we often get requests for many other sorts of content. View our [source code] on github, or read more about us in our [documentation]. Please stop by to learn about what we are doing and how you can get involved!\r\n\r\n[Pulp Project]: http://www.pulpproject.org/\r\n[python]: https://github.com/pulp/pulp_python\r\n[documentation]: http://www.pulpproject.org/docs/\r\n[source code]: https://github.com/pulp/pulp\r\n",
        "authors": [
            "Randy Barlow"
        ],
        "conf_key": 1463,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/463/",
        "contact": [
            "rbarlow@redhat.com"
        ],
        "description": "Pulp is an open source platform for managing repositories of content and pushing that content out to remote systems. It can be used to manage Yum, Puppet, and Docker content. A new plugin has been written for Python repositories. With this plugin Pulp can be used to host your own PyPI and much more. This session will demonstrate the use of this plugin and show how to extend Pulp for your needs.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Host Your Own PyPI With Pulp",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "The recent release of an OpenGL ES shader based version of the well known and widely used Visualization Toolkit [VTK](www.vtk.org) makes it possible to produce stunning and high performance state-of-the-art 3D visualizations on the iPad\u2122. On this poster, instead of using Kitware's C++ bridge, confusingly named [Kivi-viewer](http://kiwiviewer.org), I present how to embed and interact with a VTK view inside of a [Kivy](www.kivy.org) app, putting Python at the center of our medical development.",
        "authors": [
            "Samuel  John"
        ],
        "conf_key": 1462,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/462/",
        "contact": [
            "john.samuel@hzh-GmbH.de"
        ],
        "description": "I present a template that combines Kitware's [VTK](www.vtk.org) version for OpenGL ES with the [Kivy](www.kivy.org) multi-touch GUI framework for the development of a medical app in our setting for minimally invasive surgeries, targeting Apple's iOS but ultimately being platform independent thanks to Kivy. Also this is about how we drive innovation and produce medical class applications in Python.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "KivyMedPad -- A medical application template for VTK 3D applications using Kivy and Python",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "In the past one and half decade, technological developments have made it feasible to generate large volumes of heterogeneous biomedical data. \r\nBioinformatics is an interdisciplinary field that develops methods and software tools for understanding and mining these large-scale complex biological data. \r\nA major challenge in bioinformatics is the integration of data from different sources. Several efforts have been made to aid in this process, including: standard metadata annotation formats to describe the experiments ( [ISA-Tab][1] ), minimal information guidelines for reporting of biological and biomedical science ( [MIBBI project][2] ) and biological and biomedical ontology-based controlled vocabulary ( [OBO Foundry][3] and [BioPortal][4] ).\r\nHowever, the scientific bioinformatics community still struggles to bring these standards, guidelines, and ontologies straight into the wet-lab, to the workbench where the biological experiment is carried out.\r\n\r\n[LINCS][5], the Library of Integrated Network-based Cellular Signatures project, funded by the National Institutes of Health, is generating an extensive, multidimensional dataset designed to deeply assess complex biological systems. This dataset includes biochemical, genome-wide transcriptional, and phenotypic cellular response signatures to a variety of small-molecule and genetic perturbations. The aim is to create a sustainable widely applicable, and readily accessible resource to improve our understanding of complex human diseases such as cancer. \r\n\r\nHere we introduce Annot, a web application to capture the metadata, raw data, and processed data of biological studies, and to make it ready for sharing and integration. This first implementation is compatible with the latest [ISA-Tab][1] metadata annotation format and the minimal information guideline and ontologies suggested by the [LINCS metadata standards and data exchange specifications][6]. \r\n\r\nAnnot is written in Python 3.4, utilizing the Django 1.7 web framework with PostgrSQL 9.4 and Apache 2.4, running on a FreeBSD 10 operating system. \r\nOn the implementation level, each main element of the underling ISA structure ( investigation, study, assay ) and each ontology is represented by a single Django app. \r\nThrough this modular implementation, the interface could easily be adapted to fit the needs of other laboratories by swapping in and out assays and ontologies. New assays and ontologies can be integrated by using the existing ones as templates. \r\nOn the output side, we first focus on ISA-Tab compatible ISArchive to be able to share the entered data with other groups and mine the data with existing ISA-Tab-aware analysis software. In future versions, we will make use of Python 3 and the Django ORM to process, mine and analyze the entered data in explicit new ways.\r\n \r\nThe [source code][7] is distributed under the free and open source GPLv3 license through gitorious at https://gitorious.org/biotransistor/annot.\r\n\r\n\r\n[1]: http://www.isa-tools.org/  \"Investigation Study Assay Tabular format\"  \r\n[2]: http://mibbi.sourceforge.net/about.shtml  \"Minimum Information for Biological and Biomedical Investigations\"\r\n[3]: http://www.obofoundry.org/  \"the Open Biological and Biomedical Ontologies\"\r\n[4]: http://bioportal.bioontology.org/  \"National Center for Biomedical Ontology BioPortal\"\r\n[5]: http://www.lincsproject.org/  \"Library of Integrated Network-based Cellular Signatures\"\r\n[6]: https://www.ncbi.nlm.nih.gov/pubmed/24518066 \"PubMed abstract\"\r\n[7]: https://gitorious.org/biotransistor/annot  \"bIOtransistor annot source code repository\"\r\n",
        "authors": [
            "Elmar Bucher"
        ],
        "conf_key": 1461,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/461/",
        "contact": [
            "elmbeech@zoho.com"
        ],
        "description": "+ Annot is a web application to annotate bioscience experiments, to capture the experiments raw and processed data, and to make the experiments results shareable as ISArchive.  \r\n+ Annot is utterly modularly implemented to be adaptable to each laboratories specific needs.  \r\n+ Annot is written in Python 3 with Django 1.7.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Annot: A Django Web Application to Capture Bioscience Study Metadata and Data",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "[SymPy](http://sympy.org/en/index.html) is a computer algebra system written in pure python. It allows the user to create and solve complicated math quickly and easily.\r\n\r\nAs an added bonus, having software that knows about math allows for easy [code generation](http://en.wikipedia.org/wiki/Automatic_programming). This takes an equation and compiles it down to C, Fortran, or any other language to allow for fast evaluation. Because the equation was already derived by SymPy, there's no danger of typing errors in converting it to another language. SymPy handles that for you!\r\n\r\nThis poster session will cover the why and how of SymPy's code generation utilities. Topics covered include:\r\n\r\n- SymPy \"expression trees\" (very similar to how Python represents code as [abstract syntax trees](http://en.wikipedia.org/wiki/Abstract_syntax_tree)) \r\n- Code printing with the [visitor pattern](http://en.wikipedia.org/wiki/Visitor_pattern)\r\n- Wrapping C or Fortran code with Python\r\n- How Codegen can improve your workflow",
        "authors": [
            "Jim Crist"
        ],
        "conf_key": 1459,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/459/",
        "contact": [
            "crist042@umn.edu"
        ],
        "description": "Have you ever derived some math on paper, only to mistype it into your code? With the code-generation tools provided by SymPy, these errors are a thing of the past! Learn about how SymPy can help ensure your equations are correct, and also generate native code for fast evaluation. This poster session will cover how code-generation works under-the-hood, as well as demonstrate the features provided.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Generating Fast and Correct Code with SymPy",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "ClusterRunner enables lightning-fast test feedback by distributing tests horizontally across a large fleet of machines. ClusterRunner allows Box Engineering to run an eight-hour test suite in around three minutes, hundreds of times every day. It is [open source](http://www.clusterrunner.com/), implemented entirely in Python 3, and supports running test suites for virtually any language.\r\n\r\nClusterRunner is most useful to larger engineering teams struggling with longer and longer test feedback delays. It was designed from the bottom up to be easy to use and can be dropped in to an existing CI system. If you can run a single test or test file, you can use ClusterRunner to parallelize those tests. \r\n\r\nIt's able to utilize infrastructure efficiently by learning how long your tests take to execute and scheduling accordingly. ClusterRunner services communicate via a friendly REST API (built on Tornado!) which allows it to be both performant and extensible.\r\n\r\nClusterRunner is an excellent example of how Python makes it easy to build a distributed application consisting of multiple services communicating via REST API. Our poster session will include visualizations of how ClusterRunner breaks up and distributes test suites, and how it dynamically scales queued job execution into all available infrastructure.",
        "authors": [
            "Timothy Bozarth"
        ],
        "conf_key": 1458,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/458/",
        "contact": [
            "tbozarth@box.com"
        ],
        "description": "Maintaining prompt test feedback is a common challenge for fast-growing projects and engineering teams. ClusterRunner is a Python open source application we've developed at Box to run our suite of over 8 sequential hours of tests in ~3 minutes. ClusterRunner makes it insanely easy to horizontally scale test suites in any language across your entire infrastructure.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "End slow test feedback! Easy Horizontal Scaling with ClusterRunner",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "\r\nScientific simulations and experiments often generate results that can only be interpreted with the help of computer graphics. Even though Python packages do exist for three- or higher-dimensional data visualization, they are either limited to specialized applications or too general and thus inefficient.\r\n\r\nIn this poster session we present three applications that demonstrate the visualization capabilities of python and show why problems of different types require different approaches. Since still images cannot fully represent interactive applications, the poster will be accompanied by live demonstrations.\r\n\r\nThe visualization of molecules is a common problem and involves neither complex data preprocessing nor elaborate graphics. Based on GR3 and the [GR framework][2], [mogli][1] serves as an example of the typical ball-and-stick representations. These can be achieved with existing tools, and developing an end user application requires comparatively little effort.\r\n\r\nHowever, this is not the case for the visualization of Fermi surfaces, atomic orbitals, and other implicit functions defined on unstructured point sets. The resulting surfaces can easily be rendered, but their computation from raw data requires complex and time-consuming algorithms.\r\n\r\nIn analyzing neutron scattering experiments, we do not focus on the rather simple data preprocessing, but on volume rendering. Despite millions of rendered data points, acceptable frame rates can be achieved by utilizing modern graphics hardware.\r\n\r\n---\r\n\r\nExample Images:\r\n![][3]\r\nDNA rendered with mogli (also, see [html5 with WebGL][4])\r\n\r\n---\r\n\r\n![][5]\r\nd-orbital (also, see [html5 with WebGL][6])\r\n\r\n---\r\n![][7]\r\nneutron scattering data (also, see [movie][8])\r\n\r\n  [1]: https://pypi.python.org/pypi/mogli\r\n  [2]: http://gr-framework.org\r\n  [3]: http://pgi-jcns.fz-juelich.de/pub/media/dna.png\r\n  [4]: http://pgi-jcns.fz-juelich.de/pub/media/dna.html\r\n  [5]: http://pgi-jcns.fz-juelich.de/pub/media/orb_iso.png\r\n  [6]: http://pgi-jcns.fz-juelich.de/pub/media/orb_iso.html\r\n  [7]: http://pgi-jcns.fz-juelich.de/pub/media/qevis.png\r\n  [8]: http://pgi-jcns.fz-juelich.de/pub/media/qevis.mov\r\n",
        "authors": [
            "Florian Rhiem",
            "Ingo Heimbach"
        ],
        "conf_key": 1456,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/456/",
        "contact": [
            "f.rhiem@fz-juelich.de",
            "i.heimbach@fz-juelich.de"
        ],
        "description": "Increasing amounts of data have made graphical representations essential to the analysis of scientific simulations and experiments. Although there is presently no universal and efficient tool for three-dimensional data, Python is capable of scientific visualization. In this poster session, we present three applications, ranging from simple ball-and-stick molecules to complex volume rendering.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "from scientific.data import graphics: 3D-Visualization with Python",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "This poster draws upon my graduate studies in applied linguistics and my experience working with Python and the [Natural Language Toolkit (NLTK)](http://nltk.org), a Python library that provides a number of tools for working with language. The poster will demonstrate how the NLTK can be used to extract meaningful chunks of language from a text, specifically _noun phrases_, using regular expressions to carry out part of speech (POS) tagging. Relevant concepts in linguistics are introduced and illustrated using the NLTK.\r\n\r\nA fundamental idea for the presentation is _grammar as science_; audience members are inductively introduced to the idea of descriptive grammar and how to use language samples to extrapolate grammar rules & patterns. These skills are incredibly useful for anyone who works with text.\r\n\r\nThe poster contents will be made available online via an iPython notebook. A draft version of [the notebook](http://nbviewer.ipython.org/github/lukewrites/NP_chunking_with_nltk/blob/master/NP_chunking_with_the_NLTK.ipynb) and [its source](https://github.com/lukewrites/NP_chunking_with_nltk) are online now.",
        "authors": [
            "Luke Petschauer"
        ],
        "conf_key": 1449,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/449/",
        "contact": [
            "luke.petschauer@gmail.com"
        ],
        "description": "A look at how the Natural Language Toolkit (NLTK) can be used to identify meaningful information in a text. Learn what noun phrases are, why phrase chunking is useful for text analysis, and why grammar is more fun than you may think.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Linguistics 101 for Pythonistas: Why noun phrase chunking with the NLTK is awesome & useful.",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "From all the robots with statically stable gaits, quadrupeds are the hardest to program. They don't have huge feet to keep them stable, like the bipeds, and they don't have as many legs as hexapods. As a result, they have to move one leg at a time, and balance with their body to keep their center of gravity between the remaining three legs. If you add the fact that the order of moving their legs matters, and that they have to be able to react to stimulus and change their movemnts accordingly, you get an interesting programming problem.\r\nIn addition to that, a robot is an animated interactive system, not very different from a computer game. The only difference is that instead of moving pixels on the screen, you are moving servomotors -- but all the problems of running and synchronising multiple animations, while processing user input, remain. That is why many of the techniques used in computer games work well and can be used in robotics.\r\nFinally, there is the challenge (and fun) of designing and building a physical artifact, and having it move according to our programs. There are many challenges and a lot of experience to be gained, both in mechanical and electronic design.",
        "authors": [
            "Radomir Dopieralski"
        ],
        "conf_key": 1448,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/448/",
        "contact": [
            "pycon.us@sheep.art.pl"
        ],
        "description": "Programming a four-legged robot to walk around can be a challenge. I will show the robots that I have build using Raspberry Pi and Arduino, and I will talk about how I programmed them using Python and PyGame (and a little bit of C for the Arduino, of course).",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Making robots walk with Python",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "DistArray provides general multidimensional NumPy-like distributed arrays to Python. It intends to bring the strengths of NumPy to data-parallel high-performance computing. DistArray has a similar API to NumPy.\r\n\r\nDistArray is for users who\r\n\r\n - know and love Python and NumPy,\r\n - want to scale NumPy to larger distributed datasets,\r\n - want to interactively play with distributed data but also\r\n - want to run batch-oriented distributed programs,\r\n - want an easier way to drive and coordinate existing MPI-based codes,\r\n - have a lot of data that may already be distributed,\r\n - want a global view (\"think globally\") with local control (\"act locally\"),\r\n - need to tap into existing parallel libraries like Trilinos, PETSc, or Elemental, and\r\n - want the interactivity of IPython and the performance of MPI.\r\n\r\nDistArray is designed to work with other packages that implement the [Distributed Array Protocol]( Distributed Array Protocol).\r\n\r\nDistArray was started by Brian Granger in 2008 and is currently being developed at Enthought by a team led by Kurt Smith, in partnership with Bill Spotz from Sandia's (Py)Trilinos project.\r\n\r\n",
        "authors": [
            "Kurt Smith",
            "Robert Grant"
        ],
        "conf_key": 1442,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/442/",
        "contact": [
            "ksmith@enthought.com",
            "rgrant@enthought.com"
        ],
        "description": "DistArray is an up-and-coming Python package providing distributed NumPy-like multidimensional arrays, ufuncs, and IO to bring the strengths of NumPy to data-parallel high-performance computing (HPC). We build on widely-used Python HPC libraries and have introduced the Distributed Array Protocol to exchange arrays without copying with external distributed libraries like Trilinos.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "DistArray - Distributed array computing for Python",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "## Start building a \"CPython\" combo\r\n\r\n[3] A tuple of guitars - Reading source code, writing documentation, testing\r\n[2] Dueling banjos - Python 2.7 and Python 3\r\n[1] Ukulele - Focus on a module \r\n[and...] You\r\n\r\n##Key steps and resources\r\n1. Learn your craft - CPython developer guide; FAQ; Core mentorship list\r\n2. Sight reading the \"source\" code\r\n3. Tuning up your tools (editors, patches, mercurial, and issue trackers)\r\n4. Practice with Pythonistas (IRC, mailing lists, and users)\r\n5. Compose your code and perform \r\n\r\n",
        "authors": [
            "Carol Willing"
        ],
        "conf_key": 1452,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/452/",
        "contact": [
            "willingc@willingconsulting.com"
        ],
        "description": "A first time contribution to CPython has many parallels to learning to play a musical instrument. Instruction, practice, and mastery happen over time.  Effort, patience, and a sense of timing interplay to `Create CPython harmony.`",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "First time contributing to CPython:  A tuple of guitars, dueling banjos, a ukulele, and you",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "As an engineer, analyst, or scientist, sharing your work with someone outside of your immediate team can be a challenge. End-users embody many roles with a wide range of technical skill and often times no familiarity with Python or the command line. Findings, key results, and models are frequently boiled down to static graphs, tables, and figures presented in short reports or slideshow presentations. However, engaging research and data analysis is interactive, anticipating the users\u2019 questions and giving them the tools to answer those questions with a simple and intuitive user interface.\r\n\r\nBrowser based applications are an ideal vehicle for delivering these types of interactive tools, but building a web app requires setting up backend applications to serve up content and creating a UI with languages like HTML, CSS, and JavaScript.  This is a non-trivial task even for web-developers and can be completely overwhelming for anyone not familiar with web stack basics.\r\n\r\n[Spyre][1] is a web application framework for the python developer who may have little knowledge of how web applications works, much less how to build them. Spyre takes care of setting up both the front and back-end of your web application. It uses CherryPy to handle HTTP request logic and Jinja2 to auto-generate all of the client-side nuts and bolts, allowing developers to quickly move the inputs and outputs of their python modules into a browser based application. Inputs, controls, outputs, and the relationships between all of these components are specified in a python dictionary. The developer need only define this dictionary and override the methods needed to generate content (text, tables, and plots).\r\n\r\nWhile Spyre apps are launched on CherryPy\u2019s production-ready server, Spyre\u2019s primary goal is to provide a development path for simple light-weight apps without the need for a designer or front-end engineer. For example, Spyre can be used for\r\n1. rapid prototyping and building MVPs \r\n2. data exploration\r\n3. developing educational resources\r\n4. building monitoring tools\r\n5. presenting interactive scientific or analytical results to a non-technical audience\r\n\r\njust to name a few.\r\n\r\nAt Next Big Sound we recently used Spyre to build an app to visualize the effects of sampling parameter values on the volume of tweets collected from one of our data providers (see screenshot below).\r\n![][2]\r\nWeb applications like this can turn a highly technical process into a simple tool that can be used by anyone with any level of technical skill.\r\n\r\nAfter you\u2019ve finished the foundational parts of your project -- the data collection, data cleaning, exploration, modeling, and analysis -- Spyre provides a quick and simple way to package the results into an interactive web application that can be viewed by the rest of the world.\r\n\r\n  [1]: https://github.com/adamhajari/spyre\r\n  [2]: https://raw.githubusercontent.com/adamhajari/spyre/master/examples/screenshots/gnip_sampling_spyre_app.png",
        "authors": [
            "adam hajari"
        ],
        "conf_key": 1445,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/445/",
        "contact": [
            "adamhajari@gmail.com"
        ],
        "description": "Any data driven projects can benefit greatly from a simple, interactive, and easily accessible user interface. Whether your project is in the prototyping stage or you just want a way to quickly get your ideas and research to an audience unfamiliar with the command line, Spyre gives you all the tools you need to turn your python code into interactive web applications in under 10 minutes. ",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Building Simple Interactive Web Applications with Spyre",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "The NASA Astrobiology Institute has been in existence since 1998. It collects list of publications from its member teams as part of the annual reporting process. Various attempts have been made over the years to maintain and standardize the meta data for the publications in the database.\r\n\r\nMost attempts have required the hiring of part-time librarians to manually review and clean up records.\r\n\r\nThere have also been many years where the data was not reviewed or cleaned at all.\r\n\r\nAs the database grew to around 10,000 records, we knew the majority of the records have not been examined.  We also knew that this database would be of limited use for any bibliometric analysis until the records are cleaned and verified.\r\n\r\nThis poster will describe the challenges, the scope of the problem and the Python-based workflow that was developed during the summer of 2014 to continuously update and verify the publication citations in our database.",
        "authors": [
            "Shige Abe"
        ],
        "conf_key": 1443,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/443/",
        "contact": [
            "shige.abe@nasa.gov"
        ],
        "description": "The NASA Astrobiology Institute was established in 1998. It collects list of publications as part of its annual reporting process. To date, there are at least 10,000 publication citations. Each of these need to be validated especially when used for bibliometric analysis. This poster will show we finally solved this problem in 2014 using Python and free web services.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Maintaining over 15 years of publication data for the NASA Astrobiology Institute using Python",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "    The dynamic motions of biomolecules like DNA, RNA, and proteins are integral to our understanding of drugs, disease, and human health. By performing expensive supercomputer simulations, one can model the motion of proteins in a controlled manner not possible in a test-tube or petri dish. \r\n    While data science and statistical approaches are ubiquitous in the field of genomics, dealing primarily with large genetic sequence or expression datasets, these approaches are infrequently used in the field of structural biology. However, this paradigm is changing with advances in GPU computing and supercomputer availability, \r\n    In this work I present a novel approach, documented in the open-source repository [\"PandasMD\"][2] (New repo commit imminent!), to analyze time series data derived from supercomputer simulations by leveraging the functionality of Pandas. By applying approaches commonly used in data science, I am able to perform meta-analysis across different biological models and across different simulation repeats. In doing so I am able to test scientific hypotheses with improved statistical certainty over traditional analysis conducted in this field.\r\n    The application of this approach is demonstrated for an example protein, a voltage-gated ion channel found in human neurons, that culminated in a [peer-reviewed publication][3]. The generalization of this approach to a \"high-throughput\" methodology is discussed.\r\n\r\n  [1]: http://en.wikipedia.org/wiki/Molecular_dynamics\r\n  [2]: https://github.com/cing/ChannelAnalysis\r\n  [3]: http://www.ncbi.nlm.nih.gov/pubmed/23803856",
        "authors": [
            "Christopher Ing"
        ],
        "conf_key": 1441,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/441/",
        "contact": [
            "ing.chris@gmail.com"
        ],
        "description": "The dynamic motions of biomolecules like DNA and proteins are of primary interest in the study of health and medicine. By performing novel analysis on time series data from supercomputer generated models, I am able to test scientific hypotheses with statistical certainty rarely seen in this field. I apply this process to an example protein and discuss generalizations to a high-throughput workflow.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Nanometer-scale Pandas: A Data Science Approach to Structural Biology",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "Having written a desktop application in Python, you want to make it easy for users to install and run it. Most tools designed for this focus on trying to make an executable for your application, and hide as many files as possible, but this approach is brittle: 'frozen' applications often have problems that the same code doesn't have when run normally.\r\n\r\n[Pynsist](http://pynsist.readthedocs.org/en/latest/) is a new tool taking a different approach. It creates an installer which first installs the necessary version of Python, then unpacks the application code to regular files and directories, and creates shortcuts to run that application code in Python. Although there is no `myapp.exe`, the result looks and works like a 'real' application. In addition, since NSIS is available on other platforms, the developer can prepare Windows installers from a Linux or Mac computer.\r\n\r\nPynsist is an open source project, and it works with recent versions of Python 3, and Python 2.7.",
        "authors": [
            "Thomas Kluyver"
        ],
        "conf_key": 1440,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/440/",
        "contact": [
            "thomas@kluyver.me.uk"
        ],
        "description": "Pynsist is a new tool for distributing Python applications on Windows. Unlike other tools, it keeps your code as regular Python files and packages, so no special tricks are needed to load data files or run Python subprocesses. Thanks to NSIS, it's also practical to build Windows installers on Linux or Mac.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Who needs exes? Distributing Python apps as Python on Windows",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "Python is a popular and widely used programming language but its use is limited in certain cases.\r\nConcurrency is one of those cases when people look for an alternative. It's actually what happened at the start-up I work at before I joined. The co-founders looked for a solution in a functional programming language and chose to use Clojure.\r\nFunctional programming is now implemented in most programming languages and functional languages are getting more and more popular. For a junior developer learning a functional language as her/his second programming language completely make sense and I was up for the challenge! \r\nClojure is not so different from Python in its readability and might be one of the easiest functional languages to learn for a Pythonista. \r\nI would like to share my tips and tools I used for learning and contributing to a code base in Clojure.\r\n\r\nThere are several online resources to understand the paradigm of functional programming. The same can be said regarding Clojure but a good way to learn aside from diving into a codebase is to take part in a community. The Clojurians are much fewer than the Pythonistas but they are equally friendly. They are looking forward to grow their community and their meetups and dojos are well suited to beginners. At some point you have to throw yourself into this sea of parentheses so you'd better be well equipped! In that aim Emacs is by far the best suited text editor. After customising it with the right tools you shall fear no orphan parens!\r\n\r\nThis experience will help you progress and focus on writing more concise code with short and clear functions. You will be more comfortable and curious about implementing the functional features of the Python language. Getting always closer to the Zen of Python:\r\n\"\r\n   Beautiful is better than ugly.\r\n    Explicit is better than implicit.\r\n    Simple is better than complex.\r\n    Complex is better than complicated.\r\n    Flat is better than nested.\r\n    Sparse is better than dense.\r\n    Readability counts.\r\n    ....\r\n\"\r\n",
        "authors": [
            "\u00c9l\u00e9onore Mayola"
        ],
        "conf_key": 1439,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/439/",
        "contact": [
            "eleonore.mayola@ymail.com"
        ],
        "description": "Python is widely used but can be limiting. When switching to functional programming, Clojure is quite to Python.\r\nI'd like to share my journey of learning Clojure as a junior Pythonista. \r\nMy best advice includes meeting the Clojure community, using online resources and getting the right tools to dive into a sea of parentheses!\r\nSuch an experience will help you write more concise code.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "From Python to Clojure (and FP): a newbie's tale by Eleonore Mayola",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "We present [PEP 458](http://legacy.python.org/dev/peps/pep-0458/), a standard that we have been working on closely with DistUtils-SIG. PEP 458 proposes using [The Update Framework](http://theupdateframework.com/) (TUF), a software update framework [developed](https://isis.poly.edu/~jcappos/papers/samuel_tuf_ccs_2010.pdf) by security researchers (some from the Tor project), to transparently secure PyPI against attacks. TUF has been [ported to RubyGems by Square](http://corner.squareup.com/2013/12/securing-rubygems-with-tuf-part-1.html), and will soon be [used by the LEAP project](https://groups.google.com/forum/#!msg/theupdateframework/44Dai54l5G4/CW6Nw_bUnbwJ).\r\n\r\nPEP 458 proposes giving project owners a choice: either *claim* their projects (and sign for their own packages), or let PyPI instead sign for their packages. The implications are simple to understand. In either case, all projects will be transparently protected against man-in-the-middle attacks. In the worst case, if PyPI itself is compromised, then claimed projects are immediately safe because their packages cannot be tampered with without being detected by TUF.\r\n\r\nAll of this is transparent to project developers. Developers of a claimed project use the TUF [developer tools](https://github.com/theupdateframework/tuf/blob/develop/tuf/README-developer-tools.md) to easily sign for their packages. All other projects will simply let PyPI sign for their packages.\r\n\r\nAll of this is also transparent to end-users. When PEP 458 is deployed on PyPI, users who use pip will not be able to tell that they are using TUF at all to securely download packages, _except_ when there is a security problem, in which case TUF would halt and report an exception instead of allowing a potentially compromised package to be downloaded and installed.",
        "authors": [
            "Trishank Karthik Kuppusamy"
        ],
        "conf_key": 1438,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/438/",
        "contact": [
            "tk47@nyu.edu"
        ],
        "description": "We present our ongoing work on PEP 458 to secure PyPI against a compromise. Specifically, we are working to secure PyPI such that even if attackers infiltrate it, they cannot tamper with (without being caught) projects that have chosen to sign for their own packages.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "PEP 458: Surviving a Compromise of PyPI",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "Machine translation is considered the holy grail of Natural Language Processing (NLP). The hope of that some day we would be able to automatically translate a foreign language into our native language. The wish that we can have a babelfish device that can interpret live. The day have come where we would be able to perform machine translation in python, within our favorite NLP toolkit, Natural Language ToolKit (`NLTK`)\r\n\r\nWe introduce some basic knowledge of Statistical Machine Translation (SMT) with (i) the _phrase-based machine translation_ paradigm, (ii) _noisy channel alignment model_, (iii) _ngram language models_ and (iii) _log-linear decoding model_.\r\n\r\nThereafter, we guide the users step-by-step through the SMT processes with code-snippets from the `align` and `translate` module in the NLTK toolkit. Firstly, we present the word-alignment models available in the NLTK `align` module  and then we show how to output the phrase-table with the phrases' probabilities. Finally, we introduce the stack-based decoder that produces the final translated output.\r\n\r\nBefore concluding, we compare the current performance (in speed and accuracy) of the `NLTK` stack decoder with the reigning machine translation toolkit, `Moses`\r\n",
        "authors": [
            "Liling  Tan"
        ],
        "conf_key": 1436,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/436/",
        "contact": [
            "alvations@gmail.com"
        ],
        "description": "NLTK toolkit is the de facto for text analytics and natural language processing for python developers. NLTK's recently extended `translate` module makes it possible for python programmers to achieve machine translation capabilities. This poster introduces the basic components of Statistical Machine Translation and demonstrates that machine translation is indeed achievable by mere mortals.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Statistical Machine Translation with NLTK ",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "This poster and interactive demonstration will show how the RtMidi Python library can be used to easily create a virtual MIDI device on compatible operating systems. Such a virtual device can be connected to any virtual or hardware device that communicates via MIDI, including synthesizers, drum machines, controllers, and digital audio workstations. The demonstration will consist of three example projects that use virtual MIDI devices:\r\n\r\n- The first example is a command-line MIDI keyboard that implements a variety of special functions (such as sustain pedals) and an entirely customizable keyboard layout. This can be considered a \"base\" RtMidi project from which others can spring.\r\n- The second example is a web application that allows MIDI messages to be triggered via API calls, thus creating a means for telematic (long-distance) music performance.\r\n- The third example is an interactive MIDI visualizer\u2014a pyprocessing/Pyglet program that receives MIDI messages from a hardware controller and uses them to generate interesting animations. Because the visuals can respond to general MIDI control messages instead of just musical notes, this project has extramusical implications. ",
        "authors": [
            "Decky Coss"
        ],
        "conf_key": 1435,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/435/",
        "contact": [
            "coss@alum.hackerschool.com"
        ],
        "description": "This is a demonstration of how Python can be used to communicate with electronic musical instruments and devices using the MIDI protocol. It will show how a virtual MIDI device can be used as the base for a multitude of applications related to performance and play, from simple command-line music keyboards to interactive visual art installations.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Building a Python MIDI Controller",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "**Nodjango**, a portmanteau of _Node_ and _Django_, is a simple library to add websockets to Django. Rather than complicatedly rolling a Django websockets server in Python, this library simply connects to a Nodejs socket.io server as a client, and exposes certain Python services like the Django ORM over this websocket. There are a lot of rich resources for developing single-page applications across the gulf in the Javascript ecosystem, and I sought (and developed) a simple way to develop Nodejs/Angular/socket.io applications using the same Django framework modules I've come to love: GeoDjango ORM, tastypie RESTful API resources, South migrations, etc.\r\n\r\n### Sample stack\r\n\r\n- *Django* WSGI service listens for requests on port `8000`\r\n-  *Nodejs* listens on both ports `80` and `3044` for socket.io connections\r\n- *Nodejs* listens on port 80 to proxy requests matching `/` to `127.0.0.1:8000`\r\n- **New** *Django* socket.io client connects to `127.0.0.1:3044` and listens for ORM requests from the *Nodejs* application (server *or client* !)\r\n\r\n### Danger zone\r\nBy connecting Django to socket.io, it becomes possible to do crazy not-yet-secure things in client-side javascript like so:\r\n\r\n    <script type=\"text/javascript\">\r\n        socket.emit('django_orm', {\r\n            callback: 'django_orm_response',\r\n            app: 'my_application',\r\n            model: 'my_model',\r\n            method: 'get',\r\n            kwargs: {\r\n                'id': 1\r\n            }\r\n        });\r\n    \r\n        socket.on('django_orm_response', function(payload){\r\n            jQuery('#username').val(payload.username);\r\n        });\r\n    </script>\r\n\r\n### Next steps\r\nI have the MVP working where I manually configure this stack and daemonize the various processes.\r\n\r\nUltimately, I want to package the entire Nodejs proxy, websockets, `npm`, and other dependencies into a Python package that can be installed into any virtualenv (using [virtual-node](https://github.com/elbaschid/virtual-node). Then, overload the `python manage.py runserver` command to possibly start this complete stack with the front-matter proxy listening on `80` or `8000` as expected, with socket.io. Then, with only `pip install nodjango` and adding the app your Django project's settings you can start writing client-side javascript that interacts with the Django ORM.",
        "authors": [
            "Patrick Paul"
        ],
        "conf_key": 1434,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/434/",
        "contact": [
            "patrick@gridpar.com"
        ],
        "description": "Nodjango, a portmanteau of Node and Django, is a simple module to add websockets to Django. Rather than complicatedly rolling a Django websockets server in Python, this library simply connects to a Nodejs socket.io server as a client, and exposes certain Python services like the Django ORM over this websocket to the Nodejs application. A proxy routes non-websockets traffic to the Django webserver.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Nodjango, websockets with Django and Nodejs",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "How good can one jumpstart to do interesting real world analysis and prediction with in the python eco system?\r\n\r\nHow close can we get to yahoo\u2019s predictions? Can we beat them with open source machine learning/statistics tools? (we have not yet bet them as the time of writing.)\r\n\r\nFantasy Football is an online competition where users compete against one another as general managers for a virtual team. The players in the virtual team's performance is based on their real world performance. Each week, users are able to perform different actions, simulating professional football organization. Fantasy football has vastly increased in popularity, mainly because fantasy football providers such as ESPN, Yahoo! Fantasy Sports, and the NFL are able to keep track of statistics entirely online. The virtual teams are ranked by using the performance of the real world games, therefore predicting the real world performance of players is can lead to an advantage for the virtual general manager.\r\n\r\nUsing our fork of NFLGame (we ported the library to Python 3) to directly get statistics from NFL Game Center, we are able to produce a big pandas panel data structure of historic performance of players. This data structure is much more convenient for explorative data analysis and further processing than REST (web) APIs. We started directly with Python 3.4 for this project and the libs and tools we use include IPython, numpy, scipy, pandas, seaborn/matplotlib, sklearn, requests and python-yahooapi.\r\n\r\nFrom simple counting over correlation analysis to building models as a basis for statistical evaluation and machine learning tools (provided by sklearn), we are addressing our main question: How important are carefully hand-crafted performance models for the different learning algorithms vs. how far can we get by \"counting numbers\"?\r\n\r\nWe plan to open source the IPython notebook, since this setup and data preparation took a significant amount of time (longer than we estimated! Surprise, surprise!), before we were able to start with the more interesting part of this project. In the future others may perhaps want to reuse this basis to improve the predictions or try out other statistical models.",
        "authors": [
            "Samuel  John",
            "Gregory Sieranski"
        ],
        "conf_key": 1433,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/433/",
        "contact": [
            "john.samuel@hzh-GmbH.de",
            "greg@wonbyte.com"
        ],
        "description": "How far can we get with statistical and machine learning tools of the Python eco system to tackle an interesting real world question: predicting the performance of individual NFL players based on historic data. In the rise (hype?) of \u201cbig-data\u201d, how important are good models to train a predictor vs. just taking the brute-force approach of checking all correlations to perform the predictions?",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "faNFL - Exploring the possibilities of predicting NFL player performance for Fantasy NFL",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "How UCF (University of Central Florida) built a free proctoring solution for their learning management system.\r\n\r\nWe used the LTI standard which is incorporated into our Learning Management System, the open source LMS Canvas by Instructure.\r\n\r\nUsing HTML5 and custom javascript to embed webcam video into the test page itself, building a django app to store, display, and encode video to instructors.\r\n\r\nFiguring out storage requirements for a university with over 50,000 students.\r\n\r\nGathering faculty and student feedback.",
        "authors": [
            "Shea Silverman",
            "Elizabeth Williams"
        ],
        "conf_key": 1432,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/432/",
        "contact": [
            "shea.silverman@ucf.edu",
            "elizabeth.williams@ucf.edu"
        ],
        "description": "How UCF built a free proctoring solution for their learning management system.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Building a Proctoring Solution in Python",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "Historically, Python is based on a teaching language called ABC that was in use in the 1980s. Therefore Python from its origin was created as a powerful educational language that also has multipurpose applications outside education. Science and engineering (S & E) have benefited so far from the use of Python as a teaching/learning and research software especially with the creation  of several modules such as NumPy, SciPy, SymPy, Matplotlib and VPython and even a scientific version (Python x,y) which simplifies scientific computations, modelling, simulations and visualizations. Further, being a free and open source programming software creates the possibility that any user connected to the internet can download the entire package (including the latest version!) into any platform, install it and immediately begin to use it. These are some of the motivations for setting up the Python African Computational Science and engineering Tour (PACSET) Project  with the vision and mission of easing the learners as well as expert programmers into programming with Python and to use it for modeling, simulation and visualization to aid the teaching/learning process and research in Africa. At PACSET, we encourage the individuals to develop their own codes. However, we observed that teaching people to develop their own codes before using Python for teaching is more tasking than exposing them to using Python programmes and once have found Python captivating, they are more eager to learn and consequently begin to develop their own programmes. Therefore, one of our long time study is to develop compendia of Python teaching programmes in various disciplines of S & E. In the study here, a compendium of Python programmes for teaching physics is presented.",
        "authors": [
            "Godfrey Akpojotor"
        ],
        "conf_key": 1431,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/431/",
        "contact": [
            "akpoji@yahoo.co.uk"
        ],
        "description": "Computational activities now constitute a third pillar in science and engineering (S & E) in addition to theory and experiment. Python African Computational S & E Tour (PACSET) is to ease the learning of programming as well as modeling, simulation and visualization with Python to aid teaching/learning/research in Africa. Our study here is on a compendium of Python programmes for teaching physics",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "PACSET compendium of Python programmes for teaching physics",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "It used to be that newcomers to our novice-friendly IRC channel, many of whom had never used IRC before, would say hello, get discouraged, and leave before we even noticed they were there. Our solution? WelcomeBot, an IRC bot written in Python, who greets newcomers and alerts channel regulars to their presence. \r\n\r\nWelcomeBot supports our community by making implicit knowledge explicit. It gives newcomers guidance in understanding how IRC works as well as illuminating the social structure of our particular channel. Its simple structure also makes it a good first project for newcomers to open source to contribute to.  WelcomeBot\u2019s documentation contains introductions to concepts like unit tests, regular expressions, and basic network protocol and explains how they\u2019re implemented through python libraries.",
        "authors": [
            "Shauna Gordon-McKeon"
        ],
        "conf_key": 1430,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/430/",
        "contact": [
            "shaunagm@gmail.com"
        ],
        "description": "WelcomeBot is an IRC bot written in Python who greets newcomers to a channel and alerts channel regulars to their presence. WelcomeBot has become a valued part of the community, with newcomers not only benefiting from it but contributing to its code and design.  This poster talks about WelcomeBot, how it works, and its role in our community.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Welcome, Bot",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "The Global Health Delivery Project at Harvard University developed and launched a web-based, open-access platform in 2008 to serve health care delivery professionals around the globe. The platform, [GHDonline][1], was built on the Django web framework.\r\n\r\nThe core of the GHDonline platform is a discussion-based forum that provides interaction via email, a feature we developed to serve the needs of our users in low-resource settings. On this base platform, we have built modules for:\r\n - finding Tuberculosis infection control specialists in resource-limited countries\r\n - asynchronous teleconsult for difficult clinical cases\r\n - global, public virtual conferences (\"Expert Panels\")\r\n - community management\r\n - data analytics & reporting\r\n - digital badges to standardize professional health care learning & credentialing\r\n\r\nThis poster will demonstrate how we built these modules and how we are considering opening our API so that others might build on our platform. We are hoping to meet others who are interested in global health and discuss how this platform could be extended.\r\n\r\n  [1]: http://ghdonline.org/\r\n",
        "authors": [
            "Aaron C. Beals",
            "Aaron VanDerlip",
            "Rebecca Weintraub"
        ],
        "conf_key": 1428,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/428/",
        "contact": [
            "abeals@gmail.com",
            "a@notabot.org",
            "rebecca@globalhealthdelivery.org"
        ],
        "description": "Over the past seven years, the Global Health Delivery Project at Harvard University has built a knowledge-sharing platform to serve those working in global health. We adopted Python, by way of Django, as the core language of our platform in 2008. We're hoping to raise awareness of our project and see how opening our API or code base might allow others to build on what we've created.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "How Python is Improving Global Health ",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "#The 5 advantages of Plone 5\r\n\r\nWe're proud to announce Plone 5, the latest version of our state-of-the-art open source CMS. It's faster, more powerful and more beautiful than ever.\r\nPlone is a polished user-friendly content management system. If you are already familiar with Plone, you'll find that Plone 5 is a rewarding upgrade that delivers immediate benefits to end-users, content editors and developers alike. If you're new to Plone, welcome aboard! We think you're going to like what you see.\r\n\r\n##ENTERPRISE INTEGRATION CAPABILITY\r\nPlone is a team player. From SQL-based systems to Single\r\nSign On, Plone can connect with your existing\r\ninfrastructure.\r\n\r\n##FLEXIBLE WORKFLOWS\r\nUse Plone's advanced content workflows to customize\r\ncontent development and sharing.\r\n\r\n##INDUSTRIAL STRENGTH SECURITY\r\nPlone is the only open source CMS that provides industrial\r\nstrength security out-of-the-box.\r\n\r\n##ROBUST SCALABILITY\r\nPlone will suit your needs: from standard installations up\r\nto complex, scalable and robust infrastructures.\r\n\r\n##LIMITLESS EXTENSIBILITY\r\nFrom the design of sub-sites and individual pages to\r\ncollaborative enterprise intranets, Plone's dynamic\r\ncustomizations will meet all of your business needs.",
        "authors": [
            "Cris Ewing",
            "Calvin Hendryx-Parker"
        ],
        "conf_key": 1429,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/429/",
        "contact": [
            "cris@crisewing.com",
            "calvinhp@gmail.com"
        ],
        "description": "Plone 5 is the next major release of this flexible, powerful system to build websites, intranets and extranets. With an excellent track record in security, it scales from small community organizations to the largest of  global corporations. The upcoming release will set new standards in  accessibility, interoperability and modern web techniques.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "The Five Advantages of Plone 5",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "Drawing diagrams that effectively convey information about complex systems is both art and science. Open source projects and systems teams could more quickly, concisely and effectively communicate important ideas if they created some diagrams! Basic systems drawing is a fundamental skill that helps \r\n\r\nBased on 20 years of creating practical systems diagrams to reflect business process, software design and computer systems operations, this poster session will help anyone tasked with creating a diagram to do it better. \r\n\r\nThe poster will demonstrate how to create effective diagrams with well-scaled icons, shapes, connectors and fonts; choosing the right level of detail; explanation of jargon that's used; a \"blame\" layer; logical flow on the page; single page per idea or system; and drill-down pages for more detail. Diagrams become invaluable with iterative refinement, an easily shared document format and a maintenance schedule.\r\n\r\nThe poster will also include a list of common pitfalls in diagram creation to avoid, example diagrams and ideas to inspire viewers to create their own diagrams right away.",
        "authors": [
            "Selena Deckelmann"
        ],
        "conf_key": 1427,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/427/",
        "contact": [
            "selenamarie@gmail.com"
        ],
        "description": "Drawing diagrams that effectively convey information about complex systems is both art and science. Drawing on 20 years of creating practical systems diagrams to reflect business process, software design and computer systems operations, this poster session will help anyone tasked with creating a diagram to do it better.",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "Creating effective operations diagrams",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    },
    {
        "abstract": "Do you deploy your Python services to Amazon EC2, or to Openstack, or even to HP cloud, joyent or Azure? Do you want to - without being tied into any one of them? What about local full stack deployments with lxc or kvm containers?\r\n\r\nEven if you're convinced you don't need \"the cloud\" because you manage your own servers, amazing technologies like Private clouds and MaaS, for dynamic server management on bare metal, may change your mind.\r\n\r\nFed up with the cloud hype? Let me rehabilitate the buzzword! (A bit anyway.)\r\n\r\nA fully automated cloud deployment system is essential for rapid scaling, but it's also invaluable for full stack testing on continuous integration systems. Even better, your service deployment and infrastructure can be managed with Python code? (Devops distilled)\r\n\r\nTreat your servers as cattle not as pets, for service oriented repeatable deployments on your choice of back-end. Learn how service orchestration is a powerful new approach to deployment management, and do it with Python! If any of this sounds interesting then Juju maybe for you! ",
        "authors": [
            "Eric Snow"
        ],
        "conf_key": 1446,
        "conf_url": "https://us.pycon.org/2015/schedule/presentation/446/",
        "contact": [
            "ericsnowcurrently@gmail.com"
        ],
        "description": "Behind the buzzword is a genuinely useful technology. The cloud provides benefits like easy scaling and rapid deployment, plus it solves common problems like resource under-utilisation and dependency hell. Service orchestration is a powerful new way to manage your systems. Along the way codify your infrastructure with Python code and get cloud independence with Juju. ",
        "end": "2014-03-17T13:10:00",
        "kind": "poster",
        "license": "CC",
        "name": "To the Clouds: Service Orchestration and Cloud Deployment with Juju",
        "released": true,
        "room": "Poster Room",
        "start": "2014-03-17T10:00:00"
    }
]
